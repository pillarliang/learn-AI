{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/16/2024 15:46:35 - [INFO] -BCEmbedding.models.RerankerModel->>>    Loading from `maidalun1020/bce-reranker-base_v1`.\n",
      "04/16/2024 15:46:35 - [INFO] -BCEmbedding.models.RerankerModel->>>    Execute device: cpu;\t gpu num: 0;\t use fp16: False\n",
      "Calculate scores: 100%|██████████| 1/1 [00:00<00:00, 19.35it/s]\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.536469578742981, 0.3943931758403778, 0.4260145425796509]\n",
      "{'rerank_passages': ['hello kitty', 'sheep', 'bert'], 'rerank_scores': [0.5354868173599243, 0.47016602754592896, 0.40027934312820435], 'rerank_ids': [0, 2, 1]}\n"
     ]
    }
   ],
   "source": [
    "from BCEmbedding import RerankerModel\n",
    "\n",
    "# your query and corresponding passages\n",
    "query = 'cat'\n",
    "passages = ['hello kitty', 'bert', 'sheep']\n",
    "\n",
    "# construct sentence pairs\n",
    "sentence_pairs = [[query, passage] for passage in passages]\n",
    "\n",
    "# init reranker model\n",
    "model = RerankerModel(model_name_or_path=\"maidalun1020/bce-reranker-base_v1\")\n",
    "\n",
    "# method 0: calculate scores of sentence pairs\n",
    "scores = model.compute_score(sentence_pairs)\n",
    "print('scores:', scores)\n",
    "\n",
    "# method 1: rerank passages\n",
    "rerank_results = model.rerank(query, passages)\n",
    "print(rerank_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6293706893920898, 0.250580757856369]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, InferenceClient\n",
    "\n",
    "client = InferenceClient(token=\"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\", model=\"maidalun1020/bce-reranker-base_v1\")\n",
    "client = InferenceClient(token=\"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\")\n",
    "\n",
    "client.sentence_similarity(query, passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rerank_passages\n",
      "['hello kitty', 'bert']\n"
     ]
    }
   ],
   "source": [
    "my_dict = {\n",
    "    'rerank_passages': ['hello kitty', 'bert'], 'rerank_scores': [0.5354868173599243, 0.40027934312820435], 'rerank_ids': [0, 1],\n",
    "}\n",
    "rerank_passages, rerank_scores, rerank_ids = my_dict\n",
    "print(rerank_passages)\n",
    "print(my_dict['rerank_passages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
