{"type": "text", "bbox": [99, 631, 572, 1389], "res": [{"text": "PureSyntheticDataWefirsttraintheEASTmodelson", "confidence": 0.9965837597846985, "text_region": [[103.0, 634.0], [570.0, 634.0], [570.0, 651.0], [103.0, 651.0]]}, {"text": "different syntheticdatasets alone,tocompare our method", "confidence": 0.959636926651001, "text_region": [[101.0, 654.0], [570.0, 655.0], [570.0, 675.0], [101.0, 674.0]]}, {"text": "withprevious ones in a direct and quantitative way.Note", "confidence": 0.9553226828575134, "text_region": [[101.0, 679.0], [570.0, 679.0], [570.0, 699.0], [101.0, 699.0]]}, {"text": "thatUnrealText,SynthText3D,SynthText,andVISDhave", "confidence": 0.9623215794563293, "text_region": [[102.0, 704.0], [569.0, 704.0], [569.0, 721.0], [102.0, 721.0]]}, {"text": "differentnumbers ofimages,sowe alsoneed to control the", "confidence": 0.9667925834655762, "text_region": [[101.0, 726.0], [570.0, 727.0], [570.0, 746.0], [101.0, 745.0]]}, {"text": "number ofimages used in experiments.Results are summa-", "confidence": 0.9709925055503845, "text_region": [[100.0, 750.0], [570.0, 752.0], [570.0, 772.0], [100.0, 770.0]]}, {"text": "rized in Tab.1.", "confidence": 0.9824504256248474, "text_region": [[99.0, 775.0], [221.0, 773.0], [221.0, 793.0], [99.0, 795.0]]}, {"text": "Firstly,we control the totalnumber of images to", "confidence": 0.9481012225151062, "text_region": [[123.0, 798.0], [571.0, 800.0], [571.0, 820.0], [123.0, 818.0]]}, {"text": "10K,which is also the full size of the smallest synthetic", "confidence": 0.9423174858093262, "text_region": [[101.0, 821.0], [570.0, 822.0], [570.0, 842.0], [101.0, 841.0]]}, {"text": "datasets,VISDandSynthText3D.Weobserveaconsider", "confidence": 0.9692859053611755, "text_region": [[103.0, 848.0], [569.0, 848.0], [569.0, 865.0], [103.0, 865.0]]}, {"text": "ableimprovementonIC15overpreviousstate-of-the-artby", "confidence": 0.9975636005401611, "text_region": [[101.0, 871.0], [570.0, 871.0], [570.0, 891.0], [101.0, 891.0]]}, {"text": "+0.9%in F1-score,and significant improvements onIC13", "confidence": 0.9750538468360901, "text_region": [[101.0, 893.0], [571.0, 894.0], [571.0, 913.0], [101.0, 912.0]]}, {"text": "(+2.7%)andMLT 2017(+2.8%).Secondly,we also train", "confidence": 0.9423573613166809, "text_region": [[102.0, 918.0], [570.0, 918.0], [570.0, 935.0], [102.0, 935.0]]}, {"text": "modelsonthefullsetofSynthTextandours,sincescalabil", "confidence": 0.995623767375946, "text_region": [[103.0, 943.0], [567.0, 943.0], [567.0, 960.0], [103.0, 960.0]]}, {"text": "ityisalsoanimportantfactorforsyntheticscenetextim", "confidence": 0.9921039938926697, "text_region": [[100.0, 967.0], [568.0, 965.0], [568.0, 984.0], [100.0, 986.0]]}, {"text": "ages,especially whenconsideringthe demand to train rec", "confidence": 0.962331235408783, "text_region": [[100.0, 991.0], [570.0, 988.0], [570.0, 1009.0], [100.0, 1012.0]]}, {"text": "ognizers.Extra trainingimages furtherimproveF1scores", "confidence": 0.9840582609176636, "text_region": [[101.0, 1015.0], [569.0, 1015.0], [569.0, 1035.0], [101.0, 1035.0]]}, {"text": "onIC15,IC13,and MLT by +2.6%,+2.3%,and +2.1%", "confidence": 0.9268423318862915, "text_region": [[100.0, 1038.0], [569.0, 1036.0], [569.0, 1055.0], [100.0, 1057.0]]}, {"text": "ModelstrainedwithourUnrealTextdataoutperformall", "confidence": 0.9989125728607178, "text_region": [[102.0, 1063.0], [570.0, 1063.0], [570.0, 1080.0], [102.0, 1080.0]]}, {"text": "other synthetic datasets.Besides,the subset of 10K images", "confidence": 0.9760853052139282, "text_region": [[100.0, 1082.0], [571.0, 1085.0], [571.0, 1109.0], [100.0, 1106.0]]}, {"text": "withourmethodevensurpasses800KSynthTextimages", "confidence": 0.9851198196411133, "text_region": [[101.0, 1109.0], [570.0, 1111.0], [570.0, 1131.0], [101.0, 1129.0]]}, {"text": "significantly on all datasets.The experiment results demon-", "confidence": 0.9659050703048706, "text_region": [[100.0, 1134.0], [570.0, 1133.0], [570.0, 1153.0], [100.0, 1154.0]]}, {"text": "strate theeffectiveness of ourproposedsyntheticengine and", "confidence": 0.9633448123931885, "text_region": [[100.0, 1158.0], [571.0, 1158.0], [571.0, 1178.0], [100.0, 1178.0]]}, {"text": "datasets.", "confidence": 0.997878909111023, "text_region": [[100.0, 1181.0], [168.0, 1183.0], [168.0, 1201.0], [100.0, 1198.0]]}, {"text": "ComplementarySyntheticDataOneuniquecharacteristic", "confidence": 0.9848400950431824, "text_region": [[101.0, 1203.0], [570.0, 1204.0], [570.0, 1225.0], [101.0, 1224.0]]}, {"text": "of theproposedUnrealTextis that,theimages aregenerated", "confidence": 0.9768059849739075, "text_region": [[100.0, 1228.0], [571.0, 1229.0], [571.0, 1250.0], [100.0, 1249.0]]}, {"text": "from 3D scene models,instead ofrealbackground images", "confidence": 0.9601188898086548, "text_region": [[100.0, 1252.0], [569.0, 1254.0], [569.0, 1274.0], [100.0, 1272.0]]}, {"text": "resultinginpotentialdomaingapdue todifferentartistic", "confidence": 0.9730865955352783, "text_region": [[101.0, 1277.0], [570.0, 1277.0], [570.0, 1297.0], [101.0, 1297.0]]}, {"text": "styles.Weconductexperimentsby training onbothUnre", "confidence": 0.9796655774116516, "text_region": [[100.0, 1301.0], [568.0, 1300.0], [568.0, 1320.0], [100.0, 1321.0]]}, {"text": "alTextdata(5K)andVIsD(5K),asalsoshowninTab.1", "confidence": 0.9672307372093201, "text_region": [[101.0, 1326.0], [568.0, 1326.0], [568.0, 1343.0], [101.0, 1343.0]]}, {"text": "(lastrow,markedwithitalics),which achievesbetterperfor-", "confidence": 0.9705619215965271, "text_region": [[100.0, 1348.0], [570.0, 1349.0], [570.0, 1368.0], [100.0, 1367.0]]}, {"text": "mancethanother1OKsyntheticdatasets.Thecombinatior", "confidence": 0.9786937236785889, "text_region": [[102.0, 1374.0], [568.0, 1374.0], [568.0, 1388.0], [102.0, 1388.0]]}], "img_idx": 0}
{"type": "text", "bbox": [98, 150, 573, 571], "res": [{"text": "accurate.EASTalsoformsthebasisofseveralwidelyrec", "confidence": 0.998153030872345, "text_region": [[102.0, 153.0], [568.0, 153.0], [568.0, 170.0], [102.0, 170.0]]}, {"text": "ognized end-to-end text spotting models [18,7]. We adopt", "confidence": 0.9673420786857605, "text_region": [[101.0, 174.0], [570.0, 174.0], [570.0, 195.0], [101.0, 195.0]]}, {"text": "an opensourceimplementation?.In all experiments,models", "confidence": 0.9651122689247131, "text_region": [[99.0, 199.0], [571.0, 198.0], [571.0, 218.0], [99.0, 219.0]]}, {"text": "aretrainedon4GPUwithabatchsizeof56.Duringthe", "confidence": 0.9990940690040588, "text_region": [[100.0, 222.0], [570.0, 223.0], [570.0, 241.0], [100.0, 240.0]]}, {"text": "evaluation,the test images areresized tomatch a short side", "confidence": 0.9541195631027222, "text_region": [[101.0, 246.0], [572.0, 246.0], [572.0, 266.0], [101.0, 266.0]]}, {"text": "lengthof800pixels.Foreachexperimentsetting,wereport", "confidence": 0.9779906272888184, "text_region": [[101.0, 269.0], [571.0, 271.0], [571.0, 289.0], [101.0, 287.0]]}, {"text": "themeanperformancein5independenttrials.", "confidence": 0.9892463684082031, "text_region": [[101.0, 294.0], [464.0, 294.0], [464.0, 311.0], [101.0, 311.0]]}, {"text": "BenchmarkDatasetsWeusethefollowingscenetext", "confidence": 0.9914090633392334, "text_region": [[99.0, 315.0], [572.0, 317.0], [572.0, 337.0], [99.0, 335.0]]}, {"text": "detectiondatasetsforevaluation:(1)ICDAR2013Fo", "confidence": 0.9636309146881104, "text_region": [[102.0, 342.0], [569.0, 342.0], [569.0, 359.0], [102.0, 359.0]]}, {"text": "cusedSceneText(IC13)[14]containinghorizontaltextwith", "confidence": 0.978155255317688, "text_region": [[102.0, 367.0], [570.0, 367.0], [570.0, 384.0], [102.0, 384.0]]}, {"text": "zoomed-inviews.(2)ICDAR2015IncidentalSceneTexi", "confidence": 0.9704822897911072, "text_region": [[101.0, 390.0], [570.0, 390.0], [570.0, 407.0], [101.0, 407.0]]}, {"text": "(IC15)[13]consistingofimagestakenwithoutcarefulness", "confidence": 0.9876791834831238, "text_region": [[102.0, 414.0], [570.0, 414.0], [570.0, 431.0], [102.0, 431.0]]}, {"text": "withGoogleGlass.Imagesareblurredandtextaresmall.", "confidence": 0.983559787273407, "text_region": [[102.0, 437.0], [570.0, 437.0], [570.0, 455.0], [102.0, 455.0]]}, {"text": "(3\uff09MLT2017[27]formultilingualscenetextdetection", "confidence": 0.9694309830665588, "text_region": [[100.0, 461.0], [569.0, 462.0], [569.0, 479.0], [100.0, 478.0]]}, {"text": "whichis composedof scenetextimages of 9languages.", "confidence": 0.9634930491447449, "text_region": [[100.0, 483.0], [571.0, 486.0], [571.0, 506.0], [100.0, 503.0]]}, {"text": "Note that theimagesinIC13andMLT17havevaryingres-", "confidence": 0.9767487645149231, "text_region": [[99.0, 507.0], [570.0, 509.0], [570.0, 530.0], [99.0, 527.0]]}, {"text": "olutions.Therefore,it is necessary to resize them to the", "confidence": 0.9550303220748901, "text_region": [[101.0, 531.0], [572.0, 532.0], [572.0, 552.0], [101.0, 551.0]]}, {"text": "levelofresolutionsbeforeevaluation", "confidence": 0.979136049747467, "text_region": [[141.0, 558.0], [440.0, 558.0], [440.0, 570.0], [141.0, 570.0]]}], "img_idx": 0}
{"type": "text", "bbox": [616, 475, 1090, 1381], "res": [{"text": "ofUnrealTextandVISDisalsosuperiortothecombina-", "confidence": 0.9810508489608765, "text_region": [[619.0, 477.0], [1087.0, 477.0], [1087.0, 494.0], [619.0, 494.0]]}, {"text": "tion of SynthText3DandVISD.This resultdemonstrates", "confidence": 0.9741440415382385, "text_region": [[618.0, 498.0], [1088.0, 498.0], [1088.0, 518.0], [618.0, 518.0]]}, {"text": "that,our UnrealTextis complementary to existing syn", "confidence": 0.959830641746521, "text_region": [[617.0, 521.0], [1086.0, 524.0], [1086.0, 545.0], [617.0, 543.0]]}, {"text": "thetic datasets that use realimages as backgrounds.While", "confidence": 0.9559327960014343, "text_region": [[618.0, 546.0], [1086.0, 547.0], [1086.0, 567.0], [618.0, 566.0]]}, {"text": "UnrealTextsimulatesphoto-realisticeffects,syntheticdata", "confidence": 0.9761452674865723, "text_region": [[620.0, 572.0], [1087.0, 572.0], [1087.0, 589.0], [620.0, 589.0]]}, {"text": "withreal background images canhelp adapt toreal-world", "confidence": 0.9695603251457214, "text_region": [[619.0, 595.0], [1088.0, 595.0], [1088.0, 616.0], [619.0, 616.0]]}, {"text": "datasets.", "confidence": 0.9986351728439331, "text_region": [[619.0, 620.0], [685.0, 620.0], [685.0, 637.0], [619.0, 637.0]]}, {"text": "CombiningSyntheticandRealDataOneimportantrole", "confidence": 0.9979193806648254, "text_region": [[621.0, 646.0], [1087.0, 646.0], [1087.0, 663.0], [621.0, 663.0]]}, {"text": "ofsyntheticdataistoserveasdataforpretraining,andto", "confidence": 0.9868736863136292, "text_region": [[619.0, 670.0], [1088.0, 670.0], [1088.0, 687.0], [619.0, 687.0]]}, {"text": "further improve theperformance on domain specificreal", "confidence": 0.9652031660079956, "text_region": [[618.0, 690.0], [1089.0, 691.0], [1089.0, 713.0], [618.0, 712.0]]}, {"text": "datasets.We first pretrain theEAST models with differ-", "confidence": 0.9514475464820862, "text_region": [[618.0, 716.0], [1088.0, 716.0], [1088.0, 736.0], [618.0, 736.0]]}, {"text": "entsyntheticdata,andthenusedomaindatatofinetunethe", "confidence": 0.9879727959632874, "text_region": [[619.0, 742.0], [1088.0, 740.0], [1088.0, 757.0], [619.0, 759.0]]}, {"text": "models.TheresultsaresummarizedinTab.2.Onall", "confidence": 0.9991397261619568, "text_region": [[619.0, 765.0], [1089.0, 765.0], [1089.0, 782.0], [619.0, 782.0]]}, {"text": "domain-specific datasets,models pretrained with our syn-", "confidence": 0.9733774065971375, "text_region": [[618.0, 787.0], [1088.0, 788.0], [1088.0, 809.0], [618.0, 808.0]]}, {"text": "thetic dataset surpasses others by considerable margins,ver", "confidence": 0.9689874053001404, "text_region": [[617.0, 810.0], [1087.0, 812.0], [1087.0, 833.0], [617.0, 831.0]]}, {"text": "ifyingtheeffectiveness of oursynthesismethodin the con-", "confidence": 0.9650766253471375, "text_region": [[617.0, 835.0], [1088.0, 836.0], [1088.0, 856.0], [617.0, 855.0]]}, {"text": "textofboostingperformanceondomainspecificdatasets", "confidence": 0.9982023239135742, "text_region": [[619.0, 861.0], [1073.0, 861.0], [1073.0, 878.0], [619.0, 878.0]]}, {"text": "PretrainingonFullDatasetAsshownin thelastrows", "confidence": 0.9900161623954773, "text_region": [[618.0, 886.0], [1087.0, 886.0], [1087.0, 906.0], [618.0, 906.0]]}, {"text": "of Tab.2,whenwepretrain the detector models with our", "confidence": 0.9499303102493286, "text_region": [[618.0, 910.0], [1089.0, 910.0], [1089.0, 930.0], [618.0, 930.0]]}, {"text": "fulldataset,theperformances areimproved significantly", "confidence": 0.9785286784172058, "text_region": [[617.0, 933.0], [1088.0, 934.0], [1088.0, 954.0], [617.0, 953.0]]}, {"text": "demonstratingtheadvantageofthescalabilityofouren-", "confidence": 0.9930554032325745, "text_region": [[619.0, 959.0], [1087.0, 959.0], [1087.0, 977.0], [619.0, 977.0]]}, {"text": "gine.Especially,The EAST model achieves an F1 score", "confidence": 0.958925724029541, "text_region": [[618.0, 982.0], [1089.0, 981.0], [1089.0, 1002.0], [618.0, 1003.0]]}, {"text": "of 74.1onMLT17,which is evenbetter thanrecent state-", "confidence": 0.9486492872238159, "text_region": [[619.0, 1004.0], [1087.0, 1006.0], [1087.0, 1026.0], [619.0, 1024.0]]}, {"text": "of-the-art results,including 73.9 by CRAFT[2] and 73.1 by", "confidence": 0.9630292057991028, "text_region": [[619.0, 1030.0], [1088.0, 1030.0], [1088.0, 1050.0], [619.0, 1050.0]]}, {"text": "LOMO[52].Although the margin is not great, it suffices", "confidence": 0.9599967002868652, "text_region": [[618.0, 1053.0], [1088.0, 1053.0], [1088.0, 1074.0], [618.0, 1074.0]]}, {"text": "to claimthat theEASTmodelrevives andreclaims state-of", "confidence": 0.9644318222999573, "text_region": [[618.0, 1076.0], [1086.0, 1077.0], [1086.0, 1097.0], [618.0, 1096.0]]}, {"text": "the-artperformancewiththehelpofoursyntheticdataset.", "confidence": 0.9958233833312988, "text_region": [[619.0, 1103.0], [1078.0, 1103.0], [1078.0, 1120.0], [619.0, 1120.0]]}, {"text": "ResultswithMask-RCNNAstheEASTalgorithmweuse", "confidence": 0.9987044334411621, "text_region": [[618.0, 1126.0], [1089.0, 1128.0], [1089.0, 1148.0], [618.0, 1146.0]]}, {"text": "aboveisspecificallydesignedforscenetextandthatthe", "confidence": 0.9938319325447083, "text_region": [[620.0, 1152.0], [1087.0, 1152.0], [1087.0, 1170.0], [620.0, 1170.0]]}, {"text": "evaluationwithF1scoresmaynotbecomprehensive,we", "confidence": 0.9867678284645081, "text_region": [[620.0, 1177.0], [1088.0, 1177.0], [1088.0, 1194.0], [620.0, 1194.0]]}, {"text": "provide results with Mask-RCNN[?]which is ageneral", "confidence": 0.9541280269622803, "text_region": [[618.0, 1199.0], [1089.0, 1199.0], [1089.0, 1219.0], [618.0, 1219.0]]}, {"text": "objectdetector.WeevaluatethemodelsusingtheAverage", "confidence": 0.9982101321220398, "text_region": [[618.0, 1221.0], [1088.0, 1223.0], [1088.0, 1244.0], [618.0, 1241.0]]}, {"text": "Precision(AP)metricswhicharemorecomprehensiveand", "confidence": 0.9940810203552246, "text_region": [[619.0, 1249.0], [1088.0, 1249.0], [1088.0, 1266.0], [619.0, 1266.0]]}, {"text": "lessaffectedbythetrickychoiceofthresholdvalues.We", "confidence": 0.9976038336753845, "text_region": [[619.0, 1272.0], [1088.0, 1272.0], [1088.0, 1289.0], [619.0, 1289.0]]}, {"text": "use the opensourceimplementationDetectron24.Thero-", "confidence": 0.9824125170707703, "text_region": [[617.0, 1295.0], [1089.0, 1293.0], [1089.0, 1313.0], [617.0, 1315.0]]}, {"text": "tatedboundingboxes of text instances areused asthemask", "confidence": 0.9762003421783447, "text_region": [[618.0, 1318.0], [1089.0, 1317.0], [1089.0, 1338.0], [618.0, 1339.0]]}, {"text": "annotations.WeselectadefaultMask-RCNNconfiguration", "confidence": 0.9971362352371216, "text_region": [[619.0, 1344.0], [1088.0, 1344.0], [1088.0, 1361.0], [619.0, 1361.0]]}], "img_idx": 0}
{"type": "text", "bbox": [617, 378, 1090, 421], "res": [{"text": "Table1:", "confidence": 0.8965954780578613, "text_region": [[620.0, 381.0], [687.0, 381.0], [687.0, 394.0], [620.0, 394.0]]}, {"text": "models", "confidence": 0.9975934028625488, "text_region": [[1031.0, 381.0], [1088.0, 379.0], [1088.0, 394.0], [1031.0, 396.0]]}, {"text": "on", "confidence": 0.9485408663749695, "text_region": [[672.0, 408.0], [704.0, 408.0], [704.0, 417.0], [672.0, 417.0]]}, {"text": "svnthetic", "confidence": 0.892160177230835, "text_region": [[777.0, 408.0], [850.0, 408.0], [850.0, 417.0], [777.0, 417.0]]}, {"text": "data", "confidence": 0.9950860738754272, "text_region": [[853.0, 406.0], [887.0, 406.0], [887.0, 420.0], [853.0, 420.0]]}], "img_idx": 0}
{"type": "title", "bbox": [100, 594, 332, 614], "res": [{"text": ".z.hxpersnentskeslir", "confidence": 0.6942847967147827, "text_region": [[110.0, 600.0], [320.0, 600.0], [320.0, 608.0], [110.0, 608.0]]}], "img_idx": 0}
{"type": "figure_caption", "bbox": [617, 378, 1045, 421], "res": [{"text": "Iable", "confidence": 0.9298015832901001, "text_region": [[620.0, 381.0], [663.0, 381.0], [663.0, 394.0], [620.0, 394.0]]}, {"text": "", "confidence": 0.0, "text_region": [[660.0, 380.0], [685.0, 384.0], [684.0, 393.0], [659.0, 390.0]]}, {"text": "Detectionresults (F1-scores)of EASTn", "confidence": 0.9402263164520264, "text_region": [[700.0, 378.0], [1043.0, 378.0], [1043.0, 395.0], [700.0, 395.0]]}, {"text": "trained", "confidence": 0.9971955418586731, "text_region": [[618.0, 404.0], [674.0, 404.0], [674.0, 417.0], [618.0, 417.0]]}, {"text": "Onditferent", "confidence": 0.7689578533172607, "text_region": [[677.0, 408.0], [772.0, 408.0], [772.0, 417.0], [677.0, 417.0]]}, {"text": "syntheticdata", "confidence": 0.9957612156867981, "text_region": [[774.0, 406.0], [888.0, 406.0], [888.0, 420.0], [774.0, 420.0]]}], "img_idx": 0}
{"type": "table", "bbox": [623, 138, 1107, 370], "res": "", "img_idx": 0}
{"type": "reference", "bbox": [126, 1409, 410, 1426], "res": [{"text": "+tos\uff1a", "confidence": 0.5431625843048096, "text_region": [[136.0, 1415.0], [187.0, 1415.0], [187.0, 1421.0], [136.0, 1421.0]]}, {"text": "github.com/argman/eAs", "confidence": 0.8502197265625, "text_region": [[202.0, 1414.0], [402.0, 1414.0], [402.0, 1421.0], [202.0, 1422.0]]}], "img_idx": 0}
{"type": "reference", "bbox": [630, 1409, 1083, 1427], "res": [{"text": "+S", "confidence": 0.2290998250246048, "text_region": [[652.0, 1416.0], [693.0, 1416.0], [693.0, 1421.0], [652.0, 1421.0]]}, {"text": "b.com/tacebookresearch/detectron", "confidence": 0.9644749164581299, "text_region": [[771.0, 1413.0], [1077.0, 1415.0], [1077.0, 1422.0], [771.0, 1421.0]]}], "img_idx": 0}
