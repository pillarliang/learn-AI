{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PubMedLoader\n",
    "\n",
    "loader = PubMedLoader(\"liver\", load_max_docs=10)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'download_loader' from 'llama_index' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download_loader\n\u001b[1;32m      3\u001b[0m SemanticScholarReader \u001b[38;5;241m=\u001b[39m download_loader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSemanticScholarReader\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m loader \u001b[38;5;241m=\u001b[39m SemanticScholarReader()\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'download_loader' from 'llama_index' (unknown location)"
     ]
    }
   ],
   "source": [
    "from llama_index import download_loader\n",
    "\n",
    "SemanticScholarReader = download_loader(\"SemanticScholarReader\")\n",
    "loader = SemanticScholarReader()\n",
    "query_space = \"large language models\"\n",
    "documents = loader.load_data(query=query_space,full_text=True,limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# documents = load your documents\n",
    "\n",
    "# generator with openai models\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "# Change resulting question type distribution\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}\n",
    "\n",
    "# use generator.generate_with_llamaindex_docs if you use llama-index as document loader\n",
    "testset = generator.generate_with_langchain_docs(documents, 10, distributions) \n",
    "testset.to_pandas()\n",
    "\n",
    "test_df = testset.to_pandas()\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a context, and an answer, analyze each sentence in the answer and classify if the sentence can be attributed to the given context or not. Use only \"Yes\" (1) or \"No\" (0) as a binary classification. Output json with reason.\n",
      "\n",
      "The output should be a well-formatted JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {{\"properties\": {{\"foo\": {{\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {{\"type\": \"string\"}}}}}}, \"required\": [\"foo\"]}}\n",
      "the object {{\"foo\": [\"bar\", \"baz\"]}} is a well-formatted instance of the schema. The object {{\"properties\": {{\"foo\": [\"bar\", \"baz\"]}}}} is not well-formatted.\n",
      "\n",
      "Here is the output JSON schema:\n",
      "```\n",
      "{{\"type\": \"array\", \"items\": {{\"$ref\": \"#/definitions/ContextRecallClassificationAnswer\"}}, \"definitions\": {{\"ContextRecallClassificationAnswer\": {{\"title\": \"ContextRecallClassificationAnswer\", \"type\": \"object\", \"properties\": {{\"statement\": {{\"title\": \"Statement\", \"type\": \"string\"}}, \"attributed\": {{\"title\": \"Attributed\", \"type\": \"integer\"}}, \"reason\": {{\"title\": \"Reason\", \"type\": \"string\"}}}}, \"required\": [\"statement\", \"attributed\", \"reason\"]}}}}}}\n",
      "```\n",
      "\n",
      "Do not return any preamble or explanations, return only a pure JSON string surrounded by triple backticks (```).\n",
      "\n",
      "Examples:\n",
      "\n",
      "question: \"你能告诉我关于阿尔伯特·爱因斯坦的事情吗？\"\n",
      "context: \"阿尔伯特·爱因斯坦（1879年3月14日 - 1955年4月18日）是一位出生于德国的理论物理学家，被广泛认为是有史以来最伟大和最有影响力的科学家之一。他最为人所知的是发展了相对论，他还对量子力学做出了重要贡献，因此在二十世纪初的几十年里，他在科学对自然的理解的革命性重塑中起着核心作用。他的质能等价公式E = mc2，源于相对论，被誉为“世界上最著名的等式”。他因“对理论物理的贡献，特别是发现了光电效应的定律”而获得了1921年的诺贝尔物理学奖，这是量子理论发展的关键步骤。他的工作也因其对科学哲学的影响而闻名。在1999年由英国物理世界杂志对全球130位领先物理学家进行的投票中，爱因斯坦被评为有史以来最伟大的物理学家。他的智力成就和独创性使爱因斯坦与天才成为同义词。\"\n",
      "answer: \"阿尔伯特·爱因斯坦，1879年3月14日出生，是德国出生的理论物理学家，被广泛认为是有史以来最伟大和最有影响力的科学家之一。他因对理论物理学的贡献而获得了1921年的诺贝尔物理学奖。他在1905年发表了4篇论文。爱因斯坦于1895年移居瑞士。\"\n",
      "classification: ```[{{\"statement\": \"阿尔伯特·爱因斯坦，1879年3月14日出生，是一位出生于德国的理论物理学家，被广泛认为是有史以来最伟大和最有影响力的科学家之一。\", \"attributed\": 1, \"reason\": \"爱因斯坦的出生日期在上下文中明确提到。\"}}, {{\"statement\": \"他因对理论物理学的贡献获得了1921年的诺贝尔物理学奖。\", \"attributed\": 1, \"reason\": \"给定上下文中存在确切的句子。\"}}, {{\"statement\": \"他在1905年发表了4篇论文。\", \"attributed\": 0, \"reason\": \"在给定的上下文中没有提到他写的论文。\"}}, {{\"statement\": \"爱因斯坦在1895年移居瑞士。\", \"attributed\": 0, \"reason\": \"在给定的上下文中没有支持这一点的证据。\"}}]```\n",
      "\n",
      "question: \"谁赢得了2020年的国际板球理事会世界杯？\"\n",
      "context: \"2022年的ICC男子T20世界杯于2022年10月16日至11月13日在澳大利亚举行，这是该锦标赛的第八届。原定于2020年举行，但由于COVID-19大流行而推迟。英格兰在决赛中以五个投球击败巴基斯坦，赢得了他们的第二个ICC男子T20世界杯冠军。\"\n",
      "answer: \"英格兰\"\n",
      "classification: ```[{{\"statement\": \"英格兰赢得了2022年ICC男子T20世界杯。\", \"attributed\": 1, \"reason\": \"从上下文中可以清楚地看出，英格兰击败了巴基斯坦赢得了世界杯。\"}}]```\n",
      "\n",
      "question: \"太阳的主要燃料是什么？\"\n",
      "context: \"输入: \\\"NULL\\\"\\n输出: \\\"输入:“NULL”\\\"\"\n",
      "answer: \"氢\"\n",
      "classification: ```[{{\"statement\": \"太阳的主要燃料是氢。\", \"attributed\": 0, \"reason\": \"上下文中没有信息\"}}]```\n",
      "\n",
      "Your actual task:\n",
      "\n",
      "question: {question}\n",
      "context: {context}\n",
      "answer: {answer}\n",
      "classification: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import context_recall\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "OPENAI_API_KEY = 'FAKE_KEY'\n",
    "OPENAI_BASE_URL = 'http://10.10.11.2:8001/v1'\n",
    "OPENAI_MODEL_NAME = 'Qwen1.5-14B-Chat'\n",
    "\n",
    "generator_llm = critic_llm  = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=OPENAI_BASE_URL,\n",
    "    model=OPENAI_MODEL_NAME,\n",
    ")\n",
    "\n",
    "# context_recall.llm = generator_llm\n",
    "# context_recall.adapt(language=\"中文\")\n",
    "print(context_recall.context_recall_prompt.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
