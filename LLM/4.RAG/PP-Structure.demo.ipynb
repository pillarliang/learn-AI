{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 版面分析+表格识别\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/06/03 10:01:06] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/liangzhu/.paddleocr/whl/det/ch/ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/liangzhu/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir=None, cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir='/Users/liangzhu/.paddleocr/whl/table/ch_ppstructure_mobile_v2.0_SLANet_infer', merge_no_span_structure=True, table_char_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/table_structure_dict_ch.txt', layout_model_dir='/Users/liangzhu/.paddleocr/whl/layout/picodet_lcnet_x1_0_fgd_layout_cdla_infer', layout_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/layout_dict/layout_cdla_dict.txt', layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/06/03 10:01:09] ppocr DEBUG: dt_boxes num : 7, elapsed : 0.07033586502075195\n",
      "[2024/06/03 10:01:12] ppocr DEBUG: rec_res num  : 7, elapsed : 2.677130937576294\n",
      "[2024/06/03 10:01:12] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.04724907875061035\n",
      "[2024/06/03 10:01:13] ppocr DEBUG: rec_res num  : 2, elapsed : 0.32146501541137695\n",
      "[2024/06/03 10:01:13] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.011603355407714844\n",
      "[2024/06/03 10:01:13] ppocr DEBUG: rec_res num  : 0, elapsed : 1.1920928955078125e-06\n",
      "[2024/06/03 10:01:13] ppocr DEBUG: dt_boxes num : 21, elapsed : 0.2466869354248047\n",
      "[2024/06/03 10:01:15] ppocr DEBUG: rec_res num  : 21, elapsed : 2.2527220249176025\n",
      "[2024/06/03 10:01:15] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.025188922882080078\n",
      "[2024/06/03 10:01:15] ppocr DEBUG: rec_res num  : 1, elapsed : 0.10498690605163574\n",
      "[2024/06/03 10:01:15] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.022190093994140625\n",
      "[2024/06/03 10:01:15] ppocr DEBUG: rec_res num  : 0, elapsed : 9.5367431640625e-07\n",
      "[2024/06/03 10:01:16] ppocr DEBUG: dt_boxes num : 80, elapse : 0.14622092247009277\n",
      "[2024/06/03 10:01:24] ppocr DEBUG: rec_res num  : 80, elapse : 7.9369800090789795\n",
      "[2024/06/03 10:01:25] ppocr DEBUG: dt_boxes num : 110, elapse : 0.16349291801452637\n",
      "[2024/06/03 10:01:36] ppocr DEBUG: rec_res num  : 110, elapse : 10.794733047485352\n",
      "[2024/06/03 10:01:36] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.013908863067626953\n",
      "[2024/06/03 10:01:37] ppocr DEBUG: rec_res num  : 1, elapsed : 0.38533806800842285\n",
      "[2024/06/03 10:01:37] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.026576995849609375\n",
      "[2024/06/03 10:01:37] ppocr DEBUG: rec_res num  : 1, elapsed : 0.18347382545471191\n",
      "{'type': 'text', 'bbox': [11, 729, 407, 847], 'res': [{'text': 'C1W1500', 'confidence': 0.9461386799812317, 'text_region': [[16.0, 734.0], [87.0, 734.0], [87.0, 743.0], [16.0, 743.0]]}, {'text': 'Intesting,thethresholdthsissettoO.8', 'confidence': 0.9729145765304565, 'text_region': [[102.0, 733.0], [403.0, 731.0], [403.0, 744.0], [102.0, 746.0]]}, {'text': 'Representative visibleresults are showninFig.8(c)and', 'confidence': 0.9624862670898438, 'text_region': [[13.0, 750.0], [406.0, 750.0], [406.0, 766.0], [13.0, 766.0]]}, {'text': '（d)，whichindicateourmethodpreciselydetectsbound', 'confidence': 0.9756805896759033, 'text_region': [[14.0, 770.0], [403.0, 770.0], [403.0, 786.0], [14.0, 786.0]]}, {'text': 'ariesoflongcurvedtextwithline-level.Thequantitative', 'confidence': 0.9955954551696777, 'text_region': [[13.0, 789.0], [404.0, 789.0], [404.0, 805.0], [13.0, 805.0]]}, {'text': 'resultsarelistedinTab.6.Comparedwiththeprevious', 'confidence': 0.9981792569160461, 'text_region': [[13.0, 808.0], [405.0, 808.0], [405.0, 824.0], [13.0, 824.0]]}, {'text': 'sate-of-the-artmethods[12.34.36].ourapproachachieve', 'confidence': 0.9645132422447205, 'text_region': [[15.0, 829.0], [402.0, 829.0], [402.0, 841.0], [15.0, 841.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [442, 754, 837, 847], 'res': [{'text': 'deteclior', 'confidence': 0.7662321925163269, 'text_region': [[773.0, 778.0], [830.0, 778.0], [830.0, 785.0], [773.0, 785.0]]}, {'text': 'yhichadoptai', 'confidence': 0.8828545212745667, 'text_region': [[447.0, 795.0], [539.0, 797.0], [539.0, 806.0], [447.0, 804.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [443, 705, 559, 719], 'res': [], 'img_idx': 0}\n",
      "{'type': 'figure', 'bbox': [10, 1, 841, 294], 'res': [{'text': 'BARBER', 'confidence': 0.9973224997520447, 'text_region': [[671.0, 32.0], [801.0, 28.0], [802.0, 69.0], [672.0, 73.0]]}, {'text': 'SITEOD', 'confidence': 0.9234414100646973, 'text_region': [[493.0, 51.0], [564.0, 49.0], [564.0, 63.0], [494.0, 65.0]]}, {'text': 'ANCIEN\\'T\"', 'confidence': 0.856279194355011, 'text_region': [[485.0, 65.0], [574.0, 65.0], [574.0, 78.0], [485.0, 78.0]]}, {'text': 'MARKET SOUARE', 'confidence': 0.8942422270774841, 'text_region': [[453.0, 79.0], [606.0, 79.0], [606.0, 93.0], [453.0, 93.0]]}, {'text': '[3th C', 'confidence': 0.9436720013618469, 'text_region': [[498.0, 97.0], [558.0, 97.0], [558.0, 111.0], [498.0, 111.0]]}, {'text': 'GHOP', 'confidence': 0.9577801823616028, 'text_region': [[680.0, 96.0], [794.0, 99.0], [794.0, 136.0], [679.0, 133.0]]}, {'text': 'Nn.24]', 'confidence': 0.7599002718925476, 'text_region': [[511.0, 122.0], [548.0, 122.0], [548.0, 132.0], [511.0, 132.0]]}, {'text': 'TOSZWORLD', 'confidence': 0.8543417453765869, 'text_region': [[66.0, 195.0], [205.0, 190.0], [206.0, 222.0], [67.0, 227.0]]}, {'text': '1', 'confidence': 0.24723190069198608, 'text_region': [[469.0, 194.0], [480.0, 194.0], [480.0, 203.0], [469.0, 203.0]]}, {'text': 'OCK', 'confidence': 0.7978970408439636, 'text_region': [[677.0, 187.0], [721.0, 181.0], [723.0, 200.0], [679.0, 205.0]]}, {'text': 'Ok', 'confidence': 0.4694899320602417, 'text_region': [[326.0, 199.0], [341.0, 199.0], [341.0, 207.0], [326.0, 207.0]]}, {'text': '4WT1', 'confidence': 0.2867673635482788, 'text_region': [[338.0, 200.0], [364.0, 203.0], [363.0, 214.0], [337.0, 211.0]]}, {'text': 'Toro', 'confidence': 0.7058667540550232, 'text_region': [[314.0, 227.0], [351.0, 221.0], [354.0, 239.0], [316.0, 245.0]]}, {'text': 'Leria dei agriamiwr nie joz', 'confidence': 0.7184458374977112, 'text_region': [[465.0, 220.0], [592.0, 197.0], [595.0, 215.0], [468.0, 237.0]]}, {'text': '品', 'confidence': 0.1892227679491043, 'text_region': [[96.0, 236.0], [111.0, 236.0], [111.0, 243.0], [96.0, 243.0]]}, {'text': 'eura Winz', 'confidence': 0.5930038690567017, 'text_region': [[514.0, 232.0], [561.0, 224.0], [563.0, 238.0], [516.0, 247.0]]}, {'text': '福', 'confidence': 0.09000060707330704, 'text_region': [[679.0, 231.0], [695.0, 231.0], [695.0, 245.0], [679.0, 245.0]]}, {'text': 'SUNWADCITVPOH', 'confidence': 0.8725737929344177, 'text_region': [[77.0, 241.0], [188.0, 245.0], [187.0, 261.0], [77.0, 256.0]]}, {'text': 'CUSEUM', 'confidence': 0.8308377861976624, 'text_region': [[687.0, 234.0], [787.0, 232.0], [787.0, 256.0], [688.0, 259.0]]}, {'text': 'DTNTOON', 'confidence': 0.36491188406944275, 'text_region': [[513.0, 249.0], [564.0, 237.0], [566.0, 249.0], [515.0, 260.0]]}, {'text': '765716707', 'confidence': 0.3498694598674774, 'text_region': [[511.0, 260.0], [564.0, 247.0], [566.0, 259.0], [514.0, 271.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [70, 317, 707, 357], 'res': [{'text': 'Theblue', 'confidence': 0.9513667225837708, 'text_region': [[249.0, 319.0], [304.0, 319.0], [304.0, 328.0], [249.0, 328.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [160, 317, 797, 335], 'res': [], 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [453, 359, 822, 664], 'res': {'cell_bbox': [[37.02068328857422, 7.918814659118652, 102.86530303955078, 7.905972003936768, 103.93907928466797, 19.56243324279785, 37.05284118652344, 19.635860443115234], [146.73123168945312, 6.30679988861084, 178.56280517578125, 6.161288738250732, 181.1864013671875, 20.368322372436523, 149.0253143310547, 20.89002227783203], [209.3782958984375, 4.934308052062988, 233.69003295898438, 4.854434967041016, 236.0261993408203, 19.18915367126465, 211.77857971191406, 19.629220962524414], [266.7356262207031, 5.390480041503906, 291.5375671386719, 5.297199726104736, 293.080078125, 19.29720115661621, 268.8021545410156, 19.685426712036133], [320.026123046875, 5.839243412017822, 356.4461975097656, 5.785707950592041, 356.5975036621094, 20.283206939697266, 320.7641296386719, 20.501331329345703], [20.7646541595459, 25.679859161376953, 112.1111831665039, 25.43370246887207, 111.81182098388672, 39.405052185058594, 20.262662887573242, 39.43674087524414], [147.09384155273438, 24.41487693786621, 185.96693420410156, 24.400989532470703, 186.39842224121094, 41.975006103515625, 147.22288513183594, 41.991722106933594], [201.40086364746094, 24.820302963256836, 239.8998260498047, 24.817792892456055, 240.51055908203125, 40.00777053833008, 201.63096618652344, 40.06538391113281], [259.2837219238281, 24.979761123657227, 295.3412780761719, 24.912456512451172, 295.499267578125, 40.93314743041992, 259.46875, 41.0597038269043], [324.84490966796875, 25.06061363220215, 352.31378173828125, 24.937538146972656, 352.1299743652344, 40.6098747253418, 324.5789794921875, 40.850372314453125], [19.759246826171875, 43.01795196533203, 113.34478759765625, 42.81032180786133, 113.28692626953125, 58.85405349731445, 19.6841983795166, 59.077301025390625], [147.78749084472656, 41.97053909301758, 186.2505340576172, 41.92179870605469, 186.16128540039062, 60.08445739746094, 147.7388916015625, 60.23293685913086], [201.72164916992188, 42.2467041015625, 239.4956512451172, 42.248233795166016, 239.36732482910156, 57.9215202331543, 201.5347900390625, 58.05841827392578], [260.1635437011719, 42.601722717285156, 294.98992919921875, 42.57515335083008, 294.9012451171875, 58.725807189941406, 260.20648193359375, 58.83103561401367], [325.4668884277344, 43.47552490234375, 351.62921142578125, 43.37560272216797, 351.4233703613281, 58.69367980957031, 325.216796875, 58.835540771484375], [17.259414672851562, 61.346580505371094, 117.30838012695312, 61.391510009765625, 116.91519927978516, 77.27435302734375, 17.075847625732422, 77.33097839355469], [147.8004913330078, 60.734771728515625, 187.77105712890625, 60.81405258178711, 187.52557373046875, 78.11712646484375, 147.65296936035156, 78.2030258178711], [202.76214599609375, 61.21046447753906, 239.10650634765625, 61.31357192993164, 238.86842346191406, 76.37916564941406, 202.4485321044922, 76.49956512451172], [260.08221435546875, 61.3802604675293, 294.13031005859375, 61.427825927734375, 294.0430603027344, 77.30787658691406, 260.1399230957031, 77.3839111328125], [326.073486328125, 62.027374267578125, 351.823486328125, 61.99972152709961, 351.6172790527344, 77.16791534423828, 325.8056640625, 77.2824935913086], [22.546016693115234, 78.76058959960938, 115.20037078857422, 79.01286315917969, 114.78923797607422, 95.3654556274414, 22.27328872680664, 95.328125], [150.010986328125, 77.56190490722656, 186.1251220703125, 77.87555694580078, 185.60577392578125, 95.93988800048828, 149.50904846191406, 95.92536163330078], [202.93338012695312, 78.32875061035156, 240.6278533935547, 78.52232360839844, 240.20172119140625, 93.92353820800781, 202.3856964111328, 94.04389190673828], [259.9728088378906, 78.42684936523438, 293.83819580078125, 78.55169677734375, 293.7027893066406, 94.43096160888672, 259.9540100097656, 94.47012329101562], [326.45623779296875, 79.52989959716797, 350.3641052246094, 79.59561157226562, 350.1504821777344, 94.96216583251953, 326.22265625, 95.021728515625], [28.803327560424805, 96.73432922363281, 110.8338623046875, 97.00154876708984, 110.35033416748047, 113.23934936523438, 28.493274688720703, 113.30168914794922], [151.12509155273438, 94.88533020019531, 184.90528869628906, 95.27114868164062, 184.45571899414062, 113.02555084228516, 150.73280334472656, 113.04901885986328], [203.17555236816406, 95.92108154296875, 241.36224365234375, 96.17276000976562, 240.87518310546875, 111.35999298095703, 202.59295654296875, 111.51428985595703], [259.8492736816406, 96.0071792602539, 294.3057861328125, 96.22608947753906, 294.1304931640625, 111.5855712890625, 259.77398681640625, 111.64446258544922], [325.4111328125, 98.01475524902344, 349.1259765625, 98.07755279541016, 348.969970703125, 111.86831665039062, 325.27734375, 111.94654083251953], [30.150239944458008, 115.5923843383789, 106.22801971435547, 115.7431411743164, 105.72630310058594, 131.2559356689453, 29.854246139526367, 131.48876953125], [150.78919982910156, 113.6063461303711, 183.76246643066406, 113.86474609375, 183.4082489013672, 130.56434631347656, 150.53550720214844, 130.6955108642578], [202.75799560546875, 114.63661193847656, 240.3756103515625, 114.81969451904297, 239.9745635986328, 129.41073608398438, 202.32374572753906, 129.62567138671875], [259.1989440917969, 114.72872924804688, 294.9760437011719, 114.93421173095703, 294.842041015625, 129.6300811767578, 259.1883544921875, 129.72377014160156], [326.04425048828125, 116.85579681396484, 350.243896484375, 117.0369873046875, 350.10125732421875, 130.39637756347656, 325.92364501953125, 130.43408203125], [27.474132537841797, 134.0279998779297, 110.48754119873047, 134.14927673339844, 110.05738830566406, 148.9967498779297, 27.209733963012695, 149.21978759765625], [150.85401916503906, 132.2021942138672, 182.95213317871094, 132.4014129638672, 182.6376190185547, 148.55165100097656, 150.648193359375, 148.68629455566406], [202.8684539794922, 132.8095245361328, 237.54562377929688, 132.97613525390625, 237.29742431640625, 147.4308624267578, 202.6420440673828, 147.6585235595703], [259.1913146972656, 133.2115478515625, 295.751953125, 133.3964385986328, 295.6692199707031, 147.9803009033203, 259.2425842285156, 148.0974578857422], [324.205810546875, 135.57241821289062, 351.3150939941406, 135.78968811035156, 351.2347412109375, 148.87274169921875, 324.1680908203125, 148.86314392089844], [30.0147762298584, 150.9370574951172, 112.08710479736328, 151.07777404785156, 111.67611694335938, 166.4791717529297, 29.729248046875, 166.67739868164062], [152.13111877441406, 149.81919860839844, 185.16358947753906, 149.89291381835938, 184.78411865234375, 166.79608154296875, 151.85275268554688, 166.99557495117188], [204.49496459960938, 150.39942932128906, 239.04786682128906, 150.50021362304688, 238.75253295898438, 165.37283325195312, 204.16238403320312, 165.63937377929688], [259.93524169921875, 150.4010009765625, 296.9034118652344, 150.502685546875, 296.8099365234375, 165.58572387695312, 259.9400939941406, 165.7496795654297], [323.6069641113281, 152.7332305908203, 350.8670959472656, 152.896240234375, 350.79833984375, 166.11119079589844, 323.62274169921875, 166.0756378173828], [32.5412712097168, 168.67636108398438, 114.26155853271484, 168.83168029785156, 113.8542251586914, 185.6604766845703, 32.22219467163086, 185.82150268554688], [153.3533172607422, 168.29885864257812, 184.5426025390625, 168.52792358398438, 184.12197875976562, 185.927490234375, 153.01205444335938, 185.98419189453125], [206.7120361328125, 168.307861328125, 239.98226928710938, 168.41371154785156, 239.60433959960938, 183.3036346435547, 206.28273010253906, 183.54830932617188], [261.6434631347656, 168.23780822753906, 296.0940856933594, 168.36697387695312, 295.977294921875, 183.6400146484375, 261.5964660644531, 183.79794311523438], [325.52862548828125, 169.9776153564453, 349.64373779296875, 170.1380157470703, 349.5814208984375, 183.12118530273438, 325.6022644042969, 183.13844299316406], [32.69326400756836, 186.58355712890625, 116.05577850341797, 186.80514526367188, 115.4797134399414, 203.59652709960938, 32.26826095581055, 203.70120239257812], [152.7675018310547, 185.8518829345703, 187.56918334960938, 186.2158966064453, 187.11141967773438, 204.4582061767578, 152.38934326171875, 204.41224670410156], [207.6895751953125, 185.6238555908203, 242.64122009277344, 185.8170928955078, 242.15451049804688, 200.47450256347656, 207.20150756835938, 200.656982421875], [261.7055969238281, 185.59292602539062, 300.02947998046875, 185.7953643798828, 299.8966369628906, 200.96823120117188, 261.69036865234375, 201.0762481689453], [325.5967102050781, 187.41036987304688, 351.9095458984375, 187.69061279296875, 351.825927734375, 201.0743865966797, 325.6205139160156, 201.03013610839844], [28.86933135986328, 203.94093322753906, 117.0533676147461, 204.06097412109375, 116.60554504394531, 221.11070251464844, 28.448135375976562, 221.2569580078125], [151.3251495361328, 203.1078643798828, 193.90704345703125, 203.6356201171875, 193.4289093017578, 225.37440490722656, 150.9449005126953, 225.1250762939453], [206.6962890625, 203.03358459472656, 246.0234375, 203.22923278808594, 245.40444946289062, 218.82920837402344, 206.04649353027344, 218.98007202148438], [260.4706726074219, 203.63494873046875, 299.0133056640625, 203.87283325195312, 298.8810119628906, 219.75889587402344, 260.5023498535156, 219.75531005859375], [321.2824401855469, 204.69252014160156, 356.0981750488281, 204.98806762695312, 356.0198974609375, 220.33303833007812, 321.2466735839844, 220.21092224121094], [26.812196731567383, 219.86898803710938, 111.43795013427734, 220.12567138671875, 110.71499633789062, 236.85028076171875, 26.382404327392578, 236.80801391601562], [149.12066650390625, 218.7002716064453, 190.95091247558594, 219.22010803222656, 190.48382568359375, 239.48977661132812, 148.64141845703125, 239.30868530273438], [206.55682373046875, 218.953125, 244.9989013671875, 219.11105346679688, 244.38323974609375, 234.46746826171875, 205.9571533203125, 234.68125915527344], [260.3403625488281, 219.60073852539062, 297.866943359375, 219.7819061279297, 297.8060302734375, 235.7698974609375, 260.5165710449219, 235.8520965576172], [318.3760681152344, 220.68435668945312, 357.09710693359375, 220.9096221923828, 357.0699768066406, 236.99488830566406, 318.5380859375, 236.90711975097656], [20.496644973754883, 237.70433044433594, 113.6926040649414, 238.0107879638672, 113.00868225097656, 256.06671142578125, 20.081214904785156, 255.87301635742188], [147.21580505371094, 236.67579650878906, 189.61277770996094, 237.1195526123047, 189.2399139404297, 255.6763916015625, 146.68484497070312, 255.50355529785156], [205.30099487304688, 236.3137664794922, 244.37811279296875, 236.4507293701172, 243.9133758544922, 252.00863647460938, 204.7561798095703, 252.18850708007812], [259.8399353027344, 236.727294921875, 298.30645751953125, 236.926513671875, 298.32080078125, 252.40147399902344, 260.103759765625, 252.42959594726562], [320.6863098144531, 237.68218994140625, 355.31976318359375, 237.9605712890625, 355.2795104980469, 253.51055908203125, 320.8592529296875, 253.39132690429688], [9.670053482055664, 260.64923095703125, 123.45518493652344, 261.2735595703125, 122.9952163696289, 280.72894287109375, 9.432244300842285, 280.4143981933594], [144.48443603515625, 261.205078125, 192.4757537841797, 261.7498779296875, 192.32469177246094, 279.16436767578125, 144.24034118652344, 278.93377685546875], [201.2520751953125, 260.5758056640625, 246.07408142089844, 260.85980224609375, 245.61737060546875, 276.4698791503906, 200.6879119873047, 276.4698791503906], [257.9992980957031, 260.8434753417969, 301.0218811035156, 261.1109924316406, 301.11346435546875, 276.8946838378906, 258.2967834472656, 276.8623962402344], [318.4444274902344, 261.37408447265625, 358.4154357910156, 261.6097717285156, 358.4162902832031, 276.76141357421875, 318.69281005859375, 276.7245178222656], [15.205965995788574, 273.3135681152344, 118.6921615600586, 273.8813781738281, 118.75344848632812, 291.0320129394531, 15.006182670593262, 290.77667236328125], [143.86346435546875, 273.6345520019531, 190.87306213378906, 274.1493835449219, 190.91343688964844, 291.13677978515625, 143.84765625, 290.9415588378906], [201.47793579101562, 273.9206237792969, 242.4740447998047, 274.17657470703125, 241.9766387939453, 289.6853332519531, 200.80442810058594, 289.64910888671875], [258.99591064453125, 274.1917419433594, 297.7046203613281, 274.36785888671875, 297.6482238769531, 289.99725341796875, 259.0852355957031, 289.9828796386719], [317.8933410644531, 274.79052734375, 356.7556457519531, 274.8617248535156, 356.7833557128906, 289.8598937988281, 318.24371337890625, 289.88446044921875]], 'html': '<html><body><table><thead><tr><td>Methods</td><td>R</td><td>P</td><td>F</td><td>FPS</td></tr></thead><tbody><tr><td>SegLink [26]</td><td>70.0</td><td>86.0</td><td>77.0</td><td>8.9</td></tr><tr><td>PixelLink [4]</td><td>73.2</td><td>83.0</td><td>77.8</td><td>-</td></tr><tr><td>TextSnake [18]</td><td>73.9</td><td>83.2</td><td>78.3</td><td>1.1</td></tr><tr><td>TextField [37]</td><td>75.9</td><td>87.4</td><td>81.3</td><td>5.2</td></tr><tr><td>MSR[38]</td><td>76.7</td><td>87.4</td><td>81.7</td><td>-</td></tr><tr><td>FTSN [3]</td><td>77.1</td><td>87.6</td><td>82.0</td><td>-</td></tr><tr><td>LSE[30]</td><td>81.7</td><td>84.2</td><td>82.9</td><td>-</td></tr><tr><td>CRAFT [2]</td><td>78.2</td><td>88.2</td><td>82.9</td><td>8.6</td></tr><tr><td>MCN [16]</td><td>79</td><td>88</td><td>83</td><td>-</td></tr><tr><td>ATRR[35]</td><td>82.1</td><td>85.2</td><td>83.6</td><td>-</td></tr><tr><td>PAN [34]</td><td>83.8</td><td>84.4</td><td>84.1</td><td>30.2</td></tr><tr><td>DB[12]</td><td>79.2</td><td>91.5</td><td>84.9</td><td>32.0</td></tr><tr><td>DRRG [41]</td><td>82.30</td><td>88.05</td><td>85.08</td><td>-</td></tr><tr><td>Ours (SynText)</td><td>80.68</td><td>85.40</td><td>82.97</td><td>12.68</td></tr><tr><td>Ours (MLT-17)</td><td>84.54</td><td>86.62</td><td>85.57</td><td>12.31</td></tr></tbody></table></body></html>'}, 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [12, 360, 410, 716], 'res': {'cell_bbox': [[36.285423278808594, 7.422494411468506, 120.45590209960938, 7.534379959106445, 120.50920104980469, 21.121803283691406, 35.78128433227539, 20.998870849609375], [146.39816284179688, 6.236691474914551, 181.86721801757812, 6.220644950866699, 183.54940795898438, 21.815582275390625, 147.76657104492188, 22.08586883544922], [204.21731567382812, 5.472514629364014, 232.8430633544922, 5.454163551330566, 234.35728454589844, 21.741397857666016, 205.57138061523438, 22.0509090423584], [257.97027587890625, 5.737213134765625, 281.79718017578125, 5.705615997314453, 283.7135925292969, 20.139636993408203, 259.98828125, 20.404027938842773], [309.5661315917969, 5.743951797485352, 334.0520935058594, 5.764962673187256, 334.9576721191406, 20.066295623779297, 310.7884521484375, 20.13615608215332], [360.2051696777344, 6.001224517822266, 385.8355712890625, 6.019592761993408, 385.95184326171875, 20.494884490966797, 360.5616149902344, 20.57560920715332], [22.42711639404297, 27.098430633544922, 119.7431411743164, 26.756689071655273, 119.23863220214844, 41.63149642944336, 21.944198608398438, 41.81913375854492], [152.08091735839844, 24.659561157226562, 187.45840454101562, 24.73086929321289, 188.1002655029297, 43.03704071044922, 152.26695251464844, 42.930660247802734], [208.0348358154297, 24.752546310424805, 243.6358184814453, 24.751745223999023, 243.5220947265625, 41.251399993896484, 207.7349395751953, 41.32088088989258], [251.6757354736328, 25.499473571777344, 286.1298828125, 25.551788330078125, 286.4606018066406, 40.67621994018555, 251.8494873046875, 40.65455627441406], [306.6338806152344, 25.643091201782227, 339.0968322753906, 25.70968246459961, 339.1280212402344, 41.032344818115234, 306.79693603515625, 40.96977233886719], [359.2392272949219, 26.300771713256836, 390.72039794921875, 26.22594451904297, 390.6852722167969, 42.137962341308594, 359.2665710449219, 42.239559173583984], [30.19744300842285, 44.25946044921875, 119.74269104003906, 44.014381408691406, 119.79354858398438, 57.8848876953125, 30.226444244384766, 58.16462707519531], [153.002197265625, 41.80937194824219, 185.9923095703125, 41.91541290283203, 186.49844360351562, 60.34651184082031, 153.7005157470703, 60.295684814453125], [207.28599548339844, 41.76599884033203, 241.0735626220703, 41.77722930908203, 240.92465209960938, 58.23698806762695, 207.2686767578125, 58.43017578125], [254.19021606445312, 42.49884796142578, 286.3733215332031, 42.630558013916016, 286.38623046875, 57.511932373046875, 254.30239868164062, 57.479366302490234], [306.505126953125, 42.66230773925781, 338.56988525390625, 42.860435485839844, 338.4197692871094, 57.763668060302734, 306.4261169433594, 57.55796813964844], [358.3416748046875, 43.16223907470703, 389.99481201171875, 43.17436599731445, 389.9143371582031, 59.012611389160156, 358.18048095703125, 58.947723388671875], [31.41790199279785, 62.194313049316406, 123.16905975341797, 62.05781173706055, 122.75605010986328, 76.09066772460938, 31.23914909362793, 76.27458190917969], [155.37457275390625, 59.3648681640625, 186.61341857910156, 59.5679817199707, 186.75494384765625, 78.44019317626953, 155.65216064453125, 78.33750915527344], [209.54855346679688, 59.38275909423828, 240.70965576171875, 59.3636589050293, 240.38607788085938, 75.57691955566406, 209.3527374267578, 75.8777847290039], [254.4994659423828, 59.991905212402344, 285.4171142578125, 60.12184143066406, 285.3324279785156, 74.92545318603516, 254.4668426513672, 74.91020202636719], [306.44500732421875, 60.05768585205078, 336.9219970703125, 60.24137496948242, 336.758544921875, 75.12681579589844, 306.3419494628906, 74.94305419921875], [357.880126953125, 60.505374908447266, 387.3742370605469, 60.47499084472656, 387.27783203125, 76.28524780273438, 357.74053955078125, 76.32196044921875], [27.468704223632812, 78.5377426147461, 119.5970230102539, 78.55827331542969, 119.1155014038086, 93.43810272216797, 27.18109703063965, 93.61141204833984], [155.63539123535156, 76.20203399658203, 186.66456604003906, 76.45750427246094, 186.69911193847656, 95.11758422851562, 155.57814025878906, 95.10481262207031], [209.20960998535156, 76.15709686279297, 240.987548828125, 76.17681121826172, 240.69163513183594, 92.26066589355469, 208.98883056640625, 92.64360809326172], [254.3385772705078, 76.84210205078125, 286.6331481933594, 77.01805877685547, 286.4527587890625, 91.8974380493164, 254.2123565673828, 91.9500503540039], [306.7927551269531, 77.16926574707031, 337.1327209472656, 77.51299285888672, 336.8697509765625, 92.02342224121094, 306.5811767578125, 91.7735366821289], [360.6081848144531, 78.54499053955078, 385.5103759765625, 78.58696746826172, 385.4285888671875, 94.2911605834961, 360.5103759765625, 94.31251525878906], [19.90298080444336, 95.60383605957031, 122.01547241210938, 95.71246337890625, 121.59496307373047, 112.06427764892578, 19.630165100097656, 112.26863098144531], [156.24066162109375, 93.6199951171875, 187.67477416992188, 93.75891876220703, 187.54214477539062, 111.79722595214844, 155.94264221191406, 111.94319152832031], [209.61773681640625, 93.5753173828125, 241.64630126953125, 93.58355712890625, 241.38555908203125, 109.8885498046875, 209.373779296875, 110.35505676269531], [254.1304931640625, 94.1383285522461, 287.27459716796875, 94.25985717773438, 287.0369567871094, 109.41473388671875, 253.98385620117188, 109.57313537597656], [307.2367858886719, 94.537841796875, 337.4635925292969, 94.84545135498047, 337.17279052734375, 109.40071868896484, 306.9722595214844, 109.26031494140625], [358.9051513671875, 95.8011703491211, 385.46624755859375, 95.80899047851562, 385.38665771484375, 111.57740020751953, 358.81414794921875, 111.66289520263672], [24.559236526489258, 114.1902847290039, 118.63011932373047, 114.20915222167969, 118.2851333618164, 129.23561096191406, 24.260364532470703, 129.51034545898438], [156.6731414794922, 111.98225402832031, 186.72181701660156, 112.17321014404297, 186.54888916015625, 129.69488525390625, 156.3522491455078, 129.7993621826172], [210.12118530273438, 112.0450439453125, 240.4322052001953, 112.08304595947266, 240.18505859375, 127.84495544433594, 209.8623809814453, 128.285888671875], [254.29481506347656, 112.27803039550781, 285.9474182128906, 112.4296875, 285.7339782714844, 127.6949234008789, 254.15834045410156, 127.83705139160156], [306.0954284667969, 112.44538879394531, 336.8619689941406, 112.68710327148438, 336.6263427734375, 127.74945831298828, 305.8644714355469, 127.68382263183594], [355.17742919921875, 113.19001007080078, 386.65234375, 113.30540466308594, 386.5487060546875, 129.70199584960938, 354.9897766113281, 129.69253540039062], [26.81853485107422, 132.13555908203125, 121.2467041015625, 132.3424530029297, 120.96473693847656, 147.38125610351562, 26.523101806640625, 147.4451904296875], [155.96080017089844, 130.2698211669922, 188.0840301513672, 130.66758728027344, 187.98265075683594, 148.34765625, 155.75588989257812, 148.32887268066406], [209.98899841308594, 130.32225036621094, 240.26564025878906, 130.47003173828125, 240.08155822753906, 146.2017822265625, 209.7586212158203, 146.61968994140625], [254.29592895507812, 130.53204345703125, 285.97149658203125, 130.79800415039062, 285.7306213378906, 145.94882202148438, 254.0741729736328, 146.06082153320312], [305.4050598144531, 130.80172729492188, 337.0064697265625, 131.10791015625, 336.8152160644531, 146.34764099121094, 305.18585205078125, 146.25057983398438], [353.60516357421875, 131.4871368408203, 385.88818359375, 131.71434020996094, 385.7801513671875, 147.8212890625, 353.4273986816406, 147.75778198242188], [22.83954620361328, 150.6218719482422, 129.1835174560547, 150.8719940185547, 128.88290405273438, 166.330322265625, 22.55194664001465, 166.3306884765625], [155.96383666992188, 148.63009643554688, 189.15255737304688, 149.0399169921875, 189.0680694580078, 166.67352294921875, 155.7672119140625, 166.65911865234375], [210.23098754882812, 148.653564453125, 240.85980224609375, 148.85784912109375, 240.6442108154297, 164.74349975585938, 209.9919891357422, 165.11856079101562], [254.5501708984375, 148.8749237060547, 287.1718444824219, 149.1056671142578, 286.9343566894531, 164.15798950195312, 254.35134887695312, 164.2896728515625], [306.0564880371094, 149.08551025390625, 337.5482482910156, 149.38726806640625, 337.3466491699219, 164.27532958984375, 305.7973937988281, 164.2101287841797], [353.5728454589844, 149.83958435058594, 386.8167419433594, 150.1005096435547, 386.7277526855469, 165.94541931152344, 353.4575500488281, 165.8656768798828], [30.063810348510742, 167.66647338867188, 121.68605041503906, 167.68701171875, 121.41593170166016, 182.99093627929688, 29.727022171020508, 183.2004852294922], [156.9475555419922, 166.0070343017578, 189.05686950683594, 166.45420837402344, 189.0050506591797, 184.33114624023438, 156.78407287597656, 184.20994567871094], [210.9020538330078, 166.19920349121094, 241.183349609375, 166.43014526367188, 241.03668212890625, 182.14190673828125, 210.7647247314453, 182.3927459716797], [255.43240356445312, 166.21197509765625, 287.33660888671875, 166.50222778320312, 287.1443176269531, 181.48504638671875, 255.3190460205078, 181.49281311035156], [306.281005859375, 166.1468963623047, 338.3172912597656, 166.52850341796875, 338.1326904296875, 181.23304748535156, 306.0550842285156, 181.0651397705078], [353.9791259765625, 167.39820861816406, 389.3263854980469, 167.7330780029297, 389.2786865234375, 183.5009002685547, 353.98883056640625, 183.27890014648438], [30.3902645111084, 185.6690673828125, 121.89791870117188, 185.79678344726562, 121.47570037841797, 201.2940673828125, 30.04169273376465, 201.3894805908203], [157.104736328125, 183.75794982910156, 190.71426391601562, 184.33851623535156, 190.65536499023438, 201.68592834472656, 156.9608154296875, 201.49755859375], [210.93421936035156, 183.60691833496094, 242.544677734375, 183.887939453125, 242.34877014160156, 199.2286376953125, 210.77183532714844, 199.453857421875], [256.4974365234375, 183.82308959960938, 287.6432800292969, 184.16102600097656, 287.4307861328125, 198.9221649169922, 256.3257751464844, 198.9295196533203], [307.42108154296875, 184.10260009765625, 338.9630432128906, 184.61077880859375, 338.78302001953125, 198.9596710205078, 307.2034912109375, 198.72650146484375], [358.69927978515625, 186.37841796875, 386.9032897949219, 186.64544677734375, 386.8788146972656, 201.28062438964844, 358.7994689941406, 201.13961791992188], [28.90335464477539, 203.47097778320312, 123.34148406982422, 203.56349182128906, 122.9636459350586, 219.25733947753906, 28.57341194152832, 219.42259216308594], [159.15609741210938, 202.12107849121094, 192.58860778808594, 202.74465942382812, 192.56678771972656, 221.02850341796875, 158.94589233398438, 220.79978942871094], [212.28712463378906, 201.72531127929688, 243.1013946533203, 202.06570434570312, 242.87107849121094, 217.7368927001953, 212.0957489013672, 217.86541748046875], [257.78350830078125, 201.95828247070312, 288.43389892578125, 202.33724975585938, 288.221923828125, 216.8627471923828, 257.6288146972656, 216.79258728027344], [308.6285400390625, 202.20416259765625, 339.3149108886719, 202.79098510742188, 339.1656494140625, 216.8831329345703, 308.45050048828125, 216.56491088867188], [357.70172119140625, 203.90040588378906, 387.53594970703125, 204.23988342285156, 387.5077819824219, 218.75624084472656, 357.7644958496094, 218.5436553955078], [23.720693588256836, 219.71873474121094, 124.87129211425781, 219.91464233398438, 124.6711196899414, 236.4622039794922, 23.455785751342773, 236.55101013183594], [161.9409637451172, 218.3960723876953, 191.01632690429688, 219.1158905029297, 191.02621459960938, 239.3360595703125, 161.78634643554688, 239.04881286621094], [212.7271270751953, 218.618896484375, 243.37063598632812, 219.0283660888672, 243.05361938476562, 235.73341369628906, 212.43724060058594, 235.7926483154297], [258.0149230957031, 218.89151000976562, 289.5356140136719, 219.33425903320312, 289.19903564453125, 234.10043334960938, 257.76348876953125, 233.957275390625], [308.4171447753906, 219.27374267578125, 338.8658142089844, 219.8671112060547, 338.6505432128906, 234.38868713378906, 308.16943359375, 234.0274658203125], [356.85357666015625, 220.47543334960938, 390.8517150878906, 220.97752380371094, 390.8121032714844, 236.39739990234375, 356.8459777832031, 235.97845458984375], [17.628725051879883, 239.70556640625, 122.8242416381836, 239.95091247558594, 122.52867889404297, 256.4295654296875, 17.416156768798828, 256.3364562988281], [161.71612548828125, 237.1767578125, 191.11802673339844, 237.80203247070312, 191.1772003173828, 257.9814147949219, 161.62677001953125, 257.6913757324219], [211.7642059326172, 236.98709106445312, 244.0559539794922, 237.31370544433594, 243.7850799560547, 254.16859436035156, 211.53453063964844, 254.2226104736328], [256.9238586425781, 237.09715270996094, 290.3557434082031, 237.4551544189453, 290.04718017578125, 252.54489135742188, 256.70025634765625, 252.44696044921875], [307.01422119140625, 237.702392578125, 339.7403869628906, 238.15289306640625, 339.53997802734375, 252.98300170898438, 306.78289794921875, 252.68878173828125], [357.30914306640625, 238.9100799560547, 390.063720703125, 239.1593475341797, 390.0371398925781, 255.13165283203125, 357.3690185546875, 254.8636932373047], [17.779630661010742, 258.6816711425781, 128.52415466308594, 258.9937744140625, 128.1225128173828, 275.7886047363281, 17.542604446411133, 275.5694885253906], [162.08241271972656, 256.23809814453125, 192.4212188720703, 256.8341369628906, 192.45835876464844, 276.479248046875, 161.7987518310547, 276.20135498046875], [211.31478881835938, 255.88987731933594, 249.0355987548828, 256.203125, 248.73410034179688, 273.62158203125, 210.97317504882812, 273.67327880859375], [256.5799865722656, 255.97457885742188, 291.5391540527344, 256.2948913574219, 291.2751770019531, 271.8482666015625, 256.3579406738281, 271.7904357910156], [307.62725830078125, 256.2491760253906, 341.3979797363281, 256.7516784667969, 341.19415283203125, 271.8436279296875, 307.4203186035156, 271.529052734375], [359.41717529296875, 257.14300537109375, 388.40899658203125, 257.4435729980469, 388.4021911621094, 273.1570739746094, 359.5760803222656, 272.8807678222656], [15.2337064743042, 278.21563720703125, 128.99815368652344, 278.49755859375, 128.5677947998047, 293.84765625, 14.984126091003418, 293.6136779785156], [160.66795349121094, 276.4953308105469, 188.91879272460938, 277.0279846191406, 189.05357360839844, 294.4590759277344, 160.30287170410156, 294.2120056152344], [211.48703002929688, 275.7886657714844, 246.22381591796875, 275.99957275390625, 245.92715454101562, 291.64617919921875, 211.1219482421875, 291.7804260253906], [256.7247619628906, 275.2963562011719, 291.27978515625, 275.57379150390625, 291.0585021972656, 289.7170715332031, 256.6305236816406, 289.6956481933594], [307.522705078125, 275.12457275390625, 343.28765869140625, 275.578857421875, 343.0482482910156, 290.0420837402344, 307.2835998535156, 289.8178405761719], [359.6099548339844, 275.5776062011719, 388.5140075683594, 275.8541259765625, 388.5021057128906, 290.53314208984375, 359.7322082519531, 290.3768615722656], [44.51536560058594, 299.78704833984375, 108.3657455444336, 299.83782958984375, 108.08155822753906, 313.5824279785156, 44.13351058959961, 313.607421875], [160.39459228515625, 299.54248046875, 186.59158325195312, 299.78106689453125, 187.0976104736328, 313.361328125, 160.9273681640625, 313.3282165527344], [208.35882568359375, 298.7346496582031, 248.99874877929688, 298.685791015625, 249.26373291015625, 311.6849365234375, 208.79342651367188, 311.92486572265625], [253.85714721679688, 297.7810363769531, 293.21343994140625, 297.74456787109375, 293.5232849121094, 311.0216979980469, 254.43051147460938, 311.22869873046875], [306.1416015625, 297.74163818359375, 343.4081726074219, 297.7488708496094, 343.47637939453125, 311.1613464355469, 306.36676025390625, 311.302734375], [353.9109802246094, 298.0159912109375, 390.6549072265625, 297.78985595703125, 390.6542663574219, 311.2013854980469, 354.0141906738281, 311.4743347167969], [44.47532653808594, 315.0390930175781, 105.67305755615234, 315.2315368652344, 105.53296661376953, 330.37445068359375, 44.39646530151367, 330.2941589355469], [154.85337829589844, 314.10015869140625, 187.6738739013672, 314.40447998046875, 188.3096466064453, 330.23443603515625, 155.7605743408203, 330.2059326171875], [207.9571533203125, 313.702880859375, 247.21046447753906, 313.76275634765625, 247.3218231201172, 329.24395751953125, 208.29544067382812, 329.4185791015625], [254.2282257080078, 313.6083679199219, 291.0032653808594, 313.6017761230469, 291.1075134277344, 328.69049072265625, 254.64730834960938, 328.86578369140625], [305.12591552734375, 313.98773193359375, 341.4468994140625, 313.9635314941406, 341.5229797363281, 328.48724365234375, 305.3397521972656, 328.6434020996094], [353.73663330078125, 314.74627685546875, 391.3555908203125, 314.5265808105469, 391.38909912109375, 328.3132629394531, 354.0978088378906, 328.54290771484375], [43.153785705566406, 330.8858337402344, 104.05802154541016, 331.1070861816406, 104.5916748046875, 345.5789794921875, 43.330989837646484, 345.43731689453125], [151.83453369140625, 330.7428894042969, 189.3928680419922, 331.0130920410156, 190.90419006347656, 345.3375244140625, 153.16465759277344, 345.24755859375], [207.7955322265625, 330.86083984375, 246.1760711669922, 330.88623046875, 247.05494689941406, 344.8692626953125, 208.75729370117188, 344.9042053222656], [255.25746154785156, 330.7663269042969, 289.3519592285156, 330.7534484863281, 290.1021728515625, 344.61322021484375, 256.24346923828125, 344.651611328125], [305.8843994140625, 330.7574157714844, 341.0939636230469, 330.7154541015625, 341.3137512207031, 344.42462158203125, 306.19024658203125, 344.4768371582031], [355.0755615234375, 330.88275146484375, 392.20806884765625, 330.6521301269531, 392.2515563964844, 344.3205871582031, 355.5140686035156, 344.43499755859375]], 'html': '<html><body><table><thead><tr><td>Methods</td><td>Ext</td><td>R</td><td>P</td><td>F</td><td>FPS</td></tr></thead><tbody><tr><td>TextSnake [18]</td><td>Syn</td><td>85.3</td><td>67.9</td><td>75.6</td><td>-</td></tr><tr><td>CSE [17]</td><td>MLT</td><td>76.1</td><td>78.7</td><td>77.4</td><td>0.38</td></tr><tr><td>LOMO[40]</td><td>Syn</td><td>76.5</td><td>85.7</td><td>80.8</td><td>4.4</td></tr><tr><td>ATRR[35]</td><td>Sy-</td><td>80.2</td><td>80.1</td><td>80.1</td><td></td></tr><tr><td>SegLink++[28]</td><td>Syn</td><td>79.8</td><td>82.8</td><td>81.3</td><td></td></tr><tr><td>TextField [37]</td><td>Syn</td><td>79.8</td><td>83.0</td><td>81.4</td><td>6.0</td></tr><tr><td>MSR[38]</td><td>Syn</td><td>79.0</td><td>84.1</td><td>81.5</td><td>4.3</td></tr><tr><td>PSENet-1s [33]</td><td>MLT</td><td>79.7</td><td>84.8</td><td>82.2</td><td>3.9</td></tr><tr><td>DB [12]</td><td>Syn</td><td>80.2</td><td>86.9</td><td>83.4</td><td>22.0</td></tr><tr><td>CRAFT [2]</td><td>Syn</td><td>81.1</td><td>86.0</td><td>83.5</td><td></td></tr><tr><td>TextDragon [5]</td><td>MLT+</td><td>82.8</td><td>84.5</td><td>83.6</td><td></td></tr><tr><td>PAN [34]</td><td>Syn</td><td>81.2</td><td>86.4</td><td>83.7</td><td>39.8</td></tr><tr><td>ContourNet [36]</td><td>-</td><td>84.1</td><td>83.7</td><td>83.9</td><td>4.5</td></tr><tr><td>DRRG [41]</td><td>MLT</td><td>83.02</td><td>85.93</td><td>84.45</td><td>-</td></tr><tr><td>TextPerception[23]</td><td>Syn</td><td>81.9</td><td>87.5</td><td>84.6</td><td>-</td></tr><tr><td>Ours</td><td>·</td><td>80.57</td><td>87.66</td><td>83.97</td><td>12.08</td></tr><tr><td>Ours</td><td>Syn</td><td>81.45</td><td>87.81</td><td>84.51</td><td>12.15</td></tr><tr><td>Ours</td><td>MLT</td><td>83.608</td><td>86.45</td><td>85.00</td><td>12.21</td></tr></tbody></table></body></html>'}, 'img_idx': 0}\n",
      "{'type': 'table_caption', 'bbox': [494, 343, 785, 356], 'res': [{'text': '0RRA', 'confidence': 0.16573205590248108, 'text_region': [[637.0, 348.0], [753.0, 348.0], [753.0, 352.0], [637.0, 352.0]]}], 'img_idx': 0}\n",
      "{'type': 'table_caption', 'bbox': [69, 318, 706, 357], 'res': [{'text': 'Visualexperimentalresults.', 'confidence': 0.9943141937255859, 'text_region': [[78.0, 319.0], [241.0, 319.0], [241.0, 331.0], [78.0, 331.0]]}], 'img_idx': 0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from paddleocr import PPStructure,draw_structure_result,save_structure_res\n",
    "\n",
    "table_engine = PPStructure(show_log=True)\n",
    "\n",
    "save_folder = './output'\n",
    "img_path = '../data/ppocr_img/table/1.png'\n",
    "img = cv2.imread(img_path)\n",
    "result = table_engine(img)\n",
    "save_structure_res(result, save_folder, os.path.basename(img_path).split('.')[0])\n",
    "\n",
    "for line in result:\n",
    "    line.pop('img')\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "font_path = '../data/ppocr_img/fonts/simfang.ttf' # PaddleOCR下提供字体包\n",
    "image = Image.open(img_path).convert('RGB')\n",
    "im_show = draw_structure_result(image, result,font_path=font_path)\n",
    "im_show = Image.fromarray(im_show)\n",
    "im_show.save('result.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 版面分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/06/03 10:01:46] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/liangzhu/.paddleocr/whl/det/ch/ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/liangzhu/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir=None, cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir='/Users/liangzhu/.paddleocr/whl/table/ch_ppstructure_mobile_v2.0_SLANet_infer', merge_no_span_structure=True, table_char_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/table_structure_dict_ch.txt', layout_model_dir='/Users/liangzhu/.paddleocr/whl/layout/picodet_lcnet_x1_0_fgd_layout_cdla_infer', layout_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/layout_dict/layout_cdla_dict.txt', layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=False, ocr=False, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "{'type': 'text', 'bbox': [11, 729, 407, 847], 'res': '', 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [442, 754, 837, 847], 'res': '', 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [443, 705, 559, 719], 'res': '', 'img_idx': 0}\n",
      "{'type': 'figure', 'bbox': [10, 1, 841, 294], 'res': '', 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [70, 317, 707, 357], 'res': '', 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [160, 317, 797, 335], 'res': '', 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [453, 359, 822, 664], 'res': '', 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [12, 360, 410, 716], 'res': '', 'img_idx': 0}\n",
      "{'type': 'table_caption', 'bbox': [494, 343, 785, 356], 'res': '', 'img_idx': 0}\n",
      "{'type': 'table_caption', 'bbox': [69, 318, 706, 357], 'res': '', 'img_idx': 0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from paddleocr import PPStructure,save_structure_res\n",
    "\n",
    "table_engine = PPStructure(table=False, ocr=False, show_log=True)\n",
    "\n",
    "save_folder = './output'\n",
    "img_path = '../data/ppocr_img/table/1.png'\n",
    "img = cv2.imread(img_path)\n",
    "result = table_engine(img)\n",
    "save_structure_res(result, save_folder, os.path.basename(img_path).split('.')[0])\n",
    "\n",
    "for line in result:\n",
    "    line.pop('img')\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/06/03 10:01:51] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/liangzhu/.paddleocr/whl/det/ch/ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/liangzhu/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir=None, cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir='/Users/liangzhu/.paddleocr/whl/table/ch_ppstructure_mobile_v2.0_SLANet_infer', merge_no_span_structure=True, table_char_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/table_structure_dict_ch.txt', layout_model_dir='/Users/liangzhu/.paddleocr/whl/layout/picodet_lcnet_x1_0_fgd_layout_cdla_infer', layout_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/layout_dict/layout_cdla_dict.txt', layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=False, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m save_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/ppocr_img/recovery/UnrealText.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mocr_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(result):\n\u001b[1;32m     12\u001b[0m     save_structure_res(res, save_folder, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(img_path)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m], index)\n",
      "File \u001b[0;32m~/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/paddleocr.py:766\u001b[0m, in \u001b[0;36mPPStructure.__call__\u001b[0;34m(self, img, return_ocr_result_in_table, img_idx)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, return_ocr_result_in_table\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, img_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    765\u001b[0m     img \u001b[38;5;241m=\u001b[39m check_img(img)\n\u001b[0;32m--> 766\u001b[0m     res, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_ocr_result_in_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppstructure/predict_system.py:112\u001b[0m, in \u001b[0;36mStructureSystem.__call__\u001b[0;34m(self, img, return_ocr_result_in_table, img_idx)\u001b[0m\n\u001b[1;32m    110\u001b[0m ori_im \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout_predictor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     layout_res, elapse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayout_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     time_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m elapse\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppstructure/layout/predict_layout.py:73\u001b[0m, in \u001b[0;36mLayoutPredictor.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     71\u001b[0m ori_im \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     72\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m: img}\n\u001b[0;32m---> 73\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_op\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m img \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/data/imaug/__init__.py:56\u001b[0m, in \u001b[0;36mtransform\u001b[0;34m(data, ops)\u001b[0m\n\u001b[1;32m     54\u001b[0m     ops \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m ops:\n\u001b[0;32m---> 56\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/data/imaug/operators.py:192\u001b[0m, in \u001b[0;36mResize.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolys\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    190\u001b[0m     text_polys \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolys\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 192\u001b[0m img_resize, [ratio_h, ratio_w] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpolys\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[1;32m    194\u001b[0m     new_boxes \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/data/imaug/operators.py:181\u001b[0m, in \u001b[0;36mResize.resize_image\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresize_image\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    180\u001b[0m     resize_h, resize_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m--> 181\u001b[0m     ori_h, ori_w \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]  \u001b[38;5;66;03m# (h, w, c)\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     ratio_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(resize_h) \u001b[38;5;241m/\u001b[39m ori_h\n\u001b[1;32m    183\u001b[0m     ratio_w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(resize_w) \u001b[38;5;241m/\u001b[39m ori_w\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from paddleocr import PPStructure,save_structure_res\n",
    "\n",
    "ocr_engine = PPStructure(table=False, ocr=True, show_log=True)\n",
    "\n",
    "save_folder = './output'\n",
    "img_path = '../data/ppocr_img/recovery/UnrealText.pdf'\n",
    "\n",
    "result = ocr_engine(img_path)\n",
    "for index, res in enumerate(result):\n",
    "    save_structure_res(res, save_folder, os.path.basename(img_path).split('.')[0], index)\n",
    "\n",
    "for res in result:\n",
    "    for line in res:\n",
    "        line.pop('img')\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/05/30 16:40:34] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/liangzhu/.paddleocr/whl/det/ch/ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/liangzhu/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir=None, cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir='/home/liangzhu/.paddleocr/whl/table/ch_ppstructure_mobile_v2.0_SLANet_infer', merge_no_span_structure=True, table_char_dict_path='/home/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/table_structure_dict_ch.txt', layout_model_dir='/home/liangzhu/.paddleocr/whl/layout/picodet_lcnet_x1_0_fgd_layout_cdla_infer', layout_dict_path='/home/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/layout_dict/layout_cdla_dict.txt', layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=False, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/05/30 16:40:36] ppocr DEBUG: dt_boxes num : 21, elapsed : 0.2201228141784668\n",
      "[2024/05/30 16:40:39] ppocr DEBUG: rec_res num  : 21, elapsed : 2.9298131465911865\n",
      "[2024/05/30 16:40:39] ppocr DEBUG: dt_boxes num : 29, elapsed : 0.2060554027557373\n",
      "[2024/05/30 16:40:42] ppocr DEBUG: rec_res num  : 29, elapsed : 3.3720948696136475\n",
      "[2024/05/30 16:40:42] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.0906534194946289\n",
      "[2024/05/30 16:40:42] ppocr DEBUG: rec_res num  : 1, elapsed : 0.07851862907409668\n",
      "[2024/05/30 16:40:43] ppocr DEBUG: dt_boxes num : 9, elapsed : 0.12874937057495117\n",
      "[2024/05/30 16:40:43] ppocr DEBUG: rec_res num  : 9, elapsed : 0.5464837551116943\n",
      "[2024/05/30 16:40:43] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.0442197322845459\n",
      "[2024/05/30 16:40:43] ppocr DEBUG: rec_res num  : 5, elapsed : 0.1868422031402588\n",
      "[2024/05/30 16:40:43] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.05751824378967285\n",
      "[2024/05/30 16:40:43] ppocr DEBUG: rec_res num  : 0, elapsed : 1.6689300537109375e-06\n",
      "[2024/05/30 16:40:44] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.13388299942016602\n",
      "[2024/05/30 16:40:44] ppocr DEBUG: rec_res num  : 1, elapsed : 0.08951592445373535\n",
      "[2024/05/30 16:40:44] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.04571652412414551\n",
      "[2024/05/30 16:40:44] ppocr DEBUG: rec_res num  : 0, elapsed : 1.6689300537109375e-06\n",
      "[2024/05/30 16:40:44] ppocr DEBUG: dt_boxes num : 13, elapsed : 0.23818612098693848\n",
      "[2024/05/30 16:40:45] ppocr DEBUG: rec_res num  : 13, elapsed : 0.5829944610595703\n",
      "[2024/05/30 16:40:45] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.14008164405822754\n",
      "[2024/05/30 16:40:45] ppocr DEBUG: rec_res num  : 8, elapsed : 0.3674740791320801\n",
      "[2024/05/30 16:40:45] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.04163360595703125\n",
      "[2024/05/30 16:40:45] ppocr DEBUG: rec_res num  : 0, elapsed : 1.430511474609375e-06\n",
      "[2024/05/30 16:40:45] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.011198997497558594\n",
      "[2024/05/30 16:40:45] ppocr DEBUG: rec_res num  : 0, elapsed : 1.1920928955078125e-06\n",
      "{'type': 'text', 'bbox': [97, 789, 572, 1286], 'res': [{'text': 'Syntheticdatahasbeenacriticaltoolfortrainingscene', 'confidence': 0.9936355352401733, 'text_region': [[125.0, 791.0], [570.0, 792.0], [570.0, 808.0], [125.0, 807.0]]}, {'text': 'textdetectionandrecognitionmodels.Ontheonehand', 'confidence': 0.9934363961219788, 'text_region': [[102.0, 815.0], [569.0, 815.0], [569.0, 832.0], [102.0, 832.0]]}, {'text': 'syntheticwordimageshaveproventobeasuccessfulsub', 'confidence': 0.99535071849823, 'text_region': [[101.0, 838.0], [568.0, 837.0], [568.0, 856.0], [101.0, 857.0]]}, {'text': 'stituteforrealimagesintrainingscenetextrecognizers.On', 'confidence': 0.9977197647094727, 'text_region': [[101.0, 863.0], [570.0, 863.0], [570.0, 882.0], [101.0, 882.0]]}, {'text': 'theotherhand，however,scenetextdetectorsstillheavily', 'confidence': 0.9790904521942139, 'text_region': [[101.0, 887.0], [568.0, 887.0], [568.0, 904.0], [101.0, 904.0]]}, {'text': 'relyonalargeamountofmanuallyannotatedreal-worla', 'confidence': 0.9972066879272461, 'text_region': [[101.0, 910.0], [570.0, 910.0], [570.0, 930.0], [101.0, 930.0]]}, {'text': 'images，whichareexpensive.Inthispaper,weintroduce', 'confidence': 0.9872862696647644, 'text_region': [[101.0, 935.0], [570.0, 935.0], [570.0, 954.0], [101.0, 954.0]]}, {'text': 'UnrealText,anefficientimagesynthesismethodthatren-', 'confidence': 0.9885703325271606, 'text_region': [[101.0, 958.0], [570.0, 958.0], [570.0, 977.0], [101.0, 977.0]]}, {'text': 'dersrealisticimagesviaa3Dgraphicsengine.3Dsyn-', 'confidence': 0.9956387877464294, 'text_region': [[100.0, 981.0], [570.0, 982.0], [570.0, 1002.0], [100.0, 1001.0]]}, {'text': 'theticengineprovidesrealisticappearancebyrendering', 'confidence': 0.998952329158783, 'text_region': [[101.0, 1006.0], [571.0, 1006.0], [571.0, 1026.0], [101.0, 1026.0]]}, {'text': 'sceneandtextasawhole,andallowsforbettertextre-', 'confidence': 0.9816924333572388, 'text_region': [[101.0, 1032.0], [570.0, 1032.0], [570.0, 1048.0], [101.0, 1048.0]]}, {'text': 'gionproposalswithaccesstoprecisesceneinformation', 'confidence': 0.999375581741333, 'text_region': [[99.0, 1053.0], [569.0, 1052.0], [569.0, 1072.0], [99.0, 1073.0]]}, {'text': 'e.g.normalandevenobjectmeshes.Thecomprehensive', 'confidence': 0.9971789717674255, 'text_region': [[99.0, 1077.0], [570.0, 1075.0], [570.0, 1096.0], [99.0, 1098.0]]}, {'text': 'experimentsverifyitseffectivenessonbothscenetextde', 'confidence': 0.997951328754425, 'text_region': [[102.0, 1103.0], [569.0, 1103.0], [569.0, 1119.0], [102.0, 1119.0]]}, {'text': 'tectionandrecognition.Wealsogenerateamultilingua', 'confidence': 0.9972924590110779, 'text_region': [[102.0, 1127.0], [569.0, 1127.0], [569.0, 1143.0], [102.0, 1143.0]]}, {'text': 'versionforfutureresearchintomultilingualscenetextde', 'confidence': 0.9979372024536133, 'text_region': [[100.0, 1149.0], [569.0, 1148.0], [569.0, 1168.0], [100.0, 1169.0]]}, {'text': 'tectionandrecognition.Additionally,were-annotatescene', 'confidence': 0.9898651242256165, 'text_region': [[102.0, 1174.0], [569.0, 1174.0], [569.0, 1191.0], [102.0, 1191.0]]}, {'text': 'textrecognitiondatasetsinacase-sensitivewayandin', 'confidence': 0.9983563423156738, 'text_region': [[102.0, 1199.0], [567.0, 1199.0], [567.0, 1215.0], [102.0, 1215.0]]}, {'text': 'cludepunctuationmarksformorecomprehensiveevalua-', 'confidence': 0.9888401031494141, 'text_region': [[101.0, 1221.0], [569.0, 1221.0], [569.0, 1240.0], [101.0, 1240.0]]}, {'text': 'tions.Thecodeandthegenerateddatasetsarereleasedat:', 'confidence': 0.9892204999923706, 'text_region': [[100.0, 1245.0], [570.0, 1245.0], [570.0, 1265.0], [100.0, 1265.0]]}, {'text': 'https://iyouhou.github.io/UnrealText/', 'confidence': 0.9783293008804321, 'text_region': [[101.0, 1270.0], [397.0, 1269.0], [397.0, 1285.0], [101.0, 1285.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [615, 743, 1091, 1419], 'res': [{'text': 'els are data-thirsty,and it is expensive and sometimes dif-', 'confidence': 0.9567070007324219, 'text_region': [[617.0, 743.0], [1088.0, 743.0], [1088.0, 762.0], [617.0, 763.0]]}, {'text': 'ficult,if not impossible,to collect enough data.More', 'confidence': 0.9733289480209351, 'text_region': [[619.0, 767.0], [1086.0, 767.0], [1086.0, 787.0], [619.0, 787.0]]}, {'text': 'over,the various applications,from traffic sign reading in', 'confidence': 0.9605211019515991, 'text_region': [[617.0, 790.0], [1090.0, 789.0], [1090.0, 809.0], [617.0, 810.0]]}, {'text': 'autonomous vehicles toinstant translation,require alarge', 'confidence': 0.975957989692688, 'text_region': [[617.0, 813.0], [1089.0, 814.0], [1089.0, 835.0], [617.0, 834.0]]}, {'text': 'amount ofdata specificallyfor eachdomain,further es-', 'confidence': 0.9742271900177002, 'text_region': [[618.0, 838.0], [1089.0, 838.0], [1089.0, 858.0], [618.0, 858.0]]}, {'text': 'calatingthisissue.Therefore,syntheticdataandsynthe', 'confidence': 0.9900727272033691, 'text_region': [[620.0, 864.0], [1085.0, 864.0], [1085.0, 881.0], [620.0, 881.0]]}, {'text': 'sis algorithms are important for scene text tasks.Further-', 'confidence': 0.9760555028915405, 'text_region': [[616.0, 886.0], [1089.0, 885.0], [1089.0, 906.0], [616.0, 907.0]]}, {'text': 'more,syntheticdatacanprovidedetailedannotations,such', 'confidence': 0.985406756401062, 'text_region': [[619.0, 912.0], [1090.0, 912.0], [1090.0, 929.0], [619.0, 929.0]]}, {'text': 'as character-levelor even pixel-levelground truths that are', 'confidence': 0.9590421319007874, 'text_region': [[617.0, 933.0], [1089.0, 934.0], [1089.0, 954.0], [617.0, 953.0]]}, {'text': 'rareforrealimagesduetohighcost.', 'confidence': 0.9980413317680359, 'text_region': [[618.0, 958.0], [910.0, 959.0], [909.0, 977.0], [618.0, 976.0]]}, {'text': 'Currently,thereexistseveralsynthesisalgorithms[46', 'confidence': 0.9906306266784668, 'text_region': [[644.0, 990.0], [1087.0, 990.0], [1087.0, 1008.0], [644.0, 1008.0]]}, {'text': '10,6,50] that have proven beneficial.Especially, in scene', 'confidence': 0.9561216831207275, 'text_region': [[620.0, 1013.0], [1090.0, 1013.0], [1090.0, 1033.0], [620.0, 1033.0]]}, {'text': 'textrecognition,training on synthetic data[10,6]alone', 'confidence': 0.9611268639564514, 'text_region': [[618.0, 1037.0], [1089.0, 1037.0], [1089.0, 1057.0], [618.0, 1057.0]]}, {'text': 'hasbecome awidely accepted standard practice.Some re-', 'confidence': 0.9597859382629395, 'text_region': [[617.0, 1059.0], [1088.0, 1060.0], [1088.0, 1080.0], [617.0, 1079.0]]}, {'text': 'searchers thatattempttrainingonbothsyntheticandreal', 'confidence': 0.9900434017181396, 'text_region': [[618.0, 1083.0], [1090.0, 1084.0], [1090.0, 1104.0], [618.0, 1103.0]]}, {'text': 'data only report marginal improvements[15,20]on most', 'confidence': 0.964549720287323, 'text_region': [[617.0, 1107.0], [1090.0, 1108.0], [1090.0, 1128.0], [617.0, 1127.0]]}, {'text': 'datasets.Mixing synthetic and real dataisonlyimproving', 'confidence': 0.9683577418327332, 'text_region': [[617.0, 1131.0], [1090.0, 1132.0], [1090.0, 1152.0], [617.0, 1151.0]]}, {'text': 'performance on a few difficult cases that are notyet well', 'confidence': 0.9468974471092224, 'text_region': [[617.0, 1156.0], [1090.0, 1154.0], [1090.0, 1175.0], [617.0, 1177.0]]}, {'text': 'coveredbyexistingsyntheticdatasets,suchasseriously', 'confidence': 0.9942065477371216, 'text_region': [[619.0, 1182.0], [1088.0, 1182.0], [1088.0, 1199.0], [619.0, 1199.0]]}, {'text': 'blurred or curved text.This is reasonable,since cropped', 'confidence': 0.978579580783844, 'text_region': [[617.0, 1203.0], [1089.0, 1205.0], [1089.0, 1225.0], [617.0, 1223.0]]}, {'text': 'textimageshave much simplerbackground,and synthetic', 'confidence': 0.9728232026100159, 'text_region': [[617.0, 1227.0], [1089.0, 1228.0], [1089.0, 1248.0], [617.0, 1247.0]]}, {'text': 'dataenjoys advantages inlargervocabularysize anddiver-', 'confidence': 0.9762839674949646, 'text_region': [[619.0, 1252.0], [1089.0, 1252.0], [1089.0, 1272.0], [619.0, 1272.0]]}, {'text': 'sityofbackgrounds,fonts,andlightingconditions,aswell', 'confidence': 0.9676303267478943, 'text_region': [[619.0, 1277.0], [1089.0, 1277.0], [1089.0, 1294.0], [619.0, 1294.0]]}, {'text': 'asthousandsoftimesmoredatasamples.', 'confidence': 0.9852449893951416, 'text_region': [[619.0, 1300.0], [944.0, 1300.0], [944.0, 1317.0], [619.0, 1317.0]]}, {'text': 'On the contrary,however,scene text detection is still', 'confidence': 0.954940140247345, 'text_region': [[642.0, 1329.0], [1090.0, 1328.0], [1090.0, 1349.0], [642.0, 1350.0]]}, {'text': 'heavily dependent onreal-world data.Synthetic data[6,50]', 'confidence': 0.9641885757446289, 'text_region': [[617.0, 1354.0], [1089.0, 1353.0], [1089.0, 1373.0], [617.0, 1374.0]]}, {'text': 'plays a less significant role,and onlybrings marginal im-', 'confidence': 0.9589750170707703, 'text_region': [[618.0, 1379.0], [1087.0, 1377.0], [1087.0, 1397.0], [618.0, 1399.0]]}, {'text': 'provements.', 'confidence': 0.9975360631942749, 'text_region': [[618.0, 1406.0], [715.0, 1404.0], [715.0, 1418.0], [618.0, 1418.0]]}, {'text': 'Existingsynthesizersforscenetextdetec', 'confidence': 0.9922289252281189, 'text_region': [[734.0, 1403.0], [1086.0, 1403.0], [1086.0, 1418.0], [734.0, 1418.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [99, 1354, 573, 1418], 'res': [{'text': 'gnition', 'confidence': 0.8951681852340698, 'text_region': [[335.0, 1405.0], [390.0, 1405.0], [390.0, 1415.0], [335.0, 1415.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [263, 293, 925, 370], 'res': [{'text': 'ShangbangLong', 'confidence': 0.9990793466567993, 'text_region': [[315.0, 293.0], [479.0, 296.0], [479.0, 317.0], [315.0, 313.0]]}, {'text': 'Cong', 'confidence': 0.9977192878723145, 'text_region': [[719.0, 294.0], [773.0, 298.0], [772.0, 315.0], [718.0, 311.0]]}, {'text': 'Yao', 'confidence': 0.9860513210296631, 'text_region': [[775.0, 295.0], [812.0, 295.0], [812.0, 312.0], [775.0, 312.0]]}, {'text': 'CarnegieMellonUniversity', 'confidence': 0.9965262413024902, 'text_region': [[265.0, 321.0], [528.0, 321.0], [528.0, 341.0], [265.0, 341.0]]}, {'text': 'Megvii(Face++)TechnologyInc', 'confidence': 0.9742061495780945, 'text_region': [[605.0, 321.0], [922.0, 321.0], [922.0, 341.0], [605.0, 341.0]]}, {'text': 'shanqbal@cs.', 'confidence': 0.9670384526252747, 'text_region': [[296.0, 354.0], [421.0, 354.0], [421.0, 366.0], [296.0, 366.0]]}, {'text': 'cmu.edu', 'confidence': 0.9778379797935486, 'text_region': [[418.0, 354.0], [497.0, 354.0], [497.0, 366.0], [418.0, 366.0]]}, {'text': 'yaocong2010@qmail', 'confidence': 0.9492907524108887, 'text_region': [[653.0, 354.0], [841.0, 353.0], [841.0, 366.0], [653.0, 368.0]]}, {'text': '.com', 'confidence': 0.9054859280586243, 'text_region': [[839.0, 354.0], [879.0, 354.0], [879.0, 368.0], [839.0, 368.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [34, 414, 75, 624], 'res': [{'text': '/', 'confidence': 0.16486865282058716, 'text_region': [[40.0, 437.0], [63.0, 437.0], [63.0, 449.0], [40.0, 449.0]]}, {'text': '2', 'confidence': 0.9736765623092651, 'text_region': [[39.0, 467.0], [72.0, 472.0], [66.0, 493.0], [34.0, 488.0]]}, {'text': '', 'confidence': 0.0, 'text_region': [[44.0, 498.0], [74.0, 498.0], [74.0, 526.0], [44.0, 526.0]]}, {'text': 'nH', 'confidence': 0.4164782762527466, 'text_region': [[44.0, 517.0], [72.0, 520.0], [65.0, 568.0], [37.0, 566.0]]}, {'text': '8', 'confidence': 0.9991405010223389, 'text_region': [[39.0, 583.0], [65.0, 583.0], [65.0, 601.0], [39.0, 601.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [101, 1313, 254, 1331], 'res': [], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [163, 214, 1060, 239], 'res': [{'text': '', 'confidence': 0.0, 'text_region': [[205.0, 223.0], [253.0, 223.0], [253.0, 229.0], [205.0, 229.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [292, 741, 380, 757], 'res': [], 'img_idx': 0}\n",
      "{'type': 'figure', 'bbox': [93, 438, 1101, 661], 'res': [{'text': 'MER', 'confidence': 0.9935159087181091, 'text_region': [[826.0, 493.0], [862.0, 493.0], [862.0, 513.0], [826.0, 513.0]]}, {'text': 'erat', 'confidence': 0.835880696773529, 'text_region': [[1018.0, 484.0], [1039.0, 484.0], [1039.0, 496.0], [1018.0, 496.0]]}, {'text': 'e', 'confidence': 0.3909769654273987, 'text_region': [[1022.0, 503.0], [1035.0, 503.0], [1035.0, 510.0], [1022.0, 510.0]]}, {'text': 'erat', 'confidence': 0.9207978248596191, 'text_region': [[865.0, 533.0], [895.0, 533.0], [895.0, 553.0], [865.0, 553.0]]}, {'text': 'Psz', 'confidence': 0.7967483401298523, 'text_region': [[137.0, 547.0], [174.0, 547.0], [174.0, 571.0], [137.0, 571.0]]}, {'text': 'ond', 'confidence': 0.9789198040962219, 'text_region': [[314.0, 557.0], [407.0, 563.0], [404.0, 604.0], [311.0, 598.0]]}, {'text': '$BP', 'confidence': 0.926555335521698, 'text_region': [[931.0, 549.0], [960.0, 549.0], [960.0, 563.0], [931.0, 563.0]]}, {'text': 're', 'confidence': 0.9491410851478577, 'text_region': [[836.0, 568.0], [851.0, 568.0], [851.0, 581.0], [836.0, 581.0]]}, {'text': 'der', 'confidence': 0.9961697459220886, 'text_region': [[864.0, 562.0], [895.0, 562.0], [895.0, 583.0], [864.0, 583.0]]}, {'text': 'Chee', 'confidence': 0.9961114525794983, 'text_region': [[132.0, 581.0], [173.0, 581.0], [173.0, 604.0], [132.0, 604.0]]}, {'text': '200-', 'confidence': 0.9896296262741089, 'text_region': [[131.0, 601.0], [166.0, 604.0], [164.0, 624.0], [129.0, 621.0]]}, {'text': 'HPIOIU', 'confidence': 0.32180458307266235, 'text_region': [[841.0, 607.0], [909.0, 607.0], [909.0, 614.0], [841.0, 614.0]]}, {'text': 'Dccllusior', 'confidence': 0.8808084726333618, 'text_region': [[898.0, 653.0], [956.0, 653.0], [956.0, 660.0], [898.0, 660.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [101, 676, 1087, 719], 'res': [{'text': 'Demonstration', 'confidence': 0.9981067180633545, 'text_region': [[182.0, 679.0], [302.0, 680.0], [302.0, 694.0], [182.0, 692.0]]}, {'text': '01', 'confidence': 0.5467937588691711, 'text_region': [[308.0, 683.0], [323.0, 683.0], [323.0, 692.0], [308.0, 692.0]]}, {'text': 'the', 'confidence': 0.9920535087585449, 'text_region': [[330.0, 681.0], [354.0, 681.0], [354.0, 691.0], [330.0, 691.0]]}, {'text': 'pIO', 'confidence': 0.56378573179245, 'text_region': [[362.0, 683.0], [389.0, 683.0], [389.0, 692.0], [362.0, 692.0]]}, {'text': 'lightingconditions', 'confidence': 0.9918478727340698, 'text_region': [[927.0, 679.0], [1086.0, 679.0], [1086.0, 696.0], [927.0, 696.0]]}, {'text': 'finds', 'confidence': 0.8551754951477051, 'text_region': [[102.0, 703.0], [137.0, 703.0], [137.0, 716.0], [102.0, 716.0]]}, {'text': 'Suitable', 'confidence': 0.8506238460540771, 'text_region': [[140.0, 706.0], [201.0, 706.0], [201.0, 715.0], [140.0, 715.0]]}, {'text': 'Witr', 'confidence': 0.49260756373405457, 'text_region': [[913.0, 706.0], [943.0, 706.0], [943.0, 715.0], [913.0, 715.0]]}], 'img_idx': 0}\n",
      "{'type': 'footer', 'bbox': [590, 1468, 598, 1482], 'res': [], 'img_idx': 0}\n",
      "{'type': 'footer', 'bbox': [591, 1468, 604, 1482], 'res': [], 'img_idx': 0}\n",
      "[2024/05/30 16:40:46] ppocr DEBUG: dt_boxes num : 41, elapsed : 0.36983323097229004\n",
      "[2024/05/30 16:40:51] ppocr DEBUG: rec_res num  : 41, elapsed : 5.065798997879028\n",
      "[2024/05/30 16:40:51] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.10762262344360352\n",
      "[2024/05/30 16:40:52] ppocr DEBUG: rec_res num  : 8, elapsed : 1.06773042678833\n",
      "[2024/05/30 16:40:52] ppocr DEBUG: dt_boxes num : 56, elapsed : 0.21168112754821777\n",
      "[2024/05/30 16:40:56] ppocr DEBUG: rec_res num  : 56, elapsed : 3.575716257095337\n",
      "[2024/05/30 16:40:56] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.05165743827819824\n",
      "[2024/05/30 16:40:56] ppocr DEBUG: rec_res num  : 1, elapsed : 0.0963432788848877\n",
      "[2024/05/30 16:40:56] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.055032968521118164\n",
      "[2024/05/30 16:40:56] ppocr DEBUG: rec_res num  : 1, elapsed : 0.07940912246704102\n",
      "{'type': 'text', 'bbox': [614, 447, 1091, 1427], 'res': [{'text': 'Thesynthesisofphoto-realisticdatasetshasbeen apop', 'confidence': 0.9921718239784241, 'text_region': [[642.0, 447.0], [1086.0, 448.0], [1086.0, 468.0], [642.0, 466.0]]}, {'text': 'ular topic,since theyprovide detailed ground-truth annota-', 'confidence': 0.9711161255836487, 'text_region': [[619.0, 471.0], [1087.0, 471.0], [1087.0, 492.0], [619.0, 492.0]]}, {'text': 'tions at multiple granularity, and cost less than manual an-', 'confidence': 0.9751049876213074, 'text_region': [[618.0, 495.0], [1088.0, 495.0], [1088.0, 515.0], [618.0, 515.0]]}, {'text': 'notations.Inscenetextdetection andrecognition,theuseof', 'confidence': 0.988031268119812, 'text_region': [[619.0, 521.0], [1089.0, 521.0], [1089.0, 538.0], [619.0, 538.0]]}, {'text': 'synthetic datasets hasbecome a standard practice.Forscene', 'confidence': 0.9723715782165527, 'text_region': [[617.0, 542.0], [1089.0, 542.0], [1089.0, 562.0], [617.0, 562.0]]}, {'text': 'textrecognition,whereimages containonlyoneword,syn', 'confidence': 0.9790769219398499, 'text_region': [[618.0, 566.0], [1086.0, 567.0], [1086.0, 585.0], [618.0, 584.0]]}, {'text': 'thetic images are rendered through several steps [46,10],', 'confidence': 0.9562551379203796, 'text_region': [[618.0, 590.0], [1088.0, 590.0], [1088.0, 610.0], [618.0, 610.0]]}, {'text': 'includingfontrendering,coloring,homographytransfor', 'confidence': 0.983715832233429, 'text_region': [[620.0, 615.0], [1086.0, 615.0], [1086.0, 633.0], [620.0, 633.0]]}, {'text': 'mation,and background blending.Later, GANs [5] are', 'confidence': 0.9684548377990723, 'text_region': [[618.0, 638.0], [1089.0, 638.0], [1089.0, 658.0], [618.0, 658.0]]}, {'text': 'incorporatedtomaintainstyleconsistencyforimplanted', 'confidence': 0.9990283846855164, 'text_region': [[619.0, 663.0], [1088.0, 663.0], [1088.0, 681.0], [619.0, 681.0]]}, {'text': 'text [51],but it is only for single-word images.As a re-', 'confidence': 0.96273273229599, 'text_region': [[617.0, 685.0], [1089.0, 686.0], [1089.0, 706.0], [617.0, 705.0]]}, {'text': 'sult of these progresses,synthetic data alone are enough to', 'confidence': 0.9634995460510254, 'text_region': [[618.0, 710.0], [1090.0, 710.0], [1090.0, 731.0], [618.0, 731.0]]}, {'text': 'trainstate-of-the-artrecognizers', 'confidence': 0.9919918179512024, 'text_region': [[618.0, 734.0], [876.0, 735.0], [876.0, 753.0], [618.0, 752.0]]}, {'text': 'To train scene text detectors,SynthText[6]proposes to', 'confidence': 0.9723915457725525, 'text_region': [[640.0, 757.0], [1090.0, 759.0], [1090.0, 780.0], [640.0, 778.0]]}, {'text': 'generate synthetic data by printing text on background im-', 'confidence': 0.9728776812553406, 'text_region': [[615.0, 782.0], [1089.0, 780.0], [1089.0, 804.0], [615.0, 806.0]]}, {'text': 'ages.It first analyzes images with off-the-shelf models, and', 'confidence': 0.9765520691871643, 'text_region': [[617.0, 807.0], [1090.0, 805.0], [1090.0, 826.0], [617.0, 828.0]]}, {'text': 'searchsuitabletextregionsonsemanticallyconsistentre-', 'confidence': 0.9909437894821167, 'text_region': [[618.0, 832.0], [1087.0, 832.0], [1087.0, 849.0], [618.0, 849.0]]}, {'text': 'gions.Text are implanted with perspective transformation', 'confidence': 0.967926561832428, 'text_region': [[617.0, 855.0], [1089.0, 853.0], [1089.0, 874.0], [617.0, 876.0]]}, {'text': 'basedonestimateddepth.Tomaintainsemanticcoherency', 'confidence': 0.9976725578308105, 'text_region': [[618.0, 879.0], [1088.0, 880.0], [1088.0, 898.0], [618.0, 897.0]]}, {'text': 'VISD[5O]proposestousesemanticsegmentationtofilter', 'confidence': 0.9722760915756226, 'text_region': [[619.0, 904.0], [1087.0, 904.0], [1087.0, 922.0], [619.0, 922.0]]}, {'text': 'outunreasonablesurfacessuchashumanfaces.Theyalso', 'confidence': 0.9978156685829163, 'text_region': [[619.0, 928.0], [1088.0, 928.0], [1088.0, 945.0], [619.0, 945.0]]}, {'text': 'adoptanadaptivecoloringschemetofitthetextintothe', 'confidence': 0.9987147450447083, 'text_region': [[619.0, 952.0], [1088.0, 952.0], [1088.0, 970.0], [619.0, 970.0]]}, {'text': 'artisticstyleofbackgrounds.However,withoutconsider', 'confidence': 0.993664562702179, 'text_region': [[618.0, 975.0], [1086.0, 975.0], [1086.0, 992.0], [618.0, 992.0]]}, {'text': 'ingthesceneasawhole,thesemethodsfail torendertext', 'confidence': 0.9781021475791931, 'text_region': [[618.0, 999.0], [1088.0, 998.0], [1088.0, 1016.0], [618.0, 1017.0]]}, {'text': 'instancesinaphoto-realisticway,andtextinstancesaretoo', 'confidence': 0.9845336079597473, 'text_region': [[620.0, 1024.0], [1088.0, 1024.0], [1088.0, 1038.0], [620.0, 1038.0]]}, {'text': 'outstandingfrombackgrounds.Sofar,thetrainingof de', 'confidence': 0.9879672527313232, 'text_region': [[620.0, 1047.0], [1086.0, 1047.0], [1086.0, 1065.0], [620.0, 1065.0]]}, {'text': 'tectorsstillreliesheavilyonrealimages.', 'confidence': 0.9957792162895203, 'text_region': [[618.0, 1072.0], [941.0, 1072.0], [941.0, 1089.0], [618.0, 1089.0]]}, {'text': 'AlthoughGANsandotherlearning-basedmethodshave', 'confidence': 0.9880929589271545, 'text_region': [[644.0, 1097.0], [1088.0, 1097.0], [1088.0, 1115.0], [644.0, 1115.0]]}, {'text': 'alsoshowngreatpotentialingeneratingrealisticim-', 'confidence': 0.9972710013389587, 'text_region': [[617.0, 1120.0], [1089.0, 1120.0], [1089.0, 1140.0], [617.0, 1140.0]]}, {'text': 'ages[48,17,12], the generation of scene text images still', 'confidence': 0.9684392213821411, 'text_region': [[618.0, 1143.0], [1090.0, 1143.0], [1090.0, 1164.0], [618.0, 1164.0]]}, {'text': 'require a large amount of manually labeled data[51].Fur', 'confidence': 0.9586287140846252, 'text_region': [[616.0, 1167.0], [1087.0, 1166.0], [1087.0, 1186.0], [616.0, 1187.0]]}, {'text': 'thermore,suchdata aresometimesnoteasytocollect,es-', 'confidence': 0.973879873752594, 'text_region': [[617.0, 1191.0], [1088.0, 1193.0], [1088.0, 1211.0], [617.0, 1209.0]]}, {'text': 'pecially for cases such as low resource languages.', 'confidence': 0.9870400428771973, 'text_region': [[616.0, 1214.0], [1016.0, 1214.0], [1016.0, 1237.0], [616.0, 1237.0]]}, {'text': 'More recently,synthesizing images with 3D graph-', 'confidence': 0.9568800926208496, 'text_region': [[640.0, 1239.0], [1087.0, 1240.0], [1087.0, 1262.0], [640.0, 1261.0]]}, {'text': 'ics engine has become popular in several fields,in-', 'confidence': 0.9390271306037903, 'text_region': [[616.0, 1265.0], [1087.0, 1265.0], [1087.0, 1285.0], [616.0, 1285.0]]}, {'text': 'cluding human pose estimation[43],scene understand-', 'confidence': 0.9761807322502136, 'text_region': [[618.0, 1288.0], [1088.0, 1288.0], [1088.0, 1309.0], [618.0, 1309.0]]}, {'text': 'ing/segmentation[28,24，33，35，37],andobjectdetec-', 'confidence': 0.9430881142616272, 'text_region': [[619.0, 1313.0], [1088.0, 1313.0], [1088.0, 1330.0], [619.0, 1330.0]]}, {'text': 'tion[29,42,8].However,thesemethodseitherconsider', 'confidence': 0.9864678978919983, 'text_region': [[618.0, 1337.0], [1088.0, 1337.0], [1088.0, 1355.0], [618.0, 1355.0]]}, {'text': 'simplistic cases, e.g. rendering 3D objects on top of static', 'confidence': 0.9903666377067566, 'text_region': [[616.0, 1359.0], [1090.0, 1359.0], [1090.0, 1382.0], [616.0, 1382.0]]}, {'text': 'background images[29,43]andrandomly arranging scenes', 'confidence': 0.9778026342391968, 'text_region': [[616.0, 1382.0], [1090.0, 1384.0], [1090.0, 1406.0], [616.0, 1403.0]]}, {'text': 'filled with objects[28,24,35,8],or passively use off-the-', 'confidence': 0.9431247115135193, 'text_region': [[617.0, 1406.0], [1087.0, 1407.0], [1087.0, 1426.0], [617.0, 1426.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [616, 150, 1089, 334], 'res': [{'text': 'tocarryoutcomprehensiveevaluations,andtendtoover', 'confidence': 0.9923098087310791, 'text_region': [[618.0, 153.0], [1086.0, 152.0], [1086.0, 168.0], [618.0, 169.0]]}, {'text': 'estimatetheprogressofscenetextrecognitionalgorithms', 'confidence': 0.994300901889801, 'text_region': [[618.0, 175.0], [1085.0, 174.0], [1085.0, 193.0], [618.0, 194.0]]}, {'text': 'Toaddress this issue,we re-annotate these datasets toin', 'confidence': 0.9518009424209595, 'text_region': [[617.0, 197.0], [1087.0, 198.0], [1087.0, 217.0], [617.0, 216.0]]}, {'text': 'cludebothupper-caseandlower-casecharacters,digits', 'confidence': 0.9936076402664185, 'text_region': [[618.0, 222.0], [1086.0, 221.0], [1086.0, 240.0], [618.0, 241.0]]}, {'text': 'punctuationmarks,andspacesifthereareany.Weurge', 'confidence': 0.9931068420410156, 'text_region': [[619.0, 247.0], [1087.0, 247.0], [1087.0, 266.0], [619.0, 266.0]]}, {'text': 'researcherstousethenewannotations andevaluateinsuch', 'confidence': 0.991569995880127, 'text_region': [[619.0, 269.0], [1088.0, 269.0], [1088.0, 288.0], [619.0, 288.0]]}, {'text': 'afull-symbolmodeforbetterunderstandingoftheadvan', 'confidence': 0.9875588417053223, 'text_region': [[621.0, 296.0], [1085.0, 296.0], [1085.0, 309.0], [621.0, 309.0]]}, {'text': 'tagesanddisadvantagesofdifferentalgorithms', 'confidence': 0.9957818388938904, 'text_region': [[620.0, 319.0], [994.0, 319.0], [994.0, 332.0], [620.0, 332.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 153, 574, 1419], 'res': [{'text': 'groundimages,e.g.byperformingsemanticsegmentation', 'confidence': 0.9943480491638184, 'text_region': [[101.0, 177.0], [573.0, 177.0], [573.0, 194.0], [101.0, 194.0]]}, {'text': 'pelc', 'confidence': 0.801597535610199, 'text_region': [[436.0, 276.0], [473.0, 276.0], [473.0, 285.0], [436.0, 285.0]]}, {'text': 'eptivetrans', 'confidence': 0.9947784543037415, 'text_region': [[475.0, 273.0], [567.0, 273.0], [567.0, 286.0], [475.0, 286.0]]}, {'text': 'off-the-shelf models', 'confidence': 0.9808704257011414, 'text_region': [[401.0, 318.0], [573.0, 318.0], [573.0, 335.0], [401.0, 335.0]]}, {'text': 'mayberoughandimprecis', 'confidence': 0.9991240501403809, 'text_region': [[99.0, 344.0], [324.0, 339.0], [324.0, 356.0], [100.0, 362.0]]}, {'text': 'nditionssuchas', 'confidence': 0.9976491928100586, 'text_region': [[444.0, 414.0], [571.0, 417.0], [571.0, 430.0], [444.0, 427.0]]}, {'text': 'illuminationandocclusions', 'confidence': 0.9759870767593384, 'text_region': [[102.0, 439.0], [317.0, 439.0], [317.0, 452.0], [102.0, 452.0]]}, {'text': 'Thesetwofactors', 'confidence': 0.9910637736320496, 'text_region': [[432.0, 440.0], [571.0, 440.0], [571.0, 454.0], [432.0, 454.0]]}, {'text': 'maketextinstancesou', 'confidence': 0.9942970275878906, 'text_region': [[101.0, 464.0], [279.0, 464.0], [279.0, 477.0], [101.0, 477.0]]}, {'text': 'ntheticenginethatsyn', 'confidence': 0.994598388671875, 'text_region': [[378.0, 514.0], [567.0, 516.0], [567.0, 530.0], [378.0, 529.0]]}, {'text': 'thesizesscenetextiimag', 'confidence': 0.9062683582305908, 'text_region': [[103.0, 541.0], [305.0, 541.0], [305.0, 550.0], [103.0, 550.0]]}, {'text': 'virtualworld', 'confidence': 0.9914243817329407, 'text_region': [[409.0, 538.0], [519.0, 538.0], [519.0, 551.0], [409.0, 551.0]]}, {'text': 'The', 'confidence': 0.997759997844696, 'text_region': [[539.0, 535.0], [572.0, 539.0], [570.0, 553.0], [537.0, 549.0]]}, {'text': 'mousUnrealEngine', 'confidence': 0.9862893223762512, 'text_region': [[386.0, 563.0], [562.0, 563.0], [562.0, 576.0], [386.0, 576.0]]}, {'text': '(/E4).andisthereforenar', 'confidence': 0.9101719260215759, 'text_region': [[106.0, 588.0], [316.0, 588.0], [316.0, 597.0], [106.0, 597.0]]}, {'text': 'ealText.Specifically', 'confidence': 0.9716147184371948, 'text_region': [[409.0, 586.0], [567.0, 586.0], [567.0, 599.0], [409.0, 599.0]]}, {'text': 'polygonmesheswith', 'confidence': 0.9990872740745544, 'text_region': [[401.0, 612.0], [571.0, 609.0], [571.0, 624.0], [401.0, 627.0]]}, {'text': 'textforegroundsloadedastexture', 'confidence': 0.9845925569534302, 'text_region': [[101.0, 636.0], [368.0, 636.0], [368.0, 649.0], [101.0, 649.0]]}, {'text': 'hesemeshesareplacec', 'confidence': 0.9780465364456177, 'text_region': [[386.0, 636.0], [569.0, 636.0], [569.0, 649.0], [386.0, 649.0]]}, {'text': 'insuitablepositionsin3Dworld,andrenderedtogether', 'confidence': 0.9825212359428406, 'text_region': [[98.0, 657.0], [570.0, 658.0], [570.0, 675.0], [98.0, 674.0]]}, {'text': 'withthesceneasawhole', 'confidence': 0.9963310360908508, 'text_region': [[103.0, 683.0], [301.0, 683.0], [301.0, 696.0], [103.0, 696.0]]}, {'text': 'itsverynature，enjoyst', 'confidence': 0.9656389355659485, 'text_region': [[101.0, 735.0], [295.0, 735.0], [295.0, 748.0], [101.0, 748.0]]}, {'text': 'sarerenderedtogether', 'confidence': 0.9826129078865051, 'text_region': [[385.0, 757.0], [570.0, 757.0], [570.0, 774.0], [385.0, 774.0]]}, {'text': 'illumination,occlu', 'confidence': 0.9557970762252808, 'text_region': [[410.0, 782.0], [569.0, 782.0], [569.0, 795.0], [410.0, 795.0]]}, {'text': 'sion,andperspectivet', 'confidence': 0.9691599607467651, 'text_region': [[102.0, 807.0], [285.0, 807.0], [285.0, 820.0], [102.0, 820.0]]}, {'text': 'ormation.（2)Themethodhas', 'confidence': 0.9495970606803894, 'text_region': [[327.0, 806.0], [570.0, 806.0], [570.0, 819.0], [327.0, 819.0]]}, {'text': 'accesstoprecisescenein', 'confidence': 0.9968963861465454, 'text_region': [[101.0, 831.0], [301.0, 828.0], [301.0, 843.0], [101.0, 845.0]]}, {'text': 'nation,e.g.normal,depth,and', 'confidence': 0.9678816795349121, 'text_region': [[329.0, 828.0], [571.0, 827.0], [571.0, 845.0], [329.0, 847.0]]}, {'text': 'objectmeshes,andthere', 'confidence': 0.9740743041038513, 'text_region': [[102.0, 855.0], [295.0, 855.0], [295.0, 868.0], [102.0, 868.0]]}, {'text': 'ngeneratebettertextregion', 'confidence': 0.9939001202583313, 'text_region': [[352.0, 852.0], [571.0, 853.0], [571.0, 870.0], [352.0, 869.0]]}, {'text': 'Iintrainingdetectors', 'confidence': 0.9829656481742859, 'text_region': [[381.0, 878.0], [551.0, 878.0], [551.0, 891.0], [381.0, 891.0]]}, {'text': 'threekeycomponents:', 'confidence': 0.9888296723365784, 'text_region': [[101.0, 928.0], [289.0, 928.0], [289.0, 946.0], [101.0, 946.0]]}, {'text': 'viewfindingalgorithmthat', 'confidence': 0.9985561966896057, 'text_region': [[348.0, 927.0], [573.0, 927.0], [573.0, 944.0], [348.0, 944.0]]}, {'text': 'generatescameraviewpoints', 'confidence': 0.9949117302894592, 'text_region': [[343.0, 953.0], [570.0, 953.0], [570.0, 967.0], [343.0, 967.0]]}, {'text': 'toobtainmorediverseand', 'confidence': 0.9954816699028015, 'text_region': [[102.0, 976.0], [310.0, 976.0], [310.0, 989.0], [102.0, 989.0]]}, {'text': 'ralbackgrounds.(2)Anen-', 'confidence': 0.9725193381309509, 'text_region': [[352.0, 973.0], [570.0, 975.0], [570.0, 993.0], [352.0, 992.0]]}, {'text': 'dulethatchangesthelighting', 'confidence': 0.9816672205924988, 'text_region': [[335.0, 1000.0], [571.0, 1000.0], [571.0, 1017.0], [335.0, 1017.0]]}, {'text': 'conditionsregularly,to', 'confidence': 0.9768918752670288, 'text_region': [[102.0, 1025.0], [290.0, 1025.0], [290.0, 1038.0], [102.0, 1038.0]]}, {'text': 'real-worldvariations.(3)', 'confidence': 0.9901213049888611, 'text_region': [[370.0, 1023.0], [571.0, 1023.0], [571.0, 1041.0], [370.0, 1041.0]]}, {'text': 'Amesn-based', 'confidence': 0.9100568294525146, 'text_region': [[105.0, 1051.0], [217.0, 1051.0], [217.0, 1060.0], [105.0, 1060.0]]}, {'text': 'methodthatfindssuit', 'confidence': 0.9981606006622314, 'text_region': [[390.0, 1047.0], [567.0, 1047.0], [567.0, 1064.0], [390.0, 1064.0]]}, {'text': 'the3Dmeshes', 'confidence': 0.998483419418335, 'text_region': [[368.0, 1071.0], [489.0, 1071.0], [489.0, 1088.0], [368.0, 1088.0]]}, {'text': 'Thecontributions', 'confidence': 0.9918795824050903, 'text_region': [[128.0, 1099.0], [268.0, 1099.0], [268.0, 1112.0], [128.0, 1112.0]]}, {'text': 'raresummarizedasfol-', 'confidence': 0.9842391014099121, 'text_region': [[374.0, 1097.0], [570.0, 1097.0], [570.0, 1114.0], [374.0, 1114.0]]}, {'text': 'sfrom3Dworld,whichis', 'confidence': 0.9670993089675903, 'text_region': [[363.0, 1145.0], [573.0, 1145.0], [573.0, 1162.0], [363.0, 1162.0]]}, {'text': 'hesthatembedtext', 'confidence': 0.9609078764915466, 'text_region': [[424.0, 1172.0], [571.0, 1172.0], [571.0, 1186.0], [424.0, 1186.0]]}, {'text': 'scalability.(2)With th', 'confidence': 0.9664728045463562, 'text_region': [[99.0, 1244.0], [287.0, 1241.0], [287.0, 1258.0], [100.0, 1261.0]]}, {'text': '，thesynthe', 'confidence': 0.9432082176208496, 'text_region': [[470.0, 1245.0], [567.0, 1245.0], [567.0, 1258.0], [470.0, 1258.0]]}, {'text': 'ceofdetectorsandrec', 'confidence': 0.9958251118659973, 'text_region': [[379.0, 1266.0], [567.0, 1269.0], [567.0, 1282.0], [379.0, 1279.0]]}, {'text': 'ognizerssignificantly.', 'confidence': 0.9723578095436096, 'text_region': [[102.0, 1291.0], [278.0, 1290.0], [278.0, 1304.0], [102.0, 1306.0]]}, {'text': 'largescale', 'confidence': 0.9689394235610962, 'text_region': [[483.0, 1291.0], [570.0, 1291.0], [570.0, 1304.0], [483.0, 1304.0]]}, {'text': 'multilingualscenetextdatasetthatwillaidfurtherresearch', 'confidence': 0.998737633228302, 'text_region': [[99.0, 1314.0], [569.0, 1312.0], [569.0, 1329.0], [99.0, 1331.0]]}, {'text': '（4)Additionally,wenoticethatmany', 'confidence': 0.9557244777679443, 'text_region': [[101.0, 1336.0], [397.0, 1337.0], [397.0, 1354.0], [101.0, 1353.0]]}, {'text': 'ofthepopularscene', 'confidence': 0.997204601764679, 'text_region': [[408.0, 1340.0], [571.0, 1340.0], [571.0, 1353.0], [408.0, 1353.0]]}, {'text': 'textrecognitiondatasetsareonlyannotatedinanincom-', 'confidence': 0.9974988102912903, 'text_region': [[101.0, 1362.0], [571.0, 1362.0], [571.0, 1379.0], [101.0, 1379.0]]}, {'text': 'pleteway,providingonlycase-insensitivewordannota', 'confidence': 0.9881135821342468, 'text_region': [[99.0, 1385.0], [569.0, 1383.0], [569.0, 1402.0], [99.0, 1403.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [617, 408, 818, 426], 'res': [{'text': '.SyntheticImage', 'confidence': 0.9704933166503906, 'text_region': [[644.0, 409.0], [808.0, 411.0], [807.0, 423.0], [643.0, 421.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [617, 367, 784, 385], 'res': [{'text': 'Reatedw', 'confidence': 0.809347927570343, 'text_region': [[645.0, 371.0], [745.0, 371.0], [745.0, 381.0], [645.0, 381.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:40:56] ppocr DEBUG: dt_boxes num : 21, elapsed : 0.16364455223083496\n",
      "[2024/05/30 16:40:59] ppocr DEBUG: rec_res num  : 21, elapsed : 2.3577804565429688\n",
      "[2024/05/30 16:40:59] ppocr DEBUG: dt_boxes num : 18, elapsed : 0.16676044464111328\n",
      "[2024/05/30 16:41:01] ppocr DEBUG: rec_res num  : 18, elapsed : 2.1329386234283447\n",
      "[2024/05/30 16:41:01] ppocr DEBUG: dt_boxes num : 33, elapsed : 0.24124646186828613\n",
      "[2024/05/30 16:41:05] ppocr DEBUG: rec_res num  : 33, elapsed : 3.4568607807159424\n",
      "[2024/05/30 16:41:05] ppocr DEBUG: dt_boxes num : 11, elapsed : 0.1303081512451172\n",
      "[2024/05/30 16:41:06] ppocr DEBUG: rec_res num  : 11, elapsed : 1.2923879623413086\n",
      "[2024/05/30 16:41:06] ppocr DEBUG: dt_boxes num : 10, elapsed : 0.12692618370056152\n",
      "[2024/05/30 16:41:07] ppocr DEBUG: rec_res num  : 10, elapsed : 1.2234470844268799\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.06970000267028809\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: rec_res num  : 1, elapsed : 0.19215178489685059\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.07375359535217285\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: rec_res num  : 2, elapsed : 0.14324069023132324\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.04822683334350586\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: rec_res num  : 0, elapsed : 1.9073486328125e-06\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.011335134506225586\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: rec_res num  : 0, elapsed : 9.5367431640625e-07\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.07971906661987305\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: rec_res num  : 2, elapsed : 0.2119596004486084\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.02121734619140625\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: rec_res num  : 1, elapsed : 0.0931544303894043\n",
      "[2024/05/30 16:41:08] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.021760940551757812\n",
      "[2024/05/30 16:41:09] ppocr DEBUG: rec_res num  : 1, elapsed : 0.10825991630554199\n",
      "{'type': 'text', 'bbox': [615, 282, 1091, 778], 'res': [{'text': 'Inthissection,wegiveadetailedintroductiontoour', 'confidence': 0.9894290566444397, 'text_region': [[642.0, 283.0], [1089.0, 285.0], [1089.0, 302.0], [642.0, 300.0]]}, {'text': 'scenetextimage synthesisengine,UnrealText,whichis de-', 'confidence': 0.9566996097564697, 'text_region': [[617.0, 307.0], [1088.0, 306.0], [1088.0, 326.0], [617.0, 327.0]]}, {'text': 'veloped uponUE4 and theUnrealCVplugin[31].The syn-', 'confidence': 0.9724214673042297, 'text_region': [[619.0, 328.0], [1087.0, 331.0], [1087.0, 351.0], [619.0, 348.0]]}, {'text': 'thesis engine:(1)produces photo-realistic images,(2)is', 'confidence': 0.9497570395469666, 'text_region': [[618.0, 353.0], [1090.0, 355.0], [1090.0, 375.0], [618.0, 373.0]]}, {'text': 'efficient,takingaboutonly1-1.5secondtorenderandgen', 'confidence': 0.9793722629547119, 'text_region': [[620.0, 379.0], [1086.0, 379.0], [1086.0, 395.0], [620.0, 395.0]]}, {'text': 'erate a new scene text image and,(3)is general and com-', 'confidence': 0.9439994096755981, 'text_region': [[617.0, 402.0], [1087.0, 400.0], [1087.0, 420.0], [617.0, 422.0]]}, {'text': 'patible tooff-the-shelf 3Dscenemodels.As shown inFig', 'confidence': 0.9698436260223389, 'text_region': [[618.0, 425.0], [1087.0, 425.0], [1087.0, 445.0], [618.0, 445.0]]}, {'text': '2,thepipelinemainly consistsof aViewfindermodule(sec-', 'confidence': 0.9784319400787354, 'text_region': [[618.0, 450.0], [1089.0, 450.0], [1089.0, 469.0], [618.0, 469.0]]}, {'text': 'tion3.2),anEnvironmentRandomizationmodule(section', 'confidence': 0.9868032336235046, 'text_region': [[619.0, 475.0], [1088.0, 475.0], [1088.0, 491.0], [619.0, 491.0]]}, {'text': '3.3),a TextRegionGenerationmodule(section3.4),and a', 'confidence': 0.9795436263084412, 'text_region': [[617.0, 497.0], [1090.0, 496.0], [1090.0, 515.0], [617.0, 516.0]]}, {'text': 'TextRenderingmodule(section3.5).', 'confidence': 0.9941313862800598, 'text_region': [[619.0, 521.0], [912.0, 521.0], [912.0, 541.0], [619.0, 541.0]]}, {'text': 'Firstly,theviewfindermoduleexploresaroundthe3D', 'confidence': 0.9921980500221252, 'text_region': [[643.0, 548.0], [1088.0, 548.0], [1088.0, 565.0], [643.0, 565.0]]}, {'text': 'scene with the camera,generating camera viewpoints.', 'confidence': 0.951730489730835, 'text_region': [[617.0, 570.0], [1087.0, 570.0], [1087.0, 592.0], [617.0, 592.0]]}, {'text': 'Then,theenvironmentlightingisrandomly adjusted.Next', 'confidence': 0.9837110042572021, 'text_region': [[617.0, 594.0], [1088.0, 595.0], [1088.0, 614.0], [617.0, 613.0]]}, {'text': 'thetextregions areproposedbasedon2Dsceneinforma-', 'confidence': 0.9891621470451355, 'text_region': [[618.0, 619.0], [1087.0, 619.0], [1087.0, 638.0], [618.0, 638.0]]}, {'text': 'tionandrefinedwith3Dmeshinformationinthegraph', 'confidence': 0.9989776015281677, 'text_region': [[619.0, 643.0], [1086.0, 643.0], [1086.0, 660.0], [619.0, 660.0]]}, {'text': 'ics engine.After that,textforegrounds aregeneratedwith', 'confidence': 0.9651387333869934, 'text_region': [[617.0, 666.0], [1089.0, 665.0], [1089.0, 684.0], [617.0, 685.0]]}, {'text': 'randomly sampled fonts,colors,and text content,and are', 'confidence': 0.9616730213165283, 'text_region': [[619.0, 691.0], [1089.0, 691.0], [1089.0, 710.0], [619.0, 710.0]]}, {'text': 'loaded asplanar meshes.Finally,weretrieve theRGBim-', 'confidence': 0.9754212498664856, 'text_region': [[618.0, 714.0], [1089.0, 714.0], [1089.0, 733.0], [618.0, 733.0]]}, {'text': 'age and correspondingtextlocations aswell as textcontent', 'confidence': 0.9692941308021545, 'text_region': [[617.0, 739.0], [1089.0, 737.0], [1089.0, 757.0], [617.0, 759.0]]}, {'text': 'tomakethesyntheticdataset', 'confidence': 0.9940095543861389, 'text_region': [[620.0, 764.0], [849.0, 764.0], [849.0, 777.0], [620.0, 777.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 149, 573, 573], 'res': [{'text': 'shelf 3D scenes without further changing it[33].In con-', 'confidence': 0.9589988589286804, 'text_region': [[100.0, 151.0], [571.0, 151.0], [571.0, 171.0], [100.0, 171.0]]}, {'text': 'trast to these researches,our proposed synthesis engine im-', 'confidence': 0.9613619446754456, 'text_region': [[100.0, 173.0], [569.0, 174.0], [569.0, 195.0], [100.0, 194.0]]}, {'text': 'plements active andregularinteractionwith3Dscenes,to', 'confidence': 0.9760196208953857, 'text_region': [[101.0, 198.0], [572.0, 198.0], [572.0, 218.0], [101.0, 218.0]]}, {'text': 'generaterealisticand diversescene textimages.', 'confidence': 0.9797775149345398, 'text_region': [[99.0, 222.0], [481.0, 221.0], [481.0, 242.0], [99.0, 243.0]]}, {'text': 'This paper is also a sequel to our previous attempt,the', 'confidence': 0.9338112473487854, 'text_region': [[124.0, 246.0], [571.0, 247.0], [571.0, 267.0], [124.0, 266.0]]}, {'text': 'SynthText3D[16].SynthText3Dcloselyfollowsthedesigns', 'confidence': 0.9982681274414062, 'text_region': [[102.0, 272.0], [569.0, 272.0], [569.0, 290.0], [102.0, 290.0]]}, {'text': 'oftheSynthTextmethod.WhileSynthTextusesoff-the', 'confidence': 0.9983221292495728, 'text_region': [[102.0, 296.0], [569.0, 296.0], [569.0, 313.0], [102.0, 313.0]]}, {'text': 'shelf computervisionmodels toestimatesegmentation and', 'confidence': 0.97575843334198, 'text_region': [[101.0, 319.0], [572.0, 319.0], [572.0, 340.0], [101.0, 340.0]]}, {'text': 'depthmaps forbackground images,SynthText3Duses the', 'confidence': 0.970633864402771, 'text_region': [[100.0, 343.0], [571.0, 342.0], [571.0, 362.0], [100.0, 363.0]]}, {'text': 'ground-truthsegmentationanddepthmapsprovidedbythe', 'confidence': 0.9987664222717285, 'text_region': [[102.0, 369.0], [570.0, 369.0], [570.0, 386.0], [102.0, 386.0]]}, {'text': '3D engines.The rendering process of SynthText3D does', 'confidence': 0.9921678900718689, 'text_region': [[100.0, 390.0], [572.0, 390.0], [572.0, 413.0], [100.0, 413.0]]}, {'text': 'notinvolveinteractionswiththe3Dworlds,suchastheob', 'confidence': 0.9948247075080872, 'text_region': [[100.0, 416.0], [569.0, 415.0], [569.0, 432.0], [100.0, 433.0]]}, {'text': 'jectmeshes.Asaresult,SynthText3Disfacedwithatleast', 'confidence': 0.9896115064620972, 'text_region': [[100.0, 439.0], [570.0, 438.0], [570.0, 456.0], [100.0, 457.0]]}, {'text': 'thesetwolimitations:(1)thecameralocations androtations', 'confidence': 0.9804987907409668, 'text_region': [[102.0, 463.0], [569.0, 463.0], [569.0, 480.0], [102.0, 480.0]]}, {'text': 'arelabeledbyhuman,limitingthescalabilityaswellas di', 'confidence': 0.9788020253181458, 'text_region': [[101.0, 487.0], [570.0, 487.0], [570.0, 505.0], [101.0, 505.0]]}, {'text': 'versity;(2)thegenerated textregions arelimited towell', 'confidence': 0.9678035378456116, 'text_region': [[100.0, 510.0], [572.0, 509.0], [572.0, 529.0], [100.0, 530.0]]}, {'text': 'definedregions that thecameraisfacingupfront,resulting', 'confidence': 0.9785799384117126, 'text_region': [[100.0, 533.0], [571.0, 534.0], [571.0, 555.0], [100.0, 554.0]]}, {'text': 'inaunfavorablelocationbias', 'confidence': 0.9910326600074768, 'text_region': [[101.0, 559.0], [334.0, 560.0], [333.0, 572.0], [101.0, 572.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 639, 573, 1426], 'res': [{'text': 'Scenetextdetectionandrecognition,possiblyasthe', 'confidence': 0.9860122799873352, 'text_region': [[126.0, 643.0], [570.0, 643.0], [570.0, 660.0], [126.0, 660.0]]}, {'text': 'most human-centric computer vision task,has been a pop-', 'confidence': 0.9555551409721375, 'text_region': [[100.0, 663.0], [570.0, 666.0], [570.0, 686.0], [100.0, 683.0]]}, {'text': 'ular research topic for manyyears[49,21].In scene text', 'confidence': 0.9577866792678833, 'text_region': [[101.0, 689.0], [572.0, 689.0], [572.0, 709.0], [101.0, 709.0]]}, {'text': 'detection,therearemainlytwobranchesofmethodolo', 'confidence': 0.9908364415168762, 'text_region': [[103.0, 716.0], [567.0, 716.0], [567.0, 730.0], [103.0, 730.0]]}, {'text': 'gies:Top-down methods that inherit theidea of region pro-', 'confidence': 0.9805653095245361, 'text_region': [[99.0, 736.0], [569.0, 735.0], [569.0, 758.0], [99.0, 759.0]]}, {'text': 'posalnetworksfromgeneralobjectdetectorsthatdetecttext', 'confidence': 0.9900856614112854, 'text_region': [[101.0, 761.0], [570.0, 760.0], [570.0, 780.0], [101.0, 781.0]]}, {'text': 'instancesasrotatedrectanglesandpolygons[19,53,11', 'confidence': 0.9810373187065125, 'text_region': [[102.0, 787.0], [568.0, 787.0], [568.0, 803.0], [102.0, 803.0]]}, {'text': '52, 47]; Bottom-up approaches that predict local segments', 'confidence': 0.9937021732330322, 'text_region': [[100.0, 807.0], [572.0, 807.0], [572.0, 830.0], [100.0, 830.0]]}, {'text': 'andlocalgeometricattributes,andcomposethemintoin', 'confidence': 0.9928199648857117, 'text_region': [[102.0, 834.0], [569.0, 834.0], [569.0, 851.0], [102.0, 851.0]]}, {'text': 'dividual text instances[38,22,2,40].Despite significant', 'confidence': 0.9726969003677368, 'text_region': [[100.0, 854.0], [571.0, 855.0], [571.0, 875.0], [100.0, 874.0]]}, {'text': 'improvements on individual datasets,those most widely', 'confidence': 0.9600815773010254, 'text_region': [[101.0, 880.0], [570.0, 880.0], [570.0, 900.0], [101.0, 900.0]]}, {'text': 'usedbenchmarkdatasets areusuallyvery small,with only', 'confidence': 0.9719941020011902, 'text_region': [[100.0, 903.0], [570.0, 904.0], [570.0, 923.0], [100.0, 922.0]]}, {'text': 'around500to1o00imagesintestsets,andaretherefore', 'confidence': 0.9719974398612976, 'text_region': [[102.0, 929.0], [570.0, 929.0], [570.0, 946.0], [102.0, 946.0]]}, {'text': 'pronetoover-fitting.Thegeneralization abilityacrossdif-', 'confidence': 0.9815088510513306, 'text_region': [[100.0, 953.0], [571.0, 951.0], [571.0, 970.0], [100.0, 973.0]]}, {'text': 'ferentdomainsremains an openquestion,andisnotstudied', 'confidence': 0.9822422862052917, 'text_region': [[100.0, 976.0], [571.0, 975.0], [571.0, 995.0], [100.0, 996.0]]}, {'text': 'yet.The reason lies in the very limited real data and that', 'confidence': 0.9361046552658081, 'text_region': [[99.0, 1000.0], [571.0, 997.0], [571.0, 1018.0], [99.0, 1021.0]]}, {'text': 'syntheticdata arenot effective enough.Therefore,oneim', 'confidence': 0.9736716151237488, 'text_region': [[99.0, 1025.0], [569.0, 1024.0], [569.0, 1043.0], [99.0, 1044.0]]}, {'text': 'portantmotivationofour synthesis engineis toserve as a', 'confidence': 0.959510087966919, 'text_region': [[100.0, 1048.0], [572.0, 1048.0], [572.0, 1068.0], [100.0, 1068.0]]}, {'text': 'steppingstonetowardsgeneralscenetextdetection.', 'confidence': 0.9968987107276917, 'text_region': [[101.0, 1073.0], [511.0, 1072.0], [511.0, 1090.0], [101.0, 1091.0]]}, {'text': 'Mostscene text recognitionmodels consist of CNN-', 'confidence': 0.9496617317199707, 'text_region': [[123.0, 1096.0], [570.0, 1095.0], [570.0, 1115.0], [123.0, 1116.0]]}, {'text': 'basedimagefeatureextractorsandattentionalLSTM[9]or', 'confidence': 0.9911537170410156, 'text_region': [[102.0, 1123.0], [571.0, 1123.0], [571.0, 1140.0], [102.0, 1140.0]]}, {'text': 'transformer[44]-basedencoder-decodertopredictthetex', 'confidence': 0.9914591908454895, 'text_region': [[102.0, 1147.0], [569.0, 1147.0], [569.0, 1163.0], [102.0, 1163.0]]}, {'text': 'tualcontent[3,39,15,23].Sincetheencoder-decodermod-', 'confidence': 0.9786654710769653, 'text_region': [[102.0, 1170.0], [570.0, 1170.0], [570.0, 1187.0], [102.0, 1187.0]]}, {'text': 'ule is alanguage modelin essence,scene text recognizers', 'confidence': 0.9639742970466614, 'text_region': [[100.0, 1192.0], [571.0, 1194.0], [571.0, 1214.0], [100.0, 1212.0]]}, {'text': 'haveahighdemandfortrainingdatawithalargevocabu', 'confidence': 0.9974770545959473, 'text_region': [[101.0, 1218.0], [568.0, 1218.0], [568.0, 1235.0], [101.0, 1235.0]]}, {'text': 'lary,whichisextremelydifficultforreal-worlddata.Be-', 'confidence': 0.9828553199768066, 'text_region': [[102.0, 1242.0], [570.0, 1242.0], [570.0, 1259.0], [102.0, 1259.0]]}, {'text': 'sides,scenetextrecognizerswork onimagecropsthathave', 'confidence': 0.9883050322532654, 'text_region': [[100.0, 1266.0], [571.0, 1266.0], [571.0, 1285.0], [100.0, 1285.0]]}, {'text': 'simplebackgrounds,which are easy to synthesize.There-', 'confidence': 0.9620903730392456, 'text_region': [[101.0, 1288.0], [570.0, 1288.0], [570.0, 1308.0], [101.0, 1308.0]]}, {'text': 'fore,syntheticdata are necessaryfor scene textrecogniz-', 'confidence': 0.9599218368530273, 'text_region': [[100.0, 1311.0], [569.0, 1312.0], [569.0, 1332.0], [100.0, 1331.0]]}, {'text': 'ers,andsyntheticdata alone areusuallyenough toachieve', 'confidence': 0.976181149482727, 'text_region': [[100.0, 1337.0], [571.0, 1334.0], [571.0, 1354.0], [100.0, 1356.0]]}, {'text': 'state-of-the-artperformance.Moreover,sincetherecogni', 'confidence': 0.9930986166000366, 'text_region': [[101.0, 1361.0], [569.0, 1361.0], [569.0, 1378.0], [101.0, 1378.0]]}, {'text': 'tionmodulesrequirealargeamountofdata,syntheticdata', 'confidence': 0.9840396046638489, 'text_region': [[102.0, 1385.0], [569.0, 1385.0], [569.0, 1401.0], [102.0, 1401.0]]}, {'text': 'arealsonecessaryintrainingend-to-endtextspottingsys-', 'confidence': 0.9832807779312134, 'text_region': [[100.0, 1409.0], [570.0, 1409.0], [570.0, 1425.0], [100.0, 1425.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [615, 846, 1089, 1104], 'res': [{'text': 'Theaimoftheviewfindermoduleistoautomaticallyde', 'confidence': 0.9912201166152954, 'text_region': [[643.0, 846.0], [1085.0, 847.0], [1085.0, 864.0], [643.0, 863.0]]}, {'text': 'termineasetofcameralocationsandrotationsfromthe', 'confidence': 0.9992229342460632, 'text_region': [[618.0, 868.0], [1088.0, 869.0], [1088.0, 889.0], [618.0, 888.0]]}, {'text': 'wholespace of 3Dscenes that arereasonableandnon-', 'confidence': 0.9557986855506897, 'text_region': [[619.0, 893.0], [1086.0, 893.0], [1086.0, 914.0], [619.0, 914.0]]}, {'text': 'trivial,gettingridofunsuitableviewpointssuchasfrom', 'confidence': 0.9947605729103088, 'text_region': [[620.0, 920.0], [1087.0, 920.0], [1087.0, 937.0], [620.0, 937.0]]}, {'text': 'inside object meshes (e.g.Fig.3 bottom right).', 'confidence': 0.9666495323181152, 'text_region': [[617.0, 941.0], [996.0, 942.0], [996.0, 962.0], [617.0, 961.0]]}, {'text': 'Learning-basedmethods such as navigation and explo', 'confidence': 0.9564380049705505, 'text_region': [[641.0, 967.0], [1085.0, 968.0], [1085.0, 988.0], [641.0, 987.0]]}, {'text': 'rationalgorithmsmayrequireextratrainingdata andare', 'confidence': 0.9903011322021484, 'text_region': [[618.0, 992.0], [1088.0, 992.0], [1088.0, 1012.0], [618.0, 1012.0]]}, {'text': 'notguaranteedtogeneralizetodifferent3Dscenes.There', 'confidence': 0.9969070553779602, 'text_region': [[619.0, 1016.0], [1084.0, 1016.0], [1084.0, 1033.0], [619.0, 1033.0]]}, {'text': 'fore,weturn torule-based methodsand designaphysically', 'confidence': 0.9672445058822632, 'text_region': [[617.0, 1037.0], [1085.0, 1039.0], [1085.0, 1059.0], [617.0, 1058.0]]}, {'text': 'constrained3Drandomwalk(Fig.3firstrow)equippec', 'confidence': 0.9750307202339172, 'text_region': [[619.0, 1063.0], [1087.0, 1063.0], [1087.0, 1083.0], [619.0, 1083.0]]}, {'text': 'withauxiliarycameraanchors.', 'confidence': 0.9828761219978333, 'text_region': [[617.0, 1086.0], [866.0, 1088.0], [866.0, 1103.0], [617.0, 1103.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [615, 1192, 1090, 1424], 'res': [{'text': 'Startingfrom a validlocation,thephysically-constrained', 'confidence': 0.979226291179657, 'text_region': [[617.0, 1192.0], [1089.0, 1193.0], [1089.0, 1214.0], [617.0, 1213.0]]}, {'text': '3Drandomwalkaimstofindthenextvalidandnon-trivial', 'confidence': 0.997186005115509, 'text_region': [[619.0, 1218.0], [1087.0, 1218.0], [1087.0, 1236.0], [619.0, 1236.0]]}, {'text': 'location.Incontrasttobeingvalid,locationsareinvalidif', 'confidence': 0.9885559678077698, 'text_region': [[618.0, 1242.0], [1089.0, 1242.0], [1089.0, 1259.0], [618.0, 1259.0]]}, {'text': 'theyareinsideobjectmeshesorfarawayfromthescene', 'confidence': 0.9946902990341187, 'text_region': [[619.0, 1267.0], [1087.0, 1267.0], [1087.0, 1284.0], [619.0, 1284.0]]}, {'text': 'boundary,forexample.Anon-triviallocationshouldbenoi', 'confidence': 0.9772503972053528, 'text_region': [[620.0, 1290.0], [1087.0, 1290.0], [1087.0, 1305.0], [620.0, 1305.0]]}, {'text': 'tooclosetothecurrentlocation.Otherwise,thenewview', 'confidence': 0.9888464212417603, 'text_region': [[620.0, 1314.0], [1085.0, 1314.0], [1085.0, 1329.0], [620.0, 1329.0]]}, {'text': 'point will be similar to the current one.The proposed 3D', 'confidence': 0.9487308859825134, 'text_region': [[618.0, 1336.0], [1089.0, 1336.0], [1089.0, 1357.0], [618.0, 1357.0]]}, {'text': 'randomwalkusesray-casting[36],whichisconstrainedby', 'confidence': 0.9954368472099304, 'text_region': [[619.0, 1361.0], [1087.0, 1361.0], [1087.0, 1378.0], [619.0, 1378.0]]}, {'text': 'physically,toinspectthephysicalenvironmenttodetermine', 'confidence': 0.994154155254364, 'text_region': [[617.0, 1384.0], [1089.0, 1383.0], [1089.0, 1403.0], [617.0, 1404.0]]}, {'text': 'validandnon-triviallocations', 'confidence': 0.9910788536071777, 'text_region': [[620.0, 1408.0], [855.0, 1410.0], [854.0, 1423.0], [620.0, 1423.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [617, 200, 960, 220], 'res': [{'text': 'Sceneeyfins)yirtalyor', 'confidence': 0.7860562205314636, 'text_region': [[641.0, 206.0], [946.0, 206.0], [946.0, 214.0], [641.0, 214.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [98, 601, 490, 620], 'res': [{'text': '', 'confidence': 0.0, 'text_region': [[255.0, 609.0], [289.0, 609.0], [289.0, 613.0], [255.0, 613.0]]}, {'text': 'andkecogh', 'confidence': 0.788995623588562, 'text_region': [[343.0, 607.0], [445.0, 607.0], [445.0, 615.0], [343.0, 615.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [617, 806, 758, 822], 'res': [], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [617, 243, 745, 258], 'res': [], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [617, 1151, 1032, 1169], 'res': [{'text': '2nvsicolv-', 'confidence': 0.39624062180519104, 'text_region': [[685.0, 1156.0], [770.0, 1157.0], [769.0, 1163.0], [685.0, 1162.0]]}, {'text': 'ned3llkandon', 'confidence': 0.6969340443611145, 'text_region': [[840.0, 1156.0], [975.0, 1156.0], [975.0, 1163.0], [840.0, 1163.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [616, 149, 745, 168], 'res': [{'text': 'tems18.7.30', 'confidence': 0.9517849087715149, 'text_region': [[617.0, 153.0], [738.0, 151.0], [738.0, 164.0], [617.0, 166.0]]}], 'img_idx': 0}\n",
      "{'type': 'header', 'bbox': [616, 149, 746, 168], 'res': [{'text': 'tems18.7.30', 'confidence': 0.9898025989532471, 'text_region': [[617.0, 153.0], [739.0, 151.0], [739.0, 163.0], [617.0, 165.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:41:09] ppocr DEBUG: dt_boxes num : 11, elapsed : 0.15764951705932617\n",
      "[2024/05/30 16:41:10] ppocr DEBUG: rec_res num  : 11, elapsed : 1.346665620803833\n",
      "[2024/05/30 16:41:10] ppocr DEBUG: dt_boxes num : 12, elapsed : 0.13647913932800293\n",
      "[2024/05/30 16:41:12] ppocr DEBUG: rec_res num  : 12, elapsed : 1.4502284526824951\n",
      "[2024/05/30 16:41:12] ppocr DEBUG: dt_boxes num : 12, elapsed : 0.08761477470397949\n",
      "[2024/05/30 16:41:13] ppocr DEBUG: rec_res num  : 12, elapsed : 1.4563062191009521\n",
      "[2024/05/30 16:41:13] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.10914134979248047\n",
      "[2024/05/30 16:41:14] ppocr DEBUG: rec_res num  : 5, elapsed : 0.6054129600524902\n",
      "[2024/05/30 16:41:14] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.045427560806274414\n",
      "[2024/05/30 16:41:15] ppocr DEBUG: rec_res num  : 8, elapsed : 0.9761631488800049\n",
      "[2024/05/30 16:41:15] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.09636330604553223\n",
      "[2024/05/30 16:41:15] ppocr DEBUG: rec_res num  : 1, elapsed : 0.14598727226257324\n",
      "[2024/05/30 16:41:16] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.16407275199890137\n",
      "[2024/05/30 16:41:16] ppocr DEBUG: rec_res num  : 8, elapsed : 0.8004906177520752\n",
      "[2024/05/30 16:41:16] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.07600736618041992\n",
      "[2024/05/30 16:41:16] ppocr DEBUG: rec_res num  : 0, elapsed : 1.6689300537109375e-06\n",
      "[2024/05/30 16:41:16] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.07569193840026855\n",
      "[2024/05/30 16:41:17] ppocr DEBUG: rec_res num  : 1, elapsed : 0.1544508934020996\n",
      "[2024/05/30 16:41:17] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.06737422943115234\n",
      "[2024/05/30 16:41:17] ppocr DEBUG: rec_res num  : 1, elapsed : 0.14267539978027344\n",
      "[2024/05/30 16:41:17] ppocr DEBUG: dt_boxes num : 7, elapsed : 0.1488945484161377\n",
      "[2024/05/30 16:41:17] ppocr DEBUG: rec_res num  : 7, elapsed : 0.3753855228424072\n",
      "[2024/05/30 16:41:18] ppocr DEBUG: dt_boxes num : 18, elapsed : 0.31276559829711914\n",
      "[2024/05/30 16:41:19] ppocr DEBUG: rec_res num  : 18, elapsed : 0.8769452571868896\n",
      "[2024/05/30 16:41:19] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.15964317321777344\n",
      "[2024/05/30 16:41:19] ppocr DEBUG: rec_res num  : 2, elapsed : 0.3242759704589844\n",
      "{'type': 'text', 'bbox': [615, 1169, 1089, 1426], 'res': [{'text': 'In real-world,text instances are usually embedded on', 'confidence': 0.9575284123420715, 'text_region': [[641.0, 1169.0], [1088.0, 1170.0], [1088.0, 1190.0], [641.0, 1189.0]]}, {'text': 'well-defined surfaces,e.g.traffic signs,to maintain good', 'confidence': 0.9696239829063416, 'text_region': [[618.0, 1192.0], [1088.0, 1194.0], [1088.0, 1215.0], [618.0, 1213.0]]}, {'text': 'legibility.Previous works find suitableregions byusing es', 'confidence': 0.9607348442077637, 'text_region': [[617.0, 1216.0], [1085.0, 1217.0], [1085.0, 1238.0], [617.0, 1237.0]]}, {'text': 'timatedsceneinformation,suchasgPb-UCM[1]inSyn', 'confidence': 0.983975887298584, 'text_region': [[619.0, 1241.0], [1083.0, 1241.0], [1083.0, 1258.0], [619.0, 1258.0]]}, {'text': 'thText[6]or saliencymapinVISD[50]for approxima', 'confidence': 0.9743220210075378, 'text_region': [[618.0, 1265.0], [1085.0, 1265.0], [1085.0, 1285.0], [618.0, 1285.0]]}, {'text': 'tion.However,thesemethods areimprecise andoftenfai', 'confidence': 0.9789891242980957, 'text_region': [[620.0, 1289.0], [1085.0, 1289.0], [1085.0, 1307.0], [620.0, 1307.0]]}, {'text': 'tofind appropriate regions.Therefore,we propose tofind', 'confidence': 0.9697489738464355, 'text_region': [[618.0, 1313.0], [1087.0, 1313.0], [1087.0, 1333.0], [618.0, 1333.0]]}, {'text': 'textregionsbyprobing aroundobject meshesin3Dworld', 'confidence': 0.9839849472045898, 'text_region': [[618.0, 1337.0], [1086.0, 1337.0], [1086.0, 1357.0], [618.0, 1357.0]]}, {'text': 'Sinceinspectingallobjectmeshesistime-consuming,we', 'confidence': 0.9888880848884583, 'text_region': [[620.0, 1362.0], [1087.0, 1362.0], [1087.0, 1379.0], [620.0, 1379.0]]}, {'text': 'propose a 2-stagedpipeline:(1)Weretrieveground truth', 'confidence': 0.9633115530014038, 'text_region': [[617.0, 1385.0], [1088.0, 1383.0], [1088.0, 1403.0], [617.0, 1405.0]]}, {'text': 'surfacenormalmaptogenerateinitialtextregionpropos-', 'confidence': 0.9939628839492798, 'text_region': [[618.0, 1409.0], [1087.0, 1409.0], [1087.0, 1425.0], [618.0, 1425.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 611, 573, 892], 'res': [{'text': 'Ineachstep,wefirstrandomlychangethepitch andyaw', 'confidence': 0.9848085045814514, 'text_region': [[124.0, 611.0], [572.0, 612.0], [572.0, 632.0], [124.0, 631.0]]}, {'text': 'values ofthe camerarotation,makingthecamerapointing', 'confidence': 0.9790816903114319, 'text_region': [[100.0, 634.0], [571.0, 635.0], [571.0, 655.0], [100.0, 654.0]]}, {'text': 'toanewdirection.Then,wecastarayfromthecameralo-', 'confidence': 0.9846833944320679, 'text_region': [[101.0, 661.0], [570.0, 661.0], [570.0, 677.0], [101.0, 677.0]]}, {'text': 'cation towards the direction of theviewpoint.Theraystops', 'confidence': 0.9641571640968323, 'text_region': [[99.0, 681.0], [572.0, 684.0], [572.0, 705.0], [99.0, 702.0]]}, {'text': 'whenithitsanyobjectmeshesorreachesafixedmaximum', 'confidence': 0.9980599284172058, 'text_region': [[102.0, 709.0], [571.0, 709.0], [571.0, 725.0], [102.0, 725.0]]}, {'text': 'length.By design,thepath from the current location to the', 'confidence': 0.9486616253852844, 'text_region': [[101.0, 731.0], [571.0, 730.0], [571.0, 750.0], [101.0, 751.0]]}, {'text': 'stopping position is free of any barrier,i.e.not inside of', 'confidence': 0.9500126838684082, 'text_region': [[100.0, 755.0], [572.0, 753.0], [572.0, 773.0], [100.0, 775.0]]}, {'text': 'anyobjectmeshes.Therefore,pointsalongthisraypathare', 'confidence': 0.9879547357559204, 'text_region': [[101.0, 781.0], [570.0, 781.0], [570.0, 797.0], [101.0, 797.0]]}, {'text': 'allvalid.Finally,werandomlysample onepointbetween', 'confidence': 0.979047954082489, 'text_region': [[100.0, 802.0], [572.0, 803.0], [572.0, 823.0], [100.0, 822.0]]}, {'text': 'the-th and 2-th of this path, and set it as the new location', 'confidence': 0.9428146481513977, 'text_region': [[98.0, 825.0], [572.0, 824.0], [572.0, 846.0], [98.0, 847.0]]}, {'text': 'of the camera,which is non-trivial.The proposed random', 'confidence': 0.9762333631515503, 'text_region': [[100.0, 850.0], [571.0, 851.0], [571.0, 872.0], [100.0, 871.0]]}, {'text': 'walkalgorithmcangeneratediversecameraviewpoints.', 'confidence': 0.9908724427223206, 'text_region': [[100.0, 872.0], [545.0, 873.0], [545.0, 891.0], [100.0, 891.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 970, 573, 1253], 'res': [{'text': 'The proposed random walk algorithm,however,is ineffi-', 'confidence': 0.9717671871185303, 'text_region': [[100.0, 971.0], [571.0, 970.0], [571.0, 991.0], [100.0, 992.0]]}, {'text': 'cientinterms ofexploration.Therefore,wemanuallyselect', 'confidence': 0.9882090091705322, 'text_region': [[101.0, 995.0], [570.0, 995.0], [570.0, 1014.0], [101.0, 1014.0]]}, {'text': 'a set of Ncamera anchors across the 3Dscenes as start-', 'confidence': 0.9399043321609497, 'text_region': [[99.0, 1018.0], [571.0, 1018.0], [571.0, 1038.0], [99.0, 1038.0]]}, {'text': 'ingpoints.AftereveryTsteps,weresetthelocation of', 'confidence': 0.9867523312568665, 'text_region': [[101.0, 1043.0], [572.0, 1043.0], [572.0, 1062.0], [101.0, 1062.0]]}, {'text': 'thecameratoarandomlysampled camera anchor.Weset', 'confidence': 0.9820062518119812, 'text_region': [[99.0, 1065.0], [572.0, 1066.0], [572.0, 1086.0], [99.0, 1085.0]]}, {'text': 'N=150-200 and T=100.Note that the selection of cam-', 'confidence': 0.981016993522644, 'text_region': [[100.0, 1089.0], [569.0, 1091.0], [569.0, 1110.0], [100.0, 1108.0]]}, {'text': 'eraanchorsrequiresonlylittlecarefulness.Weonlyneedto', 'confidence': 0.9961826801300049, 'text_region': [[102.0, 1115.0], [571.0, 1115.0], [571.0, 1132.0], [102.0, 1132.0]]}, {'text': 'ensure coverageover thespace.It takes around 20to30sec', 'confidence': 0.9665542244911194, 'text_region': [[100.0, 1139.0], [569.0, 1137.0], [569.0, 1157.0], [100.0, 1159.0]]}, {'text': 'ondsforeachscene,whichistrivialandnotabottleneckof', 'confidence': 0.9873598217964172, 'text_region': [[103.0, 1163.0], [572.0, 1163.0], [572.0, 1179.0], [103.0, 1179.0]]}, {'text': 'scalability.Themanualbutefficientselectionofcamerais', 'confidence': 0.9984011054039001, 'text_region': [[102.0, 1187.0], [572.0, 1187.0], [572.0, 1204.0], [102.0, 1204.0]]}, {'text': 'compatiblewiththeproposedrandomwalkalgorithmthat', 'confidence': 0.9995787739753723, 'text_region': [[101.0, 1211.0], [571.0, 1211.0], [571.0, 1230.0], [101.0, 1230.0]]}, {'text': 'generatesdiverseviewpoints.', 'confidence': 0.9905177354812622, 'text_region': [[100.0, 1234.0], [332.0, 1234.0], [332.0, 1252.0], [100.0, 1252.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [99, 1311, 573, 1426], 'res': [{'text': 'Toproducereal-worldvariationssuchaslightingcondi', 'confidence': 0.9987757802009583, 'text_region': [[125.0, 1312.0], [569.0, 1313.0], [569.0, 1331.0], [125.0, 1330.0]]}, {'text': 'tions,werandomlychangetheintensity,color,anddirection', 'confidence': 0.9743930697441101, 'text_region': [[102.0, 1337.0], [571.0, 1337.0], [571.0, 1355.0], [102.0, 1355.0]]}, {'text': 'ofalllightsourcesinthescene.In additiontoilluminations', 'confidence': 0.9904873967170715, 'text_region': [[102.0, 1360.0], [568.0, 1360.0], [568.0, 1378.0], [102.0, 1378.0]]}, {'text': 'wealsoaddfogconditionsandrandomlyadjustitsinten', 'confidence': 0.9991236925125122, 'text_region': [[102.0, 1384.0], [568.0, 1384.0], [568.0, 1402.0], [102.0, 1402.0]]}, {'text': 'sity.Theenvironmentrandomizationprovestoincreasethe', 'confidence': 0.9967427253723145, 'text_region': [[101.0, 1407.0], [570.0, 1408.0], [570.0, 1425.0], [101.0, 1425.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [615, 854, 1089, 992], 'res': [{'text': 'Figure3:', 'confidence': 0.9548588395118713, 'text_region': [[620.0, 857.0], [697.0, 858.0], [697.0, 870.0], [620.0, 869.0]]}, {'text': 'Inthefirstrow', 'confidence': 0.9906224012374878, 'text_region': [[721.0, 857.0], [862.0, 857.0], [862.0, 871.0], [721.0, 871.0]]}, {'text': '(l)-(4)，weillustratethe', 'confidence': 0.9064335227012634, 'text_region': [[856.0, 857.0], [1086.0, 857.0], [1086.0, 871.0], [856.0, 871.0]]}, {'text': 'physically-constrained3Drandomwalk.Forbettervisu-', 'confidence': 0.9883488416671753, 'text_region': [[618.0, 879.0], [1087.0, 878.0], [1087.0, 896.0], [618.0, 897.0]]}, {'text': 'alization,weuseacameraobjecttorepresenttheviewpoin', 'confidence': 0.9912073016166687, 'text_region': [[618.0, 902.0], [1086.0, 905.0], [1086.0, 922.0], [618.0, 920.0]]}, {'text': '(marked with greenboxes and arrows).In the second row', 'confidence': 0.9713111519813538, 'text_region': [[620.0, 927.0], [1087.0, 927.0], [1087.0, 946.0], [620.0, 946.0]]}, {'text': 'wecompareviewpointsfrom theproposed methodwithran-', 'confidence': 0.9719324707984924, 'text_region': [[617.0, 951.0], [1087.0, 949.0], [1087.0, 970.0], [617.0, 973.0]]}, {'text': 'domlysampledviewpoints', 'confidence': 0.9986838698387146, 'text_region': [[619.0, 976.0], [832.0, 976.0], [832.0, 991.0], [619.0, 991.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [615, 1043, 1091, 1109], 'res': [{'text': 'benefitsim-to-realdomainadaptation[41', 'confidence': 0.9881317615509033, 'text_region': [[619.0, 1092.0], [952.0, 1092.0], [952.0, 1107.0], [619.0, 1107.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [101, 524, 1088, 590], 'res': [{'text': 'Figure2:Thepipe', 'confidence': 0.9849924445152283, 'text_region': [[104.0, 527.0], [245.0, 528.0], [245.0, 543.0], [104.0, 541.0]]}, {'text': 'ee', 'confidence': 0.8017875552177429, 'text_region': [[242.0, 532.0], [279.0, 532.0], [279.0, 543.0], [242.0, 543.0]]}, {'text': 'SI', 'confidence': 0.6786649227142334, 'text_region': [[821.0, 533.0], [859.0, 533.0], [859.0, 540.0], [821.0, 540.0]]}, {'text': 'region.Fromleft to right:scene overview,diverseviewpoints,various lighting conditions (light color,intensity,shadows', 'confidence': 0.9678718447685242, 'text_region': [[101.0, 550.0], [1086.0, 550.0], [1086.0, 570.0], [101.0, 570.0]]}, {'text': 'C', 'confidence': 0.4160865247249603, 'text_region': [[105.0, 579.0], [122.0, 579.0], [122.0, 586.0], [105.0, 586.0]]}, {'text': 'lexl.', 'confidence': 0.6972202062606812, 'text_region': [[146.0, 579.0], [180.0, 579.0], [180.0, 586.0], [146.0, 586.0]]}, {'text': 'giongene', 'confidence': 0.9134933352470398, 'text_region': [[201.0, 578.0], [269.0, 578.0], [269.0, 588.0], [201.0, 588.0]]}, {'text': 'rationandtextrendering', 'confidence': 0.9955155849456787, 'text_region': [[275.0, 574.0], [469.0, 577.0], [469.0, 589.0], [275.0, 588.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [99, 1274, 409, 1291], 'res': [], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [99, 931, 389, 949], 'res': [{'text': 'AuxiliaryCameraAnchor', 'confidence': 0.9507082104682922, 'text_region': [[166.0, 934.0], [382.0, 935.0], [382.0, 945.0], [165.0, 944.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [636, 1130, 861, 1149], 'res': [{'text': '.TextRegionGenerat', 'confidence': 0.9532558917999268, 'text_region': [[643.0, 1133.0], [853.0, 1134.0], [853.0, 1146.0], [643.0, 1145.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure', 'bbox': [612, 604, 1087, 844], 'res': [{'text': 'ewpoin', 'confidence': 0.8791754841804504, 'text_region': [[688.0, 611.0], [726.0, 611.0], [726.0, 617.0], [688.0, 617.0]]}, {'text': '2)NewRotation', 'confidence': 0.9719170928001404, 'text_region': [[747.0, 608.0], [833.0, 608.0], [833.0, 620.0], [747.0, 620.0]]}, {'text': '(3)Ray Casting', 'confidence': 0.9567683339118958, 'text_region': [[866.0, 607.0], [948.0, 608.0], [947.0, 621.0], [866.0, 620.0]]}, {'text': '(4) New Location', 'confidence': 0.904271125793457, 'text_region': [[981.0, 608.0], [1070.0, 608.0], [1070.0, 620.0], [981.0, 620.0]]}, {'text': 'Viewpointfrom（1)', 'confidence': 0.9418922662734985, 'text_region': [[635.0, 737.0], [729.0, 738.0], [729.0, 750.0], [635.0, 749.0]]}, {'text': 'Viewpoint from(4)', 'confidence': 0.9291789531707764, 'text_region': [[799.0, 738.0], [898.0, 738.0], [898.0, 751.0], [799.0, 751.0]]}, {'text': 'RandomlySampledViewpoin', 'confidence': 0.9966123104095459, 'text_region': [[936.0, 738.0], [1086.0, 738.0], [1086.0, 751.0], [936.0, 751.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure', 'bbox': [125, 135, 1072, 509], 'res': [{'text': 'Viewfinding', 'confidence': 0.9973382949829102, 'text_region': [[348.0, 150.0], [424.0, 154.0], [423.0, 170.0], [348.0, 167.0]]}, {'text': 'Environment', 'confidence': 0.998048722743988, 'text_region': [[476.0, 146.0], [554.0, 146.0], [554.0, 159.0], [476.0, 159.0]]}, {'text': 'Text Region Generation', 'confidence': 0.9650243520736694, 'text_region': [[627.0, 152.0], [769.0, 153.0], [769.0, 169.0], [627.0, 168.0]]}, {'text': 'Randomization', 'confidence': 0.9969696402549744, 'text_region': [[469.0, 162.0], [562.0, 162.0], [562.0, 176.0], [469.0, 176.0]]}, {'text': 'Surface Normal Map', 'confidence': 0.9832969307899475, 'text_region': [[594.0, 245.0], [692.0, 245.0], [692.0, 258.0], [594.0, 258.0]]}, {'text': 'Initial Proposals', 'confidence': 0.9961233735084534, 'text_region': [[729.0, 246.0], [807.0, 246.0], [807.0, 259.0], [729.0, 259.0]]}, {'text': 'TextRendering', 'confidence': 0.9944563508033752, 'text_region': [[889.0, 242.0], [983.0, 245.0], [983.0, 262.0], [888.0, 259.0]]}, {'text': '3D Scene Model', 'confidence': 0.9555354714393616, 'text_region': [[176.0, 393.0], [275.0, 393.0], [275.0, 407.0], [176.0, 407.0]]}, {'text': 'Synthetic Images', 'confidence': 0.9938265681266785, 'text_region': [[896.0, 401.0], [979.0, 402.0], [979.0, 416.0], [895.0, 414.0]]}, {'text': 'Refining in 3D World & Polygon Mesh', 'confidence': 0.9908347129821777, 'text_region': [[606.0, 415.0], [791.0, 415.0], [791.0, 428.0], [606.0, 428.0]]}, {'text': '', 'confidence': 0.0, 'text_region': [[933.0, 416.0], [942.0, 416.0], [942.0, 429.0], [933.0, 429.0]]}, {'text': '▼', 'confidence': 0.32011091709136963, 'text_region': [[694.0, 450.0], [703.0, 450.0], [703.0, 460.0], [694.0, 460.0]]}, {'text': 'Font', 'confidence': 0.9953297972679138, 'text_region': [[785.0, 455.0], [817.0, 459.0], [815.0, 473.0], [783.0, 469.0]]}, {'text': 'Miranda)>jbsErti', 'confidence': 0.8990764617919922, 'text_region': [[866.0, 451.0], [1008.0, 451.0], [1008.0, 464.0], [866.0, 464.0]]}, {'text': 'Heights & Widths & Colors*', 'confidence': 0.9757017493247986, 'text_region': [[633.0, 465.0], [767.0, 465.0], [767.0, 479.0], [633.0, 479.0]]}, {'text': 'Stoney but\"', 'confidence': 0.8979348540306091, 'text_region': [[865.0, 462.0], [965.0, 462.0], [965.0, 482.0], [865.0, 482.0]]}, {'text': 'Rendering', 'confidence': 0.9934854507446289, 'text_region': [[768.0, 472.0], [836.0, 475.0], [836.0, 489.0], [767.0, 485.0]]}, {'text': 'actionsHdj.Bull', 'confidence': 0.9158624410629272, 'text_region': [[866.0, 480.0], [1000.0, 480.0], [1000.0, 492.0], [866.0, 492.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [101, 524, 996, 590], 'res': [{'text': '10ISF', 'confidence': 0.5267360806465149, 'text_region': [[798.0, 533.0], [863.0, 533.0], [863.0, 540.0], [798.0, 540.0]]}, {'text': 'etc.),textregiongenerationandtextrendering', 'confidence': 0.9848717451095581, 'text_region': [[103.0, 577.0], [469.0, 577.0], [469.0, 589.0], [103.0, 589.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:41:19] ppocr DEBUG: dt_boxes num : 13, elapsed : 0.17332005500793457\n",
      "[2024/05/30 16:41:21] ppocr DEBUG: rec_res num  : 13, elapsed : 1.5486154556274414\n",
      "[2024/05/30 16:41:21] ppocr DEBUG: dt_boxes num : 12, elapsed : 0.15260100364685059\n",
      "[2024/05/30 16:41:23] ppocr DEBUG: rec_res num  : 12, elapsed : 1.6766889095306396\n",
      "[2024/05/30 16:41:23] ppocr DEBUG: dt_boxes num : 11, elapsed : 0.15034914016723633\n",
      "[2024/05/30 16:41:24] ppocr DEBUG: rec_res num  : 11, elapsed : 1.3729984760284424\n",
      "[2024/05/30 16:41:24] ppocr DEBUG: dt_boxes num : 16, elapsed : 0.16849851608276367\n",
      "[2024/05/30 16:41:26] ppocr DEBUG: rec_res num  : 16, elapsed : 1.9338088035583496\n",
      "[2024/05/30 16:41:27] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.11595630645751953\n",
      "[2024/05/30 16:41:27] ppocr DEBUG: rec_res num  : 4, elapsed : 0.6680750846862793\n",
      "[2024/05/30 16:41:27] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.13588356971740723\n",
      "[2024/05/30 16:41:29] ppocr DEBUG: rec_res num  : 8, elapsed : 1.2170889377593994\n",
      "[2024/05/30 16:41:29] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.10453510284423828\n",
      "[2024/05/30 16:41:30] ppocr DEBUG: rec_res num  : 5, elapsed : 0.9608418941497803\n",
      "[2024/05/30 16:41:30] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.04400515556335449\n",
      "[2024/05/30 16:41:31] ppocr DEBUG: rec_res num  : 8, elapsed : 1.2591462135314941\n",
      "[2024/05/30 16:41:31] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.10161733627319336\n",
      "[2024/05/30 16:41:32] ppocr DEBUG: rec_res num  : 4, elapsed : 0.49358320236206055\n",
      "[2024/05/30 16:41:32] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.09682321548461914\n",
      "[2024/05/30 16:41:32] ppocr DEBUG: rec_res num  : 2, elapsed : 0.21130084991455078\n",
      "[2024/05/30 16:41:32] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.07929277420043945\n",
      "[2024/05/30 16:41:32] ppocr DEBUG: rec_res num  : 1, elapsed : 0.23069047927856445\n",
      "[2024/05/30 16:41:32] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.07502341270446777\n",
      "[2024/05/30 16:41:32] ppocr DEBUG: rec_res num  : 1, elapsed : 0.2184281349182129\n",
      "[2024/05/30 16:41:33] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.06778597831726074\n",
      "[2024/05/30 16:41:33] ppocr DEBUG: rec_res num  : 1, elapsed : 0.15898537635803223\n",
      "[2024/05/30 16:41:33] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.06110215187072754\n",
      "[2024/05/30 16:41:33] ppocr DEBUG: rec_res num  : 1, elapsed : 0.1414945125579834\n",
      "[2024/05/30 16:41:33] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.14963030815124512\n",
      "[2024/05/30 16:41:33] ppocr DEBUG: rec_res num  : 6, elapsed : 0.30065011978149414\n",
      "[2024/05/30 16:41:33] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.1073598861694336\n",
      "[2024/05/30 16:41:34] ppocr DEBUG: rec_res num  : 2, elapsed : 0.30758047103881836\n",
      "{'type': 'text', 'bbox': [99, 359, 573, 663], 'res': [{'text': 'In computergraphics,normalvalues areunit vectors that', 'confidence': 0.9691096544265747, 'text_region': [[100.0, 360.0], [571.0, 359.0], [571.0, 379.0], [100.0, 380.0]]}, {'text': 'are perpendicular to a surface.Therefore,when projected', 'confidence': 0.9804916977882385, 'text_region': [[99.0, 383.0], [571.0, 382.0], [571.0, 404.0], [99.0, 405.0]]}, {'text': 'to2Dscreen space,aregionwithsimilarnormalvalues', 'confidence': 0.9862127304077148, 'text_region': [[100.0, 407.0], [572.0, 406.0], [572.0, 426.0], [100.0, 427.0]]}, {'text': 'tendstobeawell-definedregiontoembedtexton.Wefind', 'confidence': 0.9952394962310791, 'text_region': [[101.0, 431.0], [571.0, 430.0], [571.0, 449.0], [101.0, 450.0]]}, {'text': 'valid image regions by applying sliding windows of 64× 64', 'confidence': 0.9639771580696106, 'text_region': [[101.0, 455.0], [572.0, 455.0], [572.0, 477.0], [101.0, 477.0]]}, {'text': 'pixels across the surface normal map, and retrieve those', 'confidence': 0.9775056838989258, 'text_region': [[99.0, 479.0], [572.0, 477.0], [572.0, 499.0], [99.0, 501.0]]}, {'text': 'withsmoothsurfacenormal:theminimumcosinesimilar', 'confidence': 0.9979575276374817, 'text_region': [[101.0, 502.0], [569.0, 503.0], [569.0, 522.0], [101.0, 521.0]]}, {'text': 'ityvaluebetweenanytwopixelsislarger thanathreshold', 'confidence': 0.9903074502944946, 'text_region': [[100.0, 527.0], [571.0, 525.0], [571.0, 544.0], [100.0, 546.0]]}, {'text': 't.We set t to 0.95,which proves to produce reasonable', 'confidence': 0.9368306994438171, 'text_region': [[100.0, 551.0], [571.0, 551.0], [571.0, 570.0], [100.0, 570.0]]}, {'text': 'results.Werandomlysample atmost 10non-overlapping', 'confidence': 0.9809103012084961, 'text_region': [[100.0, 574.0], [571.0, 575.0], [571.0, 595.0], [100.0, 594.0]]}, {'text': 'valid image regions to make the initial proposals.Making', 'confidence': 0.9669265151023865, 'text_region': [[100.0, 596.0], [572.0, 597.0], [572.0, 619.0], [100.0, 617.0]]}, {'text': 'proposals from normal maps is an efficient way to find po-', 'confidence': 0.9739918112754822, 'text_region': [[99.0, 622.0], [572.0, 621.0], [572.0, 643.0], [99.0, 644.0]]}, {'text': 'tentialandvisibleregions', 'confidence': 0.9978135228157043, 'text_region': [[101.0, 647.0], [306.0, 647.0], [306.0, 662.0], [101.0, 662.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [615, 401, 1089, 681], 'res': [{'text': 'Figure4:Illustrationoftherefinementofinitialproposals', 'confidence': 0.981162965297699, 'text_region': [[618.0, 402.0], [1085.0, 403.0], [1085.0, 420.0], [618.0, 419.0]]}, {'text': 'We draw green bounding boxes to represent proposals in 2D', 'confidence': 0.9796414375305176, 'text_region': [[617.0, 423.0], [1088.0, 422.0], [1088.0, 446.0], [617.0, 447.0]]}, {'text': 'screen space,and useplanarmeshestorepresentproposals', 'confidence': 0.9766693115234375, 'text_region': [[617.0, 449.0], [1087.0, 448.0], [1087.0, 467.0], [617.0, 468.0]]}, {'text': 'in3Dspace.(1)Initialproposals aremadein 2Dspace', 'confidence': 0.9799069166183472, 'text_region': [[618.0, 473.0], [1087.0, 473.0], [1087.0, 492.0], [618.0, 492.0]]}, {'text': '(2)Whenweprojecttheminto3Dworld andinspectthem', 'confidence': 0.9780964851379395, 'text_region': [[618.0, 496.0], [1088.0, 496.0], [1088.0, 516.0], [618.0, 516.0]]}, {'text': 'fromthefrontview,theyareindistortedforms.(3)Basec', 'confidence': 0.9774245619773865, 'text_region': [[619.0, 522.0], [1086.0, 522.0], [1086.0, 538.0], [619.0, 538.0]]}, {'text': 'onthesizesofthedistortedproposalsandthepositionsof', 'confidence': 0.9901533722877502, 'text_region': [[620.0, 546.0], [1088.0, 546.0], [1088.0, 562.0], [620.0, 562.0]]}, {'text': 'thecenterpoints,were-initializeorthogonalsquaresonthe', 'confidence': 0.9939693212509155, 'text_region': [[619.0, 570.0], [1086.0, 570.0], [1086.0, 587.0], [619.0, 587.0]]}, {'text': 'samesurfaceswithhorizontalsides orthogonal tothegrav', 'confidence': 0.9840923547744751, 'text_region': [[618.0, 593.0], [1085.0, 593.0], [1085.0, 612.0], [618.0, 612.0]]}, {'text': 'ity direction.(5)Then we expand the squares.(6)Finally', 'confidence': 0.973866879940033, 'text_region': [[618.0, 617.0], [1086.0, 617.0], [1086.0, 636.0], [618.0, 636.0]]}, {'text': 'weobtain textregionsin2Dscreenspacewithnaturalper', 'confidence': 0.9898170828819275, 'text_region': [[618.0, 640.0], [1086.0, 641.0], [1086.0, 661.0], [618.0, 660.0]]}, {'text': 'spectivedistortion', 'confidence': 0.9967771172523499, 'text_region': [[618.0, 664.0], [765.0, 663.0], [765.0, 680.0], [618.0, 680.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [615, 977, 1090, 1233], 'res': [{'text': 'Theproposed synthesisengineisimplementedbased on', 'confidence': 0.9796831011772156, 'text_region': [[642.0, 977.0], [1089.0, 978.0], [1089.0, 998.0], [642.0, 997.0]]}, {'text': 'UE4.22 and theUnrealCVplugin.On anubuntu worksta-', 'confidence': 0.9718284010887146, 'text_region': [[617.0, 1000.0], [1086.0, 1001.0], [1086.0, 1021.0], [617.0, 1020.0]]}, {'text': 'tionwithan8-coreIntelCPU,anNVIDIAGeForceRTX', 'confidence': 0.9903510212898254, 'text_region': [[619.0, 1026.0], [1088.0, 1026.0], [1088.0, 1043.0], [619.0, 1043.0]]}, {'text': '2070 GPU,and 16G RAM, the synthesis speed is 0.7-1.5', 'confidence': 0.9557473659515381, 'text_region': [[619.0, 1049.0], [1089.0, 1049.0], [1089.0, 1069.0], [619.0, 1069.0]]}, {'text': 'secondsperimagewith a resolution of1080×720,depend-', 'confidence': 0.9456666111946106, 'text_region': [[617.0, 1073.0], [1088.0, 1072.0], [1088.0, 1092.0], [617.0, 1093.0]]}, {'text': 'ingonthecomplexityof thescenemodel.', 'confidence': 0.9880464673042297, 'text_region': [[617.0, 1096.0], [951.0, 1095.0], [951.0, 1115.0], [617.0, 1116.0]]}, {'text': 'Wecollect30scenemodelsfromtheofficialUE4mar-', 'confidence': 0.9898635745048523, 'text_region': [[642.0, 1120.0], [1087.0, 1120.0], [1087.0, 1137.0], [642.0, 1137.0]]}, {'text': 'ketplace.Theengineisused togenerate600Kscene text', 'confidence': 0.9738450050354004, 'text_region': [[617.0, 1143.0], [1089.0, 1144.0], [1089.0, 1164.0], [617.0, 1163.0]]}, {'text': 'imageswithEnglishwords.Withthesameconfigura-', 'confidence': 0.997047483921051, 'text_region': [[617.0, 1168.0], [1087.0, 1167.0], [1087.0, 1187.0], [617.0, 1188.0]]}, {'text': 'tion,we alsogenerate a multilingual version,making it the', 'confidence': 0.9744125008583069, 'text_region': [[618.0, 1192.0], [1087.0, 1192.0], [1087.0, 1212.0], [618.0, 1212.0]]}, {'text': 'largestmultilingualscenetextdataset.', 'confidence': 0.9844177961349487, 'text_region': [[618.0, 1215.0], [920.0, 1216.0], [920.0, 1232.0], [618.0, 1232.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [99, 736, 574, 1111], 'res': [{'text': 'As shown in Fig.4,rectangular initial proposals in 2D', 'confidence': 0.9566546082496643, 'text_region': [[100.0, 737.0], [572.0, 736.0], [572.0, 756.0], [100.0, 757.0]]}, {'text': 'screen space will be distorted when projected into 3D', 'confidence': 0.9671962857246399, 'text_region': [[100.0, 758.0], [573.0, 758.0], [573.0, 781.0], [100.0, 781.0]]}, {'text': 'world.Thus,we need to first rectify the proposals in 3D', 'confidence': 0.9666998386383057, 'text_region': [[100.0, 783.0], [571.0, 782.0], [571.0, 802.0], [100.0, 803.0]]}, {'text': 'world.Weproject thecenter point of theinitialproposals', 'confidence': 0.9696846604347229, 'text_region': [[101.0, 807.0], [572.0, 807.0], [572.0, 827.0], [101.0, 827.0]]}, {'text': 'into3Dspace,andre-initializeorthogonalsquaresonthe', 'confidence': 0.9896166324615479, 'text_region': [[102.0, 833.0], [571.0, 833.0], [571.0, 849.0], [102.0, 849.0]]}, {'text': 'correspondingmesh surfaces around the center points:the', 'confidence': 0.9673147201538086, 'text_region': [[101.0, 856.0], [573.0, 854.0], [573.0, 874.0], [101.0, 876.0]]}, {'text': 'horizontalsidesareorthogonaltothegravitydirection.The', 'confidence': 0.9931058287620544, 'text_region': [[101.0, 879.0], [572.0, 879.0], [572.0, 898.0], [101.0, 898.0]]}, {'text': 'sidelengths areset to the shortest sides of the quadrilaterals', 'confidence': 0.9423823952674866, 'text_region': [[100.0, 903.0], [572.0, 902.0], [572.0, 922.0], [100.0, 923.0]]}, {'text': 'createdbyprojectingthefour corners ofinitialproposals', 'confidence': 0.9822897911071777, 'text_region': [[103.0, 927.0], [572.0, 927.0], [572.0, 947.0], [103.0, 947.0]]}, {'text': 'intothe3Dspace.Thenweenlarge thewidthsandheights', 'confidence': 0.9870105385780334, 'text_region': [[100.0, 951.0], [572.0, 950.0], [572.0, 969.0], [100.0, 970.0]]}, {'text': 'alongthehorizontalandverticalsidesalternatively.The', 'confidence': 0.9982338547706604, 'text_region': [[101.0, 975.0], [571.0, 973.0], [571.0, 993.0], [101.0, 995.0]]}, {'text': 'expansion of one directionstopswhen thesides of that di-', 'confidence': 0.9477801322937012, 'text_region': [[101.0, 1000.0], [571.0, 998.0], [571.0, 1018.0], [101.0, 1020.0]]}, {'text': \"rectiongetoff the surface'，hit other meshes,or reach the\", 'confidence': 0.9414442777633667, 'text_region': [[100.0, 1022.0], [572.0, 1021.0], [572.0, 1041.0], [100.0, 1042.0]]}, {'text': 'preset maximum expansion ratio. The proposed refining al-', 'confidence': 0.9659112691879272, 'text_region': [[99.0, 1046.0], [570.0, 1044.0], [570.0, 1066.0], [99.0, 1068.0]]}, {'text': 'gorithm works in 3D world space, and is able to produce', 'confidence': 0.959723711013794, 'text_region': [[99.0, 1069.0], [573.0, 1068.0], [573.0, 1090.0], [99.0, 1091.0]]}, {'text': 'naturalhomographytransformationin2Dscreenspace.', 'confidence': 0.9888150095939636, 'text_region': [[99.0, 1091.0], [541.0, 1093.0], [541.0, 1110.0], [99.0, 1110.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [99, 149, 573, 284], 'res': [{'text': 'inthe3Dworldusingobjectmeshes.Finally,wesample', 'confidence': 0.9877132773399353, 'text_region': [[103.0, 177.0], [568.0, 177.0], [568.0, 192.0], [103.0, 192.0]]}, {'text': 'asubsetfrom therefinedproposalstorender.Toavoid oc', 'confidence': 0.9836370348930359, 'text_region': [[100.0, 200.0], [569.0, 200.0], [569.0, 218.0], [100.0, 218.0]]}, {'text': 'clusion amongproposals,weprojectthembacktoscreen', 'confidence': 0.98850017786026, 'text_region': [[100.0, 221.0], [572.0, 222.0], [572.0, 243.0], [100.0, 242.0]]}, {'text': 'space,anddiscardregionsthatoverlapwitheachotherone', 'confidence': 0.9876707196235657, 'text_region': [[103.0, 248.0], [568.0, 248.0], [568.0, 263.0], [103.0, 263.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [99, 1167, 573, 1352], 'res': [{'text': 'GeneratingTextImages:Giventextregionsasproposed', 'confidence': 0.9968734979629517, 'text_region': [[101.0, 1170.0], [572.0, 1170.0], [572.0, 1189.0], [101.0, 1189.0]]}, {'text': 'andrefinedinsection3.4,thetextgenerationmodulesam-', 'confidence': 0.9910182952880859, 'text_region': [[101.0, 1193.0], [569.0, 1193.0], [569.0, 1212.0], [101.0, 1212.0]]}, {'text': 'plestextcontentandrenderstextimageswithcertainfonts', 'confidence': 0.9980801343917847, 'text_region': [[101.0, 1216.0], [571.0, 1216.0], [571.0, 1235.0], [101.0, 1235.0]]}, {'text': 'andtextcolors.Thenumbersoflines andcharactersper', 'confidence': 0.9901959300041199, 'text_region': [[101.0, 1238.0], [572.0, 1240.0], [572.0, 1260.0], [101.0, 1258.0]]}, {'text': 'linearedeterminedbythefontsizeandthesizeofrefined', 'confidence': 0.9908043146133423, 'text_region': [[102.0, 1265.0], [571.0, 1265.0], [571.0, 1282.0], [102.0, 1282.0]]}, {'text': 'proposalsin 2Dspace tomakesure the characters arenot', 'confidence': 0.9634284973144531, 'text_region': [[100.0, 1288.0], [572.0, 1286.0], [572.0, 1307.0], [100.0, 1309.0]]}, {'text': 'toosmallandensurelegibility.Forafairercomparison,we', 'confidence': 0.9854939579963684, 'text_region': [[102.0, 1312.0], [569.0, 1312.0], [569.0, 1329.0], [102.0, 1329.0]]}, {'text': 'alsousethesamefontsetfromGoogleFonts2asSynthText', 'confidence': 0.9684727787971497, 'text_region': [[101.0, 1336.0], [570.0, 1334.0], [570.0, 1350.0], [101.0, 1351.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [616, 1335, 1090, 1425], 'res': [{'text': 'Wefirstverifythe', 'confidence': 0.9780749082565308, 'text_region': [[646.0, 1338.0], [792.0, 1342.0], [792.0, 1354.0], [645.0, 1350.0]]}, {'text': 'oftheproposedengine', 'confidence': 0.9860436320304871, 'text_region': [[902.0, 1341.0], [1085.0, 1341.0], [1085.0, 1353.0], [902.0, 1353.0]]}, {'text': 'bytrainingdetectorsonthesynthesizedimagesandevaluat', 'confidence': 0.9977142214775085, 'text_region': [[618.0, 1360.0], [1084.0, 1359.0], [1084.0, 1378.0], [618.0, 1379.0]]}, {'text': 'ingthemonrealimagedatasets.Weuseapreviousyettime', 'confidence': 0.9956791400909424, 'text_region': [[620.0, 1386.0], [1086.0, 1386.0], [1086.0, 1402.0], [620.0, 1402.0]]}, {'text': 'estedstate-of-the-artmodelEAST[53lwhichisfastane', 'confidence': 0.9584936499595642, 'text_region': [[622.0, 1408.0], [1084.0, 1408.0], [1084.0, 1420.0], [622.0, 1420.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [615, 778, 1090, 919], 'res': [{'text': 'RenderingTextin3DWorld:Wefirstperformtriangula', 'confidence': 0.9924274682998657, 'text_region': [[620.0, 785.0], [1084.0, 785.0], [1084.0, 800.0], [620.0, 800.0]]}, {'text': 'tionfortherefinedproposalstogenerateplanartriangulai', 'confidence': 0.9865761399269104, 'text_region': [[620.0, 810.0], [1087.0, 810.0], [1087.0, 825.0], [620.0, 825.0]]}, {'text': 'meshesthatarecloselyattachedtotheunderlyingsurface', 'confidence': 0.9975681900978088, 'text_region': [[620.0, 833.0], [1084.0, 833.0], [1084.0, 848.0], [620.0, 848.0]]}, {'text': 'Thenweloadthetextimagesastextureontothegenerated', 'confidence': 0.9980607032775879, 'text_region': [[619.0, 854.0], [1088.0, 855.0], [1088.0, 874.0], [619.0, 873.0]]}, {'text': 'meshes.Wealsorandomlysamplethetextureattributes', 'confidence': 0.9896251559257507, 'text_region': [[620.0, 880.0], [1086.0, 880.0], [1086.0, 896.0], [620.0, 896.0]]}, {'text': 'suchastheratioofdiftuse', 'confidence': 0.9678018689155579, 'text_region': [[621.0, 905.0], [831.0, 905.0], [831.0, 916.0], [621.0, 916.0]]}, {'text': 'ahd', 'confidence': 0.7265785336494446, 'text_region': [[827.0, 907.0], [861.0, 907.0], [861.0, 915.0], [827.0, 915.0]]}, {'text': '1SDe', 'confidence': 0.6872072219848633, 'text_region': [[858.0, 907.0], [889.0, 907.0], [889.0, 915.0], [858.0, 915.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [619, 711, 1091, 774], 'res': [{'text': 'es.', 'confidence': 0.7744478583335876, 'text_region': [[626.0, 717.0], [659.0, 717.0], [659.0, 724.0], [626.0, 724.0]]}, {'text': 'leSd', 'confidence': 0.7202936410903931, 'text_region': [[762.0, 718.0], [808.0, 718.0], [808.0, 728.0], [762.0, 728.0]]}, {'text': 'AtCOIP', 'confidence': 0.7646473050117493, 'text_region': [[850.0, 719.0], [909.0, 719.0], [909.0, 729.0], [850.0, 729.0]]}, {'text': 'generated textimageshavezeroalphavalues onnon-stroke', 'confidence': 0.9803087711334229, 'text_region': [[620.0, 736.0], [1087.0, 735.0], [1087.0, 754.0], [620.0, 755.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [616, 1259, 1020, 1317], 'res': [{'text': '4.Experiments onScene TextDetection', 'confidence': 0.9759436249732971, 'text_region': [[617.0, 1260.0], [1016.0, 1261.0], [1016.0, 1283.0], [617.0, 1282.0]]}, {'text': '4.1.Settings', 'confidence': 0.9907545447349548, 'text_region': [[619.0, 1296.0], [730.0, 1299.0], [729.0, 1316.0], [619.0, 1316.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [99, 697, 436, 715], 'res': [{'text': 'KehnnoPronosalsns)yvoro', 'confidence': 0.7479254007339478, 'text_region': [[166.0, 702.0], [424.0, 702.0], [424.0, 709.0], [166.0, 709.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [99, 321, 469, 340], 'res': [{'text': 'niialPronosalstromNormalye', 'confidence': 0.7894090414047241, 'text_region': [[166.0, 326.0], [444.0, 326.0], [444.0, 334.0], [166.0, 334.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [618, 940, 877, 957], 'res': [{'text': 'pesnestatdnletr', 'confidence': 0.6775303483009338, 'text_region': [[667.0, 945.0], [848.0, 945.0], [848.0, 953.0], [667.0, 953.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [100, 1130, 283, 1148], 'res': [{'text': 'B.5.1extRenderun', 'confidence': 0.8811332583427429, 'text_region': [[105.0, 1133.0], [274.0, 1134.0], [274.0, 1144.0], [105.0, 1143.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure', 'bbox': [611, 136, 1090, 384], 'res': [{'text': '(1) Initial Proposal', 'confidence': 0.9961127042770386, 'text_region': [[635.0, 244.0], [745.0, 244.0], [745.0, 261.0], [635.0, 261.0]]}, {'text': '(2)Front View', 'confidence': 0.9821428060531616, 'text_region': [[804.0, 244.0], [890.0, 244.0], [890.0, 261.0], [804.0, 261.0]]}, {'text': '(3) Create Orthogonal Square', 'confidence': 0.9733453989028931, 'text_region': [[919.0, 244.0], [1089.0, 244.0], [1089.0, 261.0], [919.0, 261.0]]}, {'text': '(4) Original View', 'confidence': 0.9255710244178772, 'text_region': [[634.0, 365.0], [737.0, 364.0], [737.0, 381.0], [634.0, 382.0]]}, {'text': '(5) Refined Proposal', 'confidence': 0.9449000358581543, 'text_region': [[788.0, 366.0], [907.0, 366.0], [907.0, 382.0], [788.0, 382.0]]}, {'text': '(6)Embedded Text', 'confidence': 0.9188002347946167, 'text_region': [[950.0, 367.0], [1059.0, 367.0], [1059.0, 380.0], [950.0, 380.0]]}], 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [99, 1371, 569, 1425], 'res': [{'text': \"when the distancesfrom the rectangular proposals'corners to the near\", 'confidence': 0.9529784917831421, 'text_region': [[125.0, 1371.0], [568.0, 1373.0], [568.0, 1390.0], [124.0, 1387.0]]}, {'text': 'estpoint on theunderlyingsurfacemeshexceedcertainthreshold', 'confidence': 0.9824509024620056, 'text_region': [[100.0, 1392.0], [518.0, 1390.0], [518.0, 1405.0], [100.0, 1406.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:41:34] ppocr DEBUG: dt_boxes num : 32, elapsed : 0.26239633560180664\n",
      "[2024/05/30 16:41:38] ppocr DEBUG: rec_res num  : 32, elapsed : 3.9470605850219727\n",
      "[2024/05/30 16:41:38] ppocr DEBUG: dt_boxes num : 18, elapsed : 0.18263673782348633\n",
      "[2024/05/30 16:41:41] ppocr DEBUG: rec_res num  : 18, elapsed : 2.294097423553467\n",
      "[2024/05/30 16:41:41] ppocr DEBUG: dt_boxes num : 37, elapsed : 0.2862985134124756\n",
      "[2024/05/30 16:41:45] ppocr DEBUG: rec_res num  : 37, elapsed : 3.554947853088379\n",
      "[2024/05/30 16:41:45] ppocr DEBUG: dt_boxes num : 5, elapsed : 0.08134961128234863\n",
      "[2024/05/30 16:41:45] ppocr DEBUG: rec_res num  : 5, elapsed : 0.17507410049438477\n",
      "[2024/05/30 16:41:45] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.055999755859375\n",
      "[2024/05/30 16:41:45] ppocr DEBUG: rec_res num  : 1, elapsed : 0.14719462394714355\n",
      "[2024/05/30 16:41:45] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.07736802101135254\n",
      "[2024/05/30 16:41:46] ppocr DEBUG: rec_res num  : 6, elapsed : 0.5168817043304443\n",
      "[2024/05/30 16:41:46] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.06838440895080566\n",
      "[2024/05/30 16:41:46] ppocr DEBUG: rec_res num  : 2, elapsed : 0.234757661819458\n",
      "[2024/05/30 16:41:46] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.0832817554473877\n",
      "[2024/05/30 16:41:46] ppocr DEBUG: rec_res num  : 2, elapsed : 0.3458895683288574\n",
      "{'type': 'text', 'bbox': [99, 631, 572, 1389], 'res': [{'text': 'PureSyntheticDataWefirsttraintheEASTmodelson', 'confidence': 0.9965837597846985, 'text_region': [[103.0, 634.0], [570.0, 634.0], [570.0, 651.0], [103.0, 651.0]]}, {'text': 'different syntheticdatasets alone,tocompare our method', 'confidence': 0.959636926651001, 'text_region': [[101.0, 654.0], [570.0, 655.0], [570.0, 675.0], [101.0, 674.0]]}, {'text': 'withprevious ones in a direct and quantitative way.Note', 'confidence': 0.9553226828575134, 'text_region': [[101.0, 679.0], [570.0, 679.0], [570.0, 699.0], [101.0, 699.0]]}, {'text': 'thatUnrealText,SynthText3D,SynthText,andVISDhave', 'confidence': 0.9623215794563293, 'text_region': [[102.0, 704.0], [569.0, 704.0], [569.0, 721.0], [102.0, 721.0]]}, {'text': 'differentnumbers ofimages,sowe alsoneed to control the', 'confidence': 0.9667925834655762, 'text_region': [[101.0, 726.0], [570.0, 727.0], [570.0, 746.0], [101.0, 745.0]]}, {'text': 'number ofimages used in experiments.Results are summa-', 'confidence': 0.9709925055503845, 'text_region': [[100.0, 750.0], [570.0, 752.0], [570.0, 772.0], [100.0, 770.0]]}, {'text': 'rized in Tab.1.', 'confidence': 0.9824504256248474, 'text_region': [[99.0, 775.0], [221.0, 773.0], [221.0, 793.0], [99.0, 795.0]]}, {'text': 'Firstly,we control the totalnumber of images to', 'confidence': 0.9481012225151062, 'text_region': [[123.0, 798.0], [571.0, 800.0], [571.0, 820.0], [123.0, 818.0]]}, {'text': '10K,which is also the full size of the smallest synthetic', 'confidence': 0.9423174858093262, 'text_region': [[101.0, 821.0], [570.0, 822.0], [570.0, 842.0], [101.0, 841.0]]}, {'text': 'datasets,VISDandSynthText3D.Weobserveaconsider', 'confidence': 0.9692859053611755, 'text_region': [[103.0, 848.0], [569.0, 848.0], [569.0, 865.0], [103.0, 865.0]]}, {'text': 'ableimprovementonIC15overpreviousstate-of-the-artby', 'confidence': 0.9975636005401611, 'text_region': [[101.0, 871.0], [570.0, 871.0], [570.0, 891.0], [101.0, 891.0]]}, {'text': '+0.9%in F1-score,and significant improvements onIC13', 'confidence': 0.9750538468360901, 'text_region': [[101.0, 893.0], [571.0, 894.0], [571.0, 913.0], [101.0, 912.0]]}, {'text': '(+2.7%)andMLT 2017(+2.8%).Secondly,we also train', 'confidence': 0.9423573613166809, 'text_region': [[102.0, 918.0], [570.0, 918.0], [570.0, 935.0], [102.0, 935.0]]}, {'text': 'modelsonthefullsetofSynthTextandours,sincescalabil', 'confidence': 0.995623767375946, 'text_region': [[103.0, 943.0], [567.0, 943.0], [567.0, 960.0], [103.0, 960.0]]}, {'text': 'ityisalsoanimportantfactorforsyntheticscenetextim', 'confidence': 0.9921039938926697, 'text_region': [[100.0, 967.0], [568.0, 965.0], [568.0, 984.0], [100.0, 986.0]]}, {'text': 'ages,especially whenconsideringthe demand to train rec', 'confidence': 0.962331235408783, 'text_region': [[100.0, 991.0], [570.0, 988.0], [570.0, 1009.0], [100.0, 1012.0]]}, {'text': 'ognizers.Extra trainingimages furtherimproveF1scores', 'confidence': 0.9840582609176636, 'text_region': [[101.0, 1015.0], [569.0, 1015.0], [569.0, 1035.0], [101.0, 1035.0]]}, {'text': 'onIC15,IC13,and MLT by +2.6%,+2.3%,and +2.1%', 'confidence': 0.9268423318862915, 'text_region': [[100.0, 1038.0], [569.0, 1036.0], [569.0, 1055.0], [100.0, 1057.0]]}, {'text': 'ModelstrainedwithourUnrealTextdataoutperformall', 'confidence': 0.9989125728607178, 'text_region': [[102.0, 1063.0], [570.0, 1063.0], [570.0, 1080.0], [102.0, 1080.0]]}, {'text': 'other synthetic datasets.Besides,the subset of 10K images', 'confidence': 0.9760853052139282, 'text_region': [[100.0, 1082.0], [571.0, 1085.0], [571.0, 1109.0], [100.0, 1106.0]]}, {'text': 'withourmethodevensurpasses800KSynthTextimages', 'confidence': 0.9851198196411133, 'text_region': [[101.0, 1109.0], [570.0, 1111.0], [570.0, 1131.0], [101.0, 1129.0]]}, {'text': 'significantly on all datasets.The experiment results demon-', 'confidence': 0.9659050703048706, 'text_region': [[100.0, 1134.0], [570.0, 1133.0], [570.0, 1153.0], [100.0, 1154.0]]}, {'text': 'strate theeffectiveness of ourproposedsyntheticengine and', 'confidence': 0.9633448123931885, 'text_region': [[100.0, 1158.0], [571.0, 1158.0], [571.0, 1178.0], [100.0, 1178.0]]}, {'text': 'datasets.', 'confidence': 0.997878909111023, 'text_region': [[100.0, 1181.0], [168.0, 1183.0], [168.0, 1201.0], [100.0, 1198.0]]}, {'text': 'ComplementarySyntheticDataOneuniquecharacteristic', 'confidence': 0.9848400950431824, 'text_region': [[101.0, 1203.0], [570.0, 1204.0], [570.0, 1225.0], [101.0, 1224.0]]}, {'text': 'of theproposedUnrealTextis that,theimages aregenerated', 'confidence': 0.9768059849739075, 'text_region': [[100.0, 1228.0], [571.0, 1229.0], [571.0, 1250.0], [100.0, 1249.0]]}, {'text': 'from 3D scene models,instead ofrealbackground images', 'confidence': 0.9601188898086548, 'text_region': [[100.0, 1252.0], [569.0, 1254.0], [569.0, 1274.0], [100.0, 1272.0]]}, {'text': 'resultinginpotentialdomaingapdue todifferentartistic', 'confidence': 0.9730865955352783, 'text_region': [[101.0, 1277.0], [570.0, 1277.0], [570.0, 1297.0], [101.0, 1297.0]]}, {'text': 'styles.Weconductexperimentsby training onbothUnre', 'confidence': 0.9796655774116516, 'text_region': [[100.0, 1301.0], [568.0, 1300.0], [568.0, 1320.0], [100.0, 1321.0]]}, {'text': 'alTextdata(5K)andVIsD(5K),asalsoshowninTab.1', 'confidence': 0.9672307372093201, 'text_region': [[101.0, 1326.0], [568.0, 1326.0], [568.0, 1343.0], [101.0, 1343.0]]}, {'text': '(lastrow,markedwithitalics),which achievesbetterperfor-', 'confidence': 0.9705619215965271, 'text_region': [[100.0, 1348.0], [570.0, 1349.0], [570.0, 1368.0], [100.0, 1367.0]]}, {'text': 'mancethanother1OKsyntheticdatasets.Thecombinatior', 'confidence': 0.9786937236785889, 'text_region': [[102.0, 1374.0], [568.0, 1374.0], [568.0, 1388.0], [102.0, 1388.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 150, 573, 571], 'res': [{'text': 'accurate.EASTalsoformsthebasisofseveralwidelyrec', 'confidence': 0.998153030872345, 'text_region': [[102.0, 153.0], [568.0, 153.0], [568.0, 170.0], [102.0, 170.0]]}, {'text': 'ognized end-to-end text spotting models [18,7]. We adopt', 'confidence': 0.9673420786857605, 'text_region': [[101.0, 174.0], [570.0, 174.0], [570.0, 195.0], [101.0, 195.0]]}, {'text': 'an opensourceimplementation?.In all experiments,models', 'confidence': 0.9651122689247131, 'text_region': [[99.0, 199.0], [571.0, 198.0], [571.0, 218.0], [99.0, 219.0]]}, {'text': 'aretrainedon4GPUwithabatchsizeof56.Duringthe', 'confidence': 0.9990940690040588, 'text_region': [[100.0, 222.0], [570.0, 223.0], [570.0, 241.0], [100.0, 240.0]]}, {'text': 'evaluation,the test images areresized tomatch a short side', 'confidence': 0.9541195631027222, 'text_region': [[101.0, 246.0], [572.0, 246.0], [572.0, 266.0], [101.0, 266.0]]}, {'text': 'lengthof800pixels.Foreachexperimentsetting,wereport', 'confidence': 0.9779906272888184, 'text_region': [[101.0, 269.0], [571.0, 271.0], [571.0, 289.0], [101.0, 287.0]]}, {'text': 'themeanperformancein5independenttrials.', 'confidence': 0.9892463684082031, 'text_region': [[101.0, 294.0], [464.0, 294.0], [464.0, 311.0], [101.0, 311.0]]}, {'text': 'BenchmarkDatasetsWeusethefollowingscenetext', 'confidence': 0.9914090633392334, 'text_region': [[99.0, 315.0], [572.0, 317.0], [572.0, 337.0], [99.0, 335.0]]}, {'text': 'detectiondatasetsforevaluation:(1)ICDAR2013Fo', 'confidence': 0.9636309146881104, 'text_region': [[102.0, 342.0], [569.0, 342.0], [569.0, 359.0], [102.0, 359.0]]}, {'text': 'cusedSceneText(IC13)[14]containinghorizontaltextwith', 'confidence': 0.978155255317688, 'text_region': [[102.0, 367.0], [570.0, 367.0], [570.0, 384.0], [102.0, 384.0]]}, {'text': 'zoomed-inviews.(2)ICDAR2015IncidentalSceneTexi', 'confidence': 0.9704822897911072, 'text_region': [[101.0, 390.0], [570.0, 390.0], [570.0, 407.0], [101.0, 407.0]]}, {'text': '(IC15)[13]consistingofimagestakenwithoutcarefulness', 'confidence': 0.9876791834831238, 'text_region': [[102.0, 414.0], [570.0, 414.0], [570.0, 431.0], [102.0, 431.0]]}, {'text': 'withGoogleGlass.Imagesareblurredandtextaresmall.', 'confidence': 0.983559787273407, 'text_region': [[102.0, 437.0], [570.0, 437.0], [570.0, 455.0], [102.0, 455.0]]}, {'text': '(3）MLT2017[27]formultilingualscenetextdetection', 'confidence': 0.9694309830665588, 'text_region': [[100.0, 461.0], [569.0, 462.0], [569.0, 479.0], [100.0, 478.0]]}, {'text': 'whichis composedof scenetextimages of 9languages.', 'confidence': 0.9634930491447449, 'text_region': [[100.0, 483.0], [571.0, 486.0], [571.0, 506.0], [100.0, 503.0]]}, {'text': 'Note that theimagesinIC13andMLT17havevaryingres-', 'confidence': 0.9767487645149231, 'text_region': [[99.0, 507.0], [570.0, 509.0], [570.0, 530.0], [99.0, 527.0]]}, {'text': 'olutions.Therefore,it is necessary to resize them to the', 'confidence': 0.9550303220748901, 'text_region': [[101.0, 531.0], [572.0, 532.0], [572.0, 552.0], [101.0, 551.0]]}, {'text': 'levelofresolutionsbeforeevaluation', 'confidence': 0.979136049747467, 'text_region': [[141.0, 558.0], [440.0, 558.0], [440.0, 570.0], [141.0, 570.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [616, 475, 1090, 1381], 'res': [{'text': 'ofUnrealTextandVISDisalsosuperiortothecombina-', 'confidence': 0.9810508489608765, 'text_region': [[619.0, 477.0], [1087.0, 477.0], [1087.0, 494.0], [619.0, 494.0]]}, {'text': 'tion of SynthText3DandVISD.This resultdemonstrates', 'confidence': 0.9741440415382385, 'text_region': [[618.0, 498.0], [1088.0, 498.0], [1088.0, 518.0], [618.0, 518.0]]}, {'text': 'that,our UnrealTextis complementary to existing syn', 'confidence': 0.959830641746521, 'text_region': [[617.0, 521.0], [1086.0, 524.0], [1086.0, 545.0], [617.0, 543.0]]}, {'text': 'thetic datasets that use realimages as backgrounds.While', 'confidence': 0.9559327960014343, 'text_region': [[618.0, 546.0], [1086.0, 547.0], [1086.0, 567.0], [618.0, 566.0]]}, {'text': 'UnrealTextsimulatesphoto-realisticeffects,syntheticdata', 'confidence': 0.9761452674865723, 'text_region': [[620.0, 572.0], [1087.0, 572.0], [1087.0, 589.0], [620.0, 589.0]]}, {'text': 'withreal background images canhelp adapt toreal-world', 'confidence': 0.9695603251457214, 'text_region': [[619.0, 595.0], [1088.0, 595.0], [1088.0, 616.0], [619.0, 616.0]]}, {'text': 'datasets.', 'confidence': 0.9986351728439331, 'text_region': [[619.0, 620.0], [685.0, 620.0], [685.0, 637.0], [619.0, 637.0]]}, {'text': 'CombiningSyntheticandRealDataOneimportantrole', 'confidence': 0.9979193806648254, 'text_region': [[621.0, 646.0], [1087.0, 646.0], [1087.0, 663.0], [621.0, 663.0]]}, {'text': 'ofsyntheticdataistoserveasdataforpretraining,andto', 'confidence': 0.9868736863136292, 'text_region': [[619.0, 670.0], [1088.0, 670.0], [1088.0, 687.0], [619.0, 687.0]]}, {'text': 'further improve theperformance on domain specificreal', 'confidence': 0.9652031660079956, 'text_region': [[618.0, 690.0], [1089.0, 691.0], [1089.0, 713.0], [618.0, 712.0]]}, {'text': 'datasets.We first pretrain theEAST models with differ-', 'confidence': 0.9514475464820862, 'text_region': [[618.0, 716.0], [1088.0, 716.0], [1088.0, 736.0], [618.0, 736.0]]}, {'text': 'entsyntheticdata,andthenusedomaindatatofinetunethe', 'confidence': 0.9879727959632874, 'text_region': [[619.0, 742.0], [1088.0, 740.0], [1088.0, 757.0], [619.0, 759.0]]}, {'text': 'models.TheresultsaresummarizedinTab.2.Onall', 'confidence': 0.9991397261619568, 'text_region': [[619.0, 765.0], [1089.0, 765.0], [1089.0, 782.0], [619.0, 782.0]]}, {'text': 'domain-specific datasets,models pretrained with our syn-', 'confidence': 0.9733774065971375, 'text_region': [[618.0, 787.0], [1088.0, 788.0], [1088.0, 809.0], [618.0, 808.0]]}, {'text': 'thetic dataset surpasses others by considerable margins,ver', 'confidence': 0.9689874053001404, 'text_region': [[617.0, 810.0], [1087.0, 812.0], [1087.0, 833.0], [617.0, 831.0]]}, {'text': 'ifyingtheeffectiveness of oursynthesismethodin the con-', 'confidence': 0.9650766253471375, 'text_region': [[617.0, 835.0], [1088.0, 836.0], [1088.0, 856.0], [617.0, 855.0]]}, {'text': 'textofboostingperformanceondomainspecificdatasets', 'confidence': 0.9982023239135742, 'text_region': [[619.0, 861.0], [1073.0, 861.0], [1073.0, 878.0], [619.0, 878.0]]}, {'text': 'PretrainingonFullDatasetAsshownin thelastrows', 'confidence': 0.9900161623954773, 'text_region': [[618.0, 886.0], [1087.0, 886.0], [1087.0, 906.0], [618.0, 906.0]]}, {'text': 'of Tab.2,whenwepretrain the detector models with our', 'confidence': 0.9499303102493286, 'text_region': [[618.0, 910.0], [1089.0, 910.0], [1089.0, 930.0], [618.0, 930.0]]}, {'text': 'fulldataset,theperformances areimproved significantly', 'confidence': 0.9785286784172058, 'text_region': [[617.0, 933.0], [1088.0, 934.0], [1088.0, 954.0], [617.0, 953.0]]}, {'text': 'demonstratingtheadvantageofthescalabilityofouren-', 'confidence': 0.9930554032325745, 'text_region': [[619.0, 959.0], [1087.0, 959.0], [1087.0, 977.0], [619.0, 977.0]]}, {'text': 'gine.Especially,The EAST model achieves an F1 score', 'confidence': 0.958925724029541, 'text_region': [[618.0, 982.0], [1089.0, 981.0], [1089.0, 1002.0], [618.0, 1003.0]]}, {'text': 'of 74.1onMLT17,which is evenbetter thanrecent state-', 'confidence': 0.9486492872238159, 'text_region': [[619.0, 1004.0], [1087.0, 1006.0], [1087.0, 1026.0], [619.0, 1024.0]]}, {'text': 'of-the-art results,including 73.9 by CRAFT[2] and 73.1 by', 'confidence': 0.9630292057991028, 'text_region': [[619.0, 1030.0], [1088.0, 1030.0], [1088.0, 1050.0], [619.0, 1050.0]]}, {'text': 'LOMO[52].Although the margin is not great, it suffices', 'confidence': 0.9599967002868652, 'text_region': [[618.0, 1053.0], [1088.0, 1053.0], [1088.0, 1074.0], [618.0, 1074.0]]}, {'text': 'to claimthat theEASTmodelrevives andreclaims state-of', 'confidence': 0.9644318222999573, 'text_region': [[618.0, 1076.0], [1086.0, 1077.0], [1086.0, 1097.0], [618.0, 1096.0]]}, {'text': 'the-artperformancewiththehelpofoursyntheticdataset.', 'confidence': 0.9958233833312988, 'text_region': [[619.0, 1103.0], [1078.0, 1103.0], [1078.0, 1120.0], [619.0, 1120.0]]}, {'text': 'ResultswithMask-RCNNAstheEASTalgorithmweuse', 'confidence': 0.9987044334411621, 'text_region': [[618.0, 1126.0], [1089.0, 1128.0], [1089.0, 1148.0], [618.0, 1146.0]]}, {'text': 'aboveisspecificallydesignedforscenetextandthatthe', 'confidence': 0.9938319325447083, 'text_region': [[620.0, 1152.0], [1087.0, 1152.0], [1087.0, 1170.0], [620.0, 1170.0]]}, {'text': 'evaluationwithF1scoresmaynotbecomprehensive,we', 'confidence': 0.9867678284645081, 'text_region': [[620.0, 1177.0], [1088.0, 1177.0], [1088.0, 1194.0], [620.0, 1194.0]]}, {'text': 'provide results with Mask-RCNN[?]which is ageneral', 'confidence': 0.9541280269622803, 'text_region': [[618.0, 1199.0], [1089.0, 1199.0], [1089.0, 1219.0], [618.0, 1219.0]]}, {'text': 'objectdetector.WeevaluatethemodelsusingtheAverage', 'confidence': 0.9982101321220398, 'text_region': [[618.0, 1221.0], [1088.0, 1223.0], [1088.0, 1244.0], [618.0, 1241.0]]}, {'text': 'Precision(AP)metricswhicharemorecomprehensiveand', 'confidence': 0.9940810203552246, 'text_region': [[619.0, 1249.0], [1088.0, 1249.0], [1088.0, 1266.0], [619.0, 1266.0]]}, {'text': 'lessaffectedbythetrickychoiceofthresholdvalues.We', 'confidence': 0.9976038336753845, 'text_region': [[619.0, 1272.0], [1088.0, 1272.0], [1088.0, 1289.0], [619.0, 1289.0]]}, {'text': 'use the opensourceimplementationDetectron24.Thero-', 'confidence': 0.9824125170707703, 'text_region': [[617.0, 1295.0], [1089.0, 1293.0], [1089.0, 1313.0], [617.0, 1315.0]]}, {'text': 'tatedboundingboxes of text instances areused asthemask', 'confidence': 0.9762003421783447, 'text_region': [[618.0, 1318.0], [1089.0, 1317.0], [1089.0, 1338.0], [618.0, 1339.0]]}, {'text': 'annotations.WeselectadefaultMask-RCNNconfiguration', 'confidence': 0.9971362352371216, 'text_region': [[619.0, 1344.0], [1088.0, 1344.0], [1088.0, 1361.0], [619.0, 1361.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [617, 378, 1090, 421], 'res': [{'text': 'Table1:', 'confidence': 0.8965954780578613, 'text_region': [[620.0, 381.0], [687.0, 381.0], [687.0, 394.0], [620.0, 394.0]]}, {'text': 'models', 'confidence': 0.9975934028625488, 'text_region': [[1031.0, 381.0], [1088.0, 379.0], [1088.0, 394.0], [1031.0, 396.0]]}, {'text': 'on', 'confidence': 0.9485408663749695, 'text_region': [[672.0, 408.0], [704.0, 408.0], [704.0, 417.0], [672.0, 417.0]]}, {'text': 'svnthetic', 'confidence': 0.892160177230835, 'text_region': [[777.0, 408.0], [850.0, 408.0], [850.0, 417.0], [777.0, 417.0]]}, {'text': 'data', 'confidence': 0.9950860738754272, 'text_region': [[853.0, 406.0], [887.0, 406.0], [887.0, 420.0], [853.0, 420.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [100, 594, 332, 614], 'res': [{'text': '.z.hxpersnentskeslir', 'confidence': 0.6942847967147827, 'text_region': [[110.0, 600.0], [320.0, 600.0], [320.0, 608.0], [110.0, 608.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [617, 378, 1045, 421], 'res': [{'text': 'Iable', 'confidence': 0.9298015832901001, 'text_region': [[620.0, 381.0], [663.0, 381.0], [663.0, 394.0], [620.0, 394.0]]}, {'text': '', 'confidence': 0.0, 'text_region': [[660.0, 380.0], [685.0, 384.0], [684.0, 393.0], [659.0, 390.0]]}, {'text': 'Detectionresults (F1-scores)of EASTn', 'confidence': 0.9402263164520264, 'text_region': [[700.0, 378.0], [1043.0, 378.0], [1043.0, 395.0], [700.0, 395.0]]}, {'text': 'trained', 'confidence': 0.9971955418586731, 'text_region': [[618.0, 404.0], [674.0, 404.0], [674.0, 417.0], [618.0, 417.0]]}, {'text': 'Onditferent', 'confidence': 0.7689578533172607, 'text_region': [[677.0, 408.0], [772.0, 408.0], [772.0, 417.0], [677.0, 417.0]]}, {'text': 'syntheticdata', 'confidence': 0.9957612156867981, 'text_region': [[774.0, 406.0], [888.0, 406.0], [888.0, 420.0], [774.0, 420.0]]}], 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [623, 138, 1107, 370], 'res': '', 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [126, 1409, 410, 1426], 'res': [{'text': '+tos：', 'confidence': 0.5431625843048096, 'text_region': [[136.0, 1415.0], [187.0, 1415.0], [187.0, 1421.0], [136.0, 1421.0]]}, {'text': 'github.com/argman/eAs', 'confidence': 0.8502197265625, 'text_region': [[202.0, 1414.0], [402.0, 1414.0], [402.0, 1421.0], [202.0, 1422.0]]}], 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [630, 1409, 1083, 1427], 'res': [{'text': '+S', 'confidence': 0.2290998250246048, 'text_region': [[652.0, 1416.0], [693.0, 1416.0], [693.0, 1421.0], [652.0, 1421.0]]}, {'text': 'b.com/tacebookresearch/detectron', 'confidence': 0.9644749164581299, 'text_region': [[771.0, 1413.0], [1077.0, 1415.0], [1077.0, 1422.0], [771.0, 1421.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:41:47] ppocr DEBUG: dt_boxes num : 51, elapsed : 0.23850369453430176\n",
      "[2024/05/30 16:41:50] ppocr DEBUG: rec_res num  : 51, elapsed : 3.2077436447143555\n",
      "[2024/05/30 16:41:50] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.119720458984375\n",
      "[2024/05/30 16:41:51] ppocr DEBUG: rec_res num  : 8, elapsed : 1.0937111377716064\n",
      "[2024/05/30 16:41:51] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.08830857276916504\n",
      "[2024/05/30 16:41:51] ppocr DEBUG: rec_res num  : 1, elapsed : 0.1509230136871338\n",
      "[2024/05/30 16:41:51] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.06899023056030273\n",
      "[2024/05/30 16:41:52] ppocr DEBUG: rec_res num  : 1, elapsed : 0.10179853439331055\n",
      "[2024/05/30 16:41:52] ppocr DEBUG: dt_boxes num : 10, elapsed : 0.08153033256530762\n",
      "[2024/05/30 16:41:52] ppocr DEBUG: rec_res num  : 10, elapsed : 0.35106396675109863\n",
      "[2024/05/30 16:41:52] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.05731463432312012\n",
      "[2024/05/30 16:41:52] ppocr DEBUG: rec_res num  : 1, elapsed : 0.11835265159606934\n",
      "[2024/05/30 16:41:52] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.08646678924560547\n",
      "[2024/05/30 16:41:53] ppocr DEBUG: rec_res num  : 4, elapsed : 0.26437902450561523\n",
      "{'type': 'text', 'bbox': [617, 148, 1090, 1424], 'res': [{'text': 'imcreas', 'confidence': 0.8453840613365173, 'text_region': [[1020.0, 156.0], [1085.0, 156.0], [1085.0, 165.0], [1020.0, 165.0]]}, {'text': 'gtiealvelsrty', 'confidence': 0.7600399255752563, 'text_region': [[621.0, 181.0], [746.0, 181.0], [746.0, 191.0], [621.0, 191.0]]}, {'text': 'odule:(l)RandomView', 'confidence': 0.9189969301223755, 'text_region': [[884.0, 228.0], [1086.0, 228.0], [1086.0, 241.0], [884.0, 241.0]]}, {'text': 'ManualAnch', 'confidence': 0.9886623620986938, 'text_region': [[672.0, 253.0], [794.0, 253.0], [794.0, 266.0], [672.0, 266.0]]}, {'text': 'Iysamplescameralo', 'confidence': 0.9748042821884155, 'text_region': [[914.0, 253.0], [1086.0, 253.0], [1086.0, 266.0], [914.0, 266.0]]}, {'text': 'ballspacescentered', 'confidence': 0.9273322224617004, 'text_region': [[927.0, 277.0], [1086.0, 277.0], [1086.0, 290.0], [927.0, 290.0]]}, {'text': '(2）RandomViewpoin', 'confidence': 0.9724360108375549, 'text_region': [[909.0, 301.0], [1086.0, 301.0], [1086.0, 314.0], [909.0, 314.0]]}, {'text': 'tionsandrotations', 'confidence': 0.9970972537994385, 'text_region': [[944.0, 325.0], [1087.0, 325.0], [1087.0, 338.0], [944.0, 338.0]]}, {'text': 'checkingtheirqual', 'confidence': 0.9965441226959229, 'text_region': [[925.0, 349.0], [1086.0, 349.0], [1086.0, 362.0], [925.0, 362.0]]}, {'text': 'scenestoibtc', 'confidence': 0.7863314747810364, 'text_region': [[964.0, 374.0], [1086.0, 374.0], [1086.0, 383.0], [964.0, 383.0]]}, {'text': 'cOiiuO1Sceie', 'confidence': 0.47366955876350403, 'text_region': [[621.0, 401.0], [725.0, 401.0], [725.0, 410.0], [621.0, 410.0]]}, {'text': 'differentnumbers', 'confidence': 0.9962731003761292, 'text_region': [[921.0, 397.0], [1079.0, 397.0], [1079.0, 410.0], [921.0, 410.0]]}, {'text': 'incecurve.Byfixing', 'confidence': 0.9778258204460144, 'text_region': [[913.0, 418.0], [1089.0, 419.0], [1089.0, 436.0], [913.0, 435.0]]}, {'text': 'howwelldifferentview', 'confidence': 0.9931818246841431, 'text_region': [[902.0, 442.0], [1086.0, 442.0], [1086.0, 459.0], [902.0, 459.0]]}, {'text': 'tionWeremovethe', 'confidence': 0.9795268774032593, 'text_region': [[922.0, 495.0], [1087.0, 495.0], [1087.0, 508.0], [922.0, 508.0]]}, {'text': 'Keep', 'confidence': 0.9031453132629395, 'text_region': [[964.0, 521.0], [1004.0, 521.0], [1004.0, 531.0], [964.0, 531.0]]}, {'text': 'thescehie', 'confidence': 0.8139604926109314, 'text_region': [[1011.0, 520.0], [1086.0, 523.0], [1086.0, 532.0], [1011.0, 529.0]]}, {'text': '10Kandusedifferent', 'confidence': 0.955756425857544, 'text_region': [[903.0, 567.0], [1087.0, 567.0], [1087.0, 580.0], [903.0, 580.0]]}, {'text': 'ethods', 'confidence': 0.8542934060096741, 'text_region': [[915.0, 617.0], [961.0, 617.0], [961.0, 626.0], [915.0, 626.0]]}, {'text': 'vithdifferentnumbersofim', 'confidence': 0.988689124584198, 'text_region': [[866.0, 641.0], [1085.0, 641.0], [1085.0, 654.0], [866.0, 654.0]]}, {'text': 'datasets,anc', 'confidence': 0.945264995098114, 'text_region': [[978.0, 666.0], [1087.0, 666.0], [1087.0, 680.0], [978.0, 680.0]]}, {'text': 'Assnowr', 'confidence': 0.9079998731613159, 'text_region': [[1015.0, 692.0], [1086.0, 692.0], [1086.0, 701.0], [1015.0, 701.0]]}, {'text': '.e.', 'confidence': 0.9066272377967834, 'text_region': [[622.0, 741.0], [651.0, 741.0], [651.0, 750.0], [622.0, 750.0]]}, {'text': 'RandomWalk+Mo', 'confidence': 0.9356787204742432, 'text_region': [[648.0, 739.0], [806.0, 739.0], [806.0, 749.0], [648.0, 749.0]]}, {'text': 'evessignificantly', 'confidence': 0.9543812870979309, 'text_region': [[953.0, 738.0], [1085.0, 738.0], [1085.0, 751.0], [953.0, 751.0]]}, {'text': 'ntnumbersofim', 'confidence': 0.955245852470398, 'text_region': [[946.0, 762.0], [1086.0, 762.0], [1086.0, 775.0], [946.0, 775.0]]}, {'text': 'imagesgeneratec', 'confidence': 0.9700003862380981, 'text_region': [[952.0, 811.0], [1087.0, 811.0], [1087.0, 825.0], [952.0, 825.0]]}, {'text': 'tingfromthe', 'confidence': 0.9852132201194763, 'text_region': [[981.0, 833.0], [1086.0, 833.0], [1086.0, 846.0], [981.0, 846.0]]}, {'text': 'Targel', 'confidence': 0.8747634887695312, 'text_region': [[1039.0, 884.0], [1086.0, 884.0], [1086.0, 894.0], [1039.0, 894.0]]}, {'text': 'alCa', 'confidence': 0.5774177312850952, 'text_region': [[621.0, 910.0], [651.0, 910.0], [651.0, 920.0], [621.0, 920.0]]}, {'text': 'lomrotationonly', 'confidence': 0.9876928925514221, 'text_region': [[952.0, 930.0], [1085.0, 930.0], [1085.0, 943.0], [952.0, 943.0]]}, {'text': 'orrandomlocation,or', 'confidence': 0.9343878030776978, 'text_region': [[909.0, 953.0], [1087.0, 953.0], [1087.0, 967.0], [909.0, 967.0]]}, {'text': 'mtoRanaomviewpoin', 'confidence': 0.8728442192077637, 'text_region': [[621.0, 980.0], [801.0, 980.0], [801.0, 989.0], [621.0, 989.0]]}, {'text': 'size.', 'confidence': 0.9380003213882446, 'text_region': [[622.0, 1004.0], [656.0, 1004.0], [656.0, 1016.0], [622.0, 1016.0]]}, {'text': 'ctionofanchors,anc', 'confidence': 0.9691624045372009, 'text_region': [[915.0, 1024.0], [1087.0, 1025.0], [1087.0, 1039.0], [915.0, 1037.0]]}, {'text': 'erent', 'confidence': 0.8606599569320679, 'text_region': [[622.0, 1076.0], [665.0, 1076.0], [665.0, 1085.0], [622.0, 1085.0]]}, {'text': 'esyntne', 'confidence': 0.8282340168952942, 'text_region': [[1020.0, 1076.0], [1082.0, 1076.0], [1082.0, 1085.0], [1020.0, 1085.0]]}, {'text': 'ndomwalkbasec', 'confidence': 0.9542401432991028, 'text_region': [[952.0, 1096.0], [1087.0, 1096.0], [1087.0, 1109.0], [952.0, 1109.0]]}, {'text': 'selectionofman', 'confidence': 0.9949250817298889, 'text_region': [[945.0, 1120.0], [1086.0, 1121.0], [1086.0, 1134.0], [945.0, 1133.0]]}, {'text': 'pointOnlymethod', 'confidence': 0.9964770674705505, 'text_region': [[933.0, 1142.0], [1085.0, 1144.0], [1085.0, 1158.0], [933.0, 1157.0]]}, {'text': 'aTargeproportiono', 'confidence': 0.9665769934654236, 'text_region': [[620.0, 1170.0], [776.0, 1170.0], [776.0, 1183.0], [620.0, 1183.0]]}, {'text': 'is out-of-distributionfol', 'confidence': 0.9479197859764099, 'text_region': [[891.0, 1190.0], [1086.0, 1191.0], [1086.0, 1206.0], [891.0, 1205.0]]}, {'text': 'realimages.Thisexp', 'confidence': 0.9928857088088989, 'text_region': [[620.0, 1217.0], [797.0, 1215.0], [797.0, 1230.0], [620.0, 1231.0]]}, {'text': 'yitresultsintheworstper', 'confidence': 0.9989232420921326, 'text_region': [[864.0, 1211.0], [1086.0, 1215.0], [1086.0, 1234.0], [864.0, 1230.0]]}, {'text': 'FromFig.5 (b),the major observation is thatenviron-', 'confidence': 0.958723247051239, 'text_region': [[641.0, 1264.0], [1087.0, 1266.0], [1087.0, 1284.0], [641.0, 1283.0]]}, {'text': 'mentrandomizationmodu', 'confidence': 0.9978278875350952, 'text_region': [[620.0, 1291.0], [833.0, 1291.0], [833.0, 1304.0], [620.0, 1304.0]]}, {'text': 'improvesperformancesover', 'confidence': 0.9989569187164307, 'text_region': [[855.0, 1290.0], [1089.0, 1290.0], [1089.0, 1307.0], [855.0, 1307.0]]}, {'text': 'differentscenenumbersconsistently.Besides,theimprove', 'confidence': 0.9935029745101929, 'text_region': [[618.0, 1314.0], [1086.0, 1314.0], [1086.0, 1331.0], [618.0, 1331.0]]}, {'text': 'fewerscenes.Therefore', 'confidence': 0.9892236590385437, 'text_region': [[895.0, 1339.0], [1083.0, 1339.0], [1083.0, 1352.0], [895.0, 1352.0]]}, {'text': 'wecandrawaconclusionthat,theenvironmentrandom', 'confidence': 0.9956187605857849, 'text_region': [[618.0, 1362.0], [1085.0, 1362.0], [1085.0, 1379.0], [618.0, 1379.0]]}, {'text': 'izationhelpsincreaseimagediversityandatthesametime', 'confidence': 0.9969337582588196, 'text_region': [[620.0, 1384.0], [1086.0, 1384.0], [1086.0, 1401.0], [620.0, 1401.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 833, 573, 1040], 'res': [{'text': 'for1xschedulelong.Allthehyperparametersaresetto', 'confidence': 0.997097909450531, 'text_region': [[100.0, 834.0], [572.0, 835.0], [572.0, 853.0], [100.0, 852.0]]}, {'text': 'defaultvalues.Theresults aresummarizedinTab.3.We', 'confidence': 0.991206169128418, 'text_region': [[102.0, 858.0], [571.0, 858.0], [571.0, 876.0], [102.0, 876.0]]}, {'text': 'noticethatthetwosyntheticdatasetswithnaturalimages', 'confidence': 0.9958655834197998, 'text_region': [[103.0, 884.0], [570.0, 884.0], [570.0, 899.0], [103.0, 899.0]]}, {'text': 'asbackgrounds,i.e.SynthText andVISD,result in similar', 'confidence': 0.9467316269874573, 'text_region': [[101.0, 904.0], [570.0, 904.0], [570.0, 922.0], [101.0, 922.0]]}, {'text': 'performances.SynthText3DandourUnrealTextaresignif', 'confidence': 0.9977304339408875, 'text_region': [[101.0, 929.0], [570.0, 927.0], [570.0, 945.0], [101.0, 947.0]]}, {'text': 'icantlybetterthanthem.UnrealTextisfurtherasignificant', 'confidence': 0.9888250827789307, 'text_region': [[101.0, 953.0], [570.0, 953.0], [570.0, 971.0], [101.0, 971.0]]}, {'text': 'improvementoverSynthText3D.WhenwecombineUnre-', 'confidence': 0.9893824458122253, 'text_region': [[102.0, 976.0], [570.0, 976.0], [570.0, 995.0], [102.0, 995.0]]}, {'text': 'alText andSynthText,thetwohighlyscalableengines,the', 'confidence': 0.9802635908126831, 'text_region': [[102.0, 1001.0], [571.0, 1001.0], [571.0, 1020.0], [102.0, 1020.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [99, 1359, 574, 1426], 'res': [{'text': 'tualscenesliesinthescenediversity.Inthissection,we', 'confidence': 0.9913384914398193, 'text_region': [[103.0, 1385.0], [568.0, 1385.0], [568.0, 1400.0], [103.0, 1400.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [98, 1322, 435, 1341], 'res': [{'text': '', 'confidence': 0.0, 'text_region': [[134.0, 1329.0], [201.0, 1329.0], [201.0, 1333.0], [134.0, 1333.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [113, 742, 562, 783], 'res': [{'text': 'Detection', 'confidence': 0.9967917203903198, 'text_region': [[185.0, 746.0], [262.0, 746.0], [262.0, 759.0], [185.0, 759.0]]}, {'text': '1performances', 'confidence': 0.9889928102493286, 'text_region': [[258.0, 747.0], [383.0, 747.0], [383.0, 760.0], [258.0, 760.0]]}, {'text': '', 'confidence': 0.0, 'text_region': [[380.0, 748.0], [391.0, 748.0], [391.0, 757.0], [380.0, 757.0]]}, {'text': 'O1', 'confidence': 0.6371607780456543, 'text_region': [[389.0, 748.0], [406.0, 748.0], [406.0, 757.0], [389.0, 757.0]]}, {'text': '', 'confidence': 0.0, 'text_region': [[404.0, 747.0], [419.0, 747.0], [419.0, 756.0], [404.0, 756.0]]}, {'text': 'EAST', 'confidence': 0.9992099404335022, 'text_region': [[416.0, 746.0], [467.0, 746.0], [467.0, 759.0], [416.0, 759.0]]}, {'text': 'models', 'confidence': 0.9924160838127136, 'text_region': [[472.0, 746.0], [544.0, 746.0], [544.0, 759.0], [472.0, 759.0]]}, {'text': 'pI', 'confidence': 0.6915718913078308, 'text_region': [[541.0, 748.0], [559.0, 748.0], [559.0, 757.0], [541.0, 757.0]]}, {'text': 'ained', 'confidence': 0.8971425890922546, 'text_region': [[116.0, 770.0], [154.0, 770.0], [154.0, 779.0], [116.0, 779.0]]}, {'text': 'datasets', 'confidence': 0.9790814518928528, 'text_region': [[474.0, 770.0], [536.0, 770.0], [536.0, 779.0], [474.0, 779.0]]}], 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [100, 1060, 573, 1222], 'res': '', 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [101, 158, 570, 738], 'res': '', 'img_idx': 0}\n",
      "{'type': 'table_caption', 'bbox': [220, 146, 448, 161], 'res': [{'text': 'EyaluationonICDAR201', 'confidence': 0.9362331628799438, 'text_region': [[229.0, 149.0], [439.0, 149.0], [439.0, 160.0], [229.0, 160.0]]}], 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [99, 1232, 571, 1274], 'res': [{'text': 'Detection', 'confidence': 0.9963655471801758, 'text_region': [[179.0, 1234.0], [261.0, 1237.0], [261.0, 1251.0], [179.0, 1248.0]]}, {'text': '(Box-AP/Mask-AP)ofMask-', 'confidence': 0.9531750082969666, 'text_region': [[329.0, 1232.0], [569.0, 1232.0], [569.0, 1249.0], [329.0, 1249.0]]}, {'text': 'R', 'confidence': 0.9220159649848938, 'text_region': [[103.0, 1261.0], [117.0, 1261.0], [117.0, 1270.0], [103.0, 1270.0]]}, {'text': 'data', 'confidence': 0.9964890480041504, 'text_region': [[459.0, 1260.0], [492.0, 1260.0], [492.0, 1273.0], [459.0, 1273.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:41:53] ppocr DEBUG: dt_boxes num : 21, elapsed : 0.18837809562683105\n",
      "[2024/05/30 16:41:55] ppocr DEBUG: rec_res num  : 21, elapsed : 2.374300479888916\n",
      "[2024/05/30 16:41:55] ppocr DEBUG: dt_boxes num : 22, elapsed : 0.10414266586303711\n",
      "[2024/05/30 16:41:58] ppocr DEBUG: rec_res num  : 22, elapsed : 2.193692922592163\n",
      "[2024/05/30 16:41:58] ppocr DEBUG: dt_boxes num : 15, elapsed : 0.1431286334991455\n",
      "[2024/05/30 16:41:59] ppocr DEBUG: rec_res num  : 15, elapsed : 1.6963365077972412\n",
      "[2024/05/30 16:42:00] ppocr DEBUG: dt_boxes num : 12, elapsed : 0.13464784622192383\n",
      "[2024/05/30 16:42:01] ppocr DEBUG: rec_res num  : 12, elapsed : 1.4855928421020508\n",
      "[2024/05/30 16:42:01] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.09725618362426758\n",
      "[2024/05/30 16:42:01] ppocr DEBUG: rec_res num  : 2, elapsed : 0.2533149719238281\n",
      "[2024/05/30 16:42:01] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.08305072784423828\n",
      "[2024/05/30 16:42:02] ppocr DEBUG: rec_res num  : 2, elapsed : 0.14124727249145508\n",
      "[2024/05/30 16:42:02] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.053140878677368164\n",
      "[2024/05/30 16:42:02] ppocr DEBUG: rec_res num  : 1, elapsed : 0.18862462043762207\n",
      "[2024/05/30 16:42:02] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.07902789115905762\n",
      "[2024/05/30 16:42:02] ppocr DEBUG: rec_res num  : 1, elapsed : 0.0770254135131836\n",
      "[2024/05/30 16:42:02] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.08121728897094727\n",
      "[2024/05/30 16:42:02] ppocr DEBUG: rec_res num  : 1, elapsed : 0.13084840774536133\n",
      "[2024/05/30 16:42:02] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.06639599800109863\n",
      "[2024/05/30 16:42:03] ppocr DEBUG: rec_res num  : 2, elapsed : 0.23507261276245117\n",
      "[2024/05/30 16:42:03] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.05796957015991211\n",
      "[2024/05/30 16:42:03] ppocr DEBUG: rec_res num  : 0, elapsed : 1.9073486328125e-06\n",
      "[2024/05/30 16:42:03] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.06801438331604004\n",
      "[2024/05/30 16:42:03] ppocr DEBUG: rec_res num  : 1, elapsed : 0.05468630790710449\n",
      "[2024/05/30 16:42:03] ppocr DEBUG: dt_boxes num : 36, elapsed : 0.14068245887756348\n",
      "[2024/05/30 16:42:04] ppocr DEBUG: rec_res num  : 36, elapsed : 1.1832215785980225\n",
      "[2024/05/30 16:42:04] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.08875036239624023\n",
      "[2024/05/30 16:42:04] ppocr DEBUG: rec_res num  : 8, elapsed : 0.2647418975830078\n",
      "[2024/05/30 16:42:04] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.05505037307739258\n",
      "[2024/05/30 16:42:05] ppocr DEBUG: rec_res num  : 3, elapsed : 0.24231934547424316\n",
      "[2024/05/30 16:42:05] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.02223801612854004\n",
      "[2024/05/30 16:42:05] ppocr DEBUG: rec_res num  : 1, elapsed : 0.17557764053344727\n",
      "{'type': 'text', 'bbox': [615, 857, 1090, 1365], 'res': [{'text': 'AlthoughMLT2017hasbeenwidelyusedasabenchmark', 'confidence': 0.9883790612220764, 'text_region': [[619.0, 859.0], [1088.0, 858.0], [1088.0, 875.0], [619.0, 876.0]]}, {'text': 'fordetection,thetaskofrecognizingmultilingualscenetext', 'confidence': 0.9960968494415283, 'text_region': [[617.0, 880.0], [1088.0, 882.0], [1088.0, 902.0], [617.0, 900.0]]}, {'text': 'stillremainslargelyuntouched,mainlyduetolackof', 'confidence': 0.9874870181083679, 'text_region': [[619.0, 907.0], [1087.0, 907.0], [1087.0, 923.0], [619.0, 923.0]]}, {'text': 'proper trainingdataset.Topave thewayforfutureresearch.', 'confidence': 0.9756561517715454, 'text_region': [[618.0, 929.0], [1087.0, 927.0], [1087.0, 947.0], [618.0, 949.0]]}, {'text': 'wealsogenerate a multilingualversionwith600Kimages', 'confidence': 0.9793694019317627, 'text_region': [[618.0, 952.0], [1088.0, 952.0], [1088.0, 972.0], [618.0, 972.0]]}, {'text': 'containing 10languages asincludedinMLT 2019[26]:', 'confidence': 0.9619884490966797, 'text_region': [[618.0, 976.0], [1088.0, 975.0], [1088.0, 995.0], [618.0, 996.0]]}, {'text': 'Arabic,Bangla,Chinese,English,French,German,Hindi', 'confidence': 0.959475040435791, 'text_region': [[619.0, 1001.0], [1087.0, 1001.0], [1087.0, 1018.0], [619.0, 1018.0]]}, {'text': 'Italian,Japanese,andKorean.Text contents aresampled', 'confidence': 0.9680902361869812, 'text_region': [[619.0, 1024.0], [1088.0, 1024.0], [1088.0, 1044.0], [619.0, 1044.0]]}, {'text': 'fromcorpusextractedfromtheWikimediadump?', 'confidence': 0.9811220169067383, 'text_region': [[617.0, 1048.0], [1020.0, 1046.0], [1020.0, 1067.0], [617.0, 1068.0]]}, {'text': 'ModelWeusethesamemodel andimplementation asSec', 'confidence': 0.9807167649269104, 'text_region': [[617.0, 1076.0], [1086.0, 1077.0], [1086.0, 1097.0], [617.0, 1096.0]]}, {'text': 'tion5.1,except that the symbolstorecognize areexpanded', 'confidence': 0.9766616821289062, 'text_region': [[619.0, 1102.0], [1088.0, 1102.0], [1088.0, 1122.0], [619.0, 1122.0]]}, {'text': 'to all characters that appearinthegenerated dataset.', 'confidence': 0.9623708724975586, 'text_region': [[617.0, 1126.0], [1035.0, 1125.0], [1035.0, 1145.0], [617.0, 1146.0]]}, {'text': 'TrainingandEvaluationDataWecropfromtheproposed', 'confidence': 0.9984611868858337, 'text_region': [[618.0, 1156.0], [1089.0, 1156.0], [1089.0, 1175.0], [618.0, 1175.0]]}, {'text': 'multilingualdataset.Wediscardimageswithwidthsshorter', 'confidence': 0.9936204552650452, 'text_region': [[620.0, 1181.0], [1088.0, 1181.0], [1088.0, 1198.0], [620.0, 1198.0]]}, {'text': 'than32pixels as they aretooblurry,and obtain4.1Mword', 'confidence': 0.9789714217185974, 'text_region': [[617.0, 1203.0], [1089.0, 1202.0], [1089.0, 1222.0], [617.0, 1223.0]]}, {'text': 'images intotal.We compare withthemultilingualversion', 'confidence': 0.9672912359237671, 'text_region': [[619.0, 1227.0], [1089.0, 1227.0], [1089.0, 1247.0], [619.0, 1247.0]]}, {'text': 'ofSynthTextprovidedbyMLT2019competitionthatcon-', 'confidence': 0.996821403503418, 'text_region': [[618.0, 1252.0], [1088.0, 1252.0], [1088.0, 1272.0], [618.0, 1272.0]]}, {'text': 'tains atotalnumber1.2Mimages.Forevaluation,weran-', 'confidence': 0.9778071641921997, 'text_region': [[618.0, 1276.0], [1087.0, 1277.0], [1087.0, 1295.0], [618.0, 1294.0]]}, {'text': 'domlysplit1500imagesforeachlanguage(includingsym-', 'confidence': 0.9804455637931824, 'text_region': [[617.0, 1298.0], [1088.0, 1300.0], [1088.0, 1319.0], [617.0, 1317.0]]}, {'text': 'bols and mixed) from the training set of MLT 2019. The', 'confidence': 0.966960072517395, 'text_region': [[617.0, 1321.0], [1089.0, 1321.0], [1089.0, 1344.0], [617.0, 1344.0]]}, {'text': 'restofthetrainingsetisusedfortraining', 'confidence': 0.9972880482673645, 'text_region': [[617.0, 1346.0], [949.0, 1347.0], [948.0, 1364.0], [617.0, 1364.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [615, 198, 1090, 724], 'res': [{'text': 'Experiment results are summarized in Tab.7.First,we', 'confidence': 0.985963761806488, 'text_region': [[618.0, 199.0], [1089.0, 199.0], [1089.0, 220.0], [618.0, 220.0]]}, {'text': 'compareourmethodwithprevioussyntheticdatasets.We', 'confidence': 0.9953710436820984, 'text_region': [[617.0, 223.0], [1089.0, 222.0], [1089.0, 242.0], [617.0, 243.0]]}, {'text': 'havetolimitthesizeoftrainingdatasetsto1Msince', 'confidence': 0.9987282752990723, 'text_region': [[618.0, 248.0], [1088.0, 248.0], [1088.0, 266.0], [618.0, 266.0]]}, {'text': 'VISDonlypublishes1Mwordimages.Oursynthetic data', 'confidence': 0.9900633692741394, 'text_region': [[618.0, 270.0], [1089.0, 271.0], [1089.0, 292.0], [618.0, 290.0]]}, {'text': 'achieves consistentimprovements on all datasets.Espe-', 'confidence': 0.9750930070877075, 'text_region': [[618.0, 295.0], [1086.0, 295.0], [1086.0, 315.0], [618.0, 315.0]]}, {'text': 'cially,itsurpasses other syntheticdatasetsbyaconsider', 'confidence': 0.9788001179695129, 'text_region': [[619.0, 320.0], [1086.0, 320.0], [1086.0, 338.0], [619.0, 338.0]]}, {'text': 'ablemarginondatasetswithdiversetextstylesandcomplex', 'confidence': 0.9931524395942688, 'text_region': [[618.0, 342.0], [1088.0, 342.0], [1088.0, 362.0], [618.0, 362.0]]}, {'text': 'backgrounds such as SVTP(+2.4%).The experiments ver-', 'confidence': 0.9793388843536377, 'text_region': [[618.0, 364.0], [1087.0, 365.0], [1087.0, 386.0], [618.0, 385.0]]}, {'text': 'ifytheeffectivenessofoursynthesismethodinscenetext', 'confidence': 0.9961482882499695, 'text_region': [[619.0, 391.0], [1088.0, 391.0], [1088.0, 409.0], [619.0, 409.0]]}, {'text': 'recognitionespeciallyinthecomplexcases.', 'confidence': 0.9939264059066772, 'text_region': [[619.0, 416.0], [966.0, 416.0], [966.0, 433.0], [619.0, 433.0]]}, {'text': 'Sincesmall scaleexperimentsarenotveryhelpfulin', 'confidence': 0.9880438446998596, 'text_region': [[641.0, 442.0], [1089.0, 444.0], [1089.0, 464.0], [641.0, 463.0]]}, {'text': 'howresearchersshouldutilizethesedatasets,wefurther', 'confidence': 0.9802700281143188, 'text_region': [[618.0, 468.0], [1088.0, 468.0], [1088.0, 486.0], [618.0, 486.0]]}, {'text': 'trainmodelsoncombinationsofSynth90K,SynthText,and', 'confidence': 0.9744471311569214, 'text_region': [[619.0, 493.0], [1088.0, 493.0], [1088.0, 510.0], [619.0, 510.0]]}, {'text': 'ours.Wefirstlimitthetotalnumberoftrainingimagesto', 'confidence': 0.9976212382316589, 'text_region': [[618.0, 515.0], [1088.0, 518.0], [1088.0, 535.0], [618.0, 533.0]]}, {'text': '9M.Whenwe train ona combination of all3 synthetic', 'confidence': 0.9511672854423523, 'text_region': [[616.0, 538.0], [1088.0, 539.0], [1088.0, 560.0], [616.0, 559.0]]}, {'text': 'datasets,with3Meach,themodelperformsbetterthanthe', 'confidence': 0.9819741249084473, 'text_region': [[619.0, 565.0], [1087.0, 565.0], [1087.0, 582.0], [619.0, 582.0]]}, {'text': 'model trainedon4.5M× 2 datasets only.Wefurther ob-', 'confidence': 0.9555642008781433, 'text_region': [[618.0, 586.0], [1087.0, 587.0], [1087.0, 608.0], [618.0, 607.0]]}, {'text': 'serve that training on3M×3 syntheticdatasets is com-', 'confidence': 0.934613823890686, 'text_region': [[618.0, 611.0], [1086.0, 612.0], [1086.0, 633.0], [618.0, 632.0]]}, {'text': 'parabletotrainingonthewholeSynth9oKandSynthText', 'confidence': 0.9861438274383545, 'text_region': [[619.0, 638.0], [1087.0, 638.0], [1087.0, 655.0], [619.0, 655.0]]}, {'text': 'while using muchfewer training data.This result suggests', 'confidence': 0.9651558995246887, 'text_region': [[617.0, 656.0], [1089.0, 659.0], [1089.0, 680.0], [617.0, 677.0]]}, {'text': 'thatthebestpracticeis tocombine theproposed synthetic', 'confidence': 0.9753973484039307, 'text_region': [[618.0, 683.0], [1088.0, 683.0], [1088.0, 703.0], [618.0, 703.0]]}, {'text': 'datasetwithpreviousones.', 'confidence': 0.9925961494445801, 'text_region': [[618.0, 706.0], [831.0, 709.0], [831.0, 723.0], [618.0, 723.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [99, 699, 573, 1054], 'res': [{'text': 'ModelWeselectawidelyacceptedbaselinemethod', 'confidence': 0.9977442622184753, 'text_region': [[101.0, 702.0], [570.0, 701.0], [570.0, 718.0], [101.0, 719.0]]}, {'text': 'ASTER [39], and adopt the implementation? that ranks top-', 'confidence': 0.9904603958129883, 'text_region': [[99.0, 721.0], [570.0, 722.0], [570.0, 746.0], [99.0, 745.0]]}, {'text': '1ontheICDAR2019ArTcompetitiononcurvedscenetext', 'confidence': 0.9955717921257019, 'text_region': [[102.0, 749.0], [571.0, 749.0], [571.0, 767.0], [102.0, 767.0]]}, {'text': 'recognition(Latin)by[20].Themodelsaretrainedwith a', 'confidence': 0.9684461951255798, 'text_region': [[101.0, 773.0], [570.0, 771.0], [570.0, 789.0], [101.0, 791.0]]}, {'text': 'batchsizeof512.Atotalof95symbolsarerecognized', 'confidence': 0.9988839030265808, 'text_region': [[102.0, 796.0], [570.0, 796.0], [570.0, 813.0], [102.0, 813.0]]}, {'text': 'includinganEnd-of-Sentencemark,52casesensitive al-', 'confidence': 0.9795902371406555, 'text_region': [[102.0, 820.0], [570.0, 819.0], [570.0, 837.0], [102.0, 838.0]]}, {'text': 'phabets,10 digits,and 32printable punctuation symbols.', 'confidence': 0.9665298461914062, 'text_region': [[100.0, 843.0], [554.0, 842.0], [554.0, 862.0], [100.0, 863.0]]}, {'text': 'Training Datasets From the 600K English synthetic im-', 'confidence': 0.9533580541610718, 'text_region': [[102.0, 869.0], [569.0, 869.0], [569.0, 890.0], [102.0, 890.0]]}, {'text': 'ages,we obtain a total number of 12Mword-level image', 'confidence': 0.9564895033836365, 'text_region': [[99.0, 893.0], [571.0, 892.0], [571.0, 913.0], [99.0, 914.0]]}, {'text': 'regions tomake our training dataset.Alsonote that,our', 'confidence': 0.9589901566505432, 'text_region': [[100.0, 918.0], [572.0, 916.0], [572.0, 936.0], [100.0, 938.0]]}, {'text': 'synthetic dataset providecharacterlevel annotations,which', 'confidence': 0.9792017936706543, 'text_region': [[100.0, 940.0], [572.0, 938.0], [572.0, 959.0], [100.0, 961.0]]}, {'text': 'willbeusefulinsomerecognition algorithms.', 'confidence': 0.988320529460907, 'text_region': [[102.0, 964.0], [466.0, 964.0], [466.0, 984.0], [102.0, 984.0]]}, {'text': 'EvaluationDatasetsWeevaluatemodelstrainedondif', 'confidence': 0.9918760061264038, 'text_region': [[101.0, 990.0], [570.0, 990.0], [570.0, 1008.0], [101.0, 1008.0]]}, {'text': 'ferentsyntheticdatasetsonseveralwidelyusedrealimage', 'confidence': 0.9880861639976501, 'text_region': [[100.0, 1013.0], [571.0, 1014.0], [571.0, 1034.0], [100.0, 1033.0]]}, {'text': 'datasets:IIIT[25].SVT[45].ICDAR2015（IC15）[13]', 'confidence': 0.9210066795349121, 'text_region': [[103.0, 1038.0], [565.0, 1038.0], [565.0, 1052.0], [103.0, 1052.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 1087, 572, 1366], 'res': [{'text': 'Someofthesedatasets,however,haveincompletean', 'confidence': 0.9889153838157654, 'text_region': [[125.0, 1088.0], [569.0, 1090.0], [569.0, 1107.0], [125.0, 1105.0]]}, {'text': 'notations,includingIIT,SVT,SVTP,CUTE.Whilethe', 'confidence': 0.9314181208610535, 'text_region': [[102.0, 1112.0], [570.0, 1112.0], [570.0, 1129.0], [102.0, 1129.0]]}, {'text': 'wordimagesinthesedatasetscontainpunctuationsymbols', 'confidence': 0.9973997473716736, 'text_region': [[101.0, 1134.0], [569.0, 1135.0], [569.0, 1155.0], [101.0, 1154.0]]}, {'text': 'digits,upper-case andlower-case characters,the aforemen', 'confidence': 0.9718793630599976, 'text_region': [[101.0, 1160.0], [568.0, 1160.0], [568.0, 1179.0], [101.0, 1179.0]]}, {'text': 'tioneddatasets,intheircurrentforms,onlyprovidecase', 'confidence': 0.9728795886039734, 'text_region': [[101.0, 1183.0], [568.0, 1185.0], [568.0, 1201.0], [101.0, 1199.0]]}, {'text': 'insensitiveannotationsandignoreallpunctuationsymbols', 'confidence': 0.9986438751220703, 'text_region': [[101.0, 1207.0], [568.0, 1208.0], [568.0, 1226.0], [101.0, 1225.0]]}, {'text': 'Inorderformorecomprehensiveevaluationofscenetext', 'confidence': 0.9985525012016296, 'text_region': [[101.0, 1231.0], [570.0, 1231.0], [570.0, 1251.0], [101.0, 1251.0]]}, {'text': 'recognition,were-annotatethese4datasetsinacase-', 'confidence': 0.9893271923065186, 'text_region': [[101.0, 1257.0], [570.0, 1257.0], [570.0, 1273.0], [101.0, 1273.0]]}, {'text': 'sensitivewayandalsoincludepunctuationsymbols.We', 'confidence': 0.9992144107818604, 'text_region': [[100.0, 1280.0], [571.0, 1280.0], [571.0, 1299.0], [100.0, 1299.0]]}, {'text': 'alsorelease thenewannotationsandwebelievethatthey', 'confidence': 0.9892290234565735, 'text_region': [[99.0, 1301.0], [570.0, 1303.0], [570.0, 1322.0], [99.0, 1320.0]]}, {'text': 'willbecomebetterbenchmarksforscenetextrecognition', 'confidence': 0.9982931017875671, 'text_region': [[100.0, 1324.0], [570.0, 1326.0], [570.0, 1346.0], [100.0, 1344.0]]}, {'text': 'inthefuture', 'confidence': 0.9734378457069397, 'text_region': [[101.0, 1349.0], [197.0, 1353.0], [196.0, 1365.0], [101.0, 1363.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [99, 529, 574, 595], 'res': [{'text': 'hingscene', 'confidence': 0.926237940788269, 'text_region': [[494.0, 534.0], [570.0, 532.0], [570.0, 545.0], [494.0, 548.0]]}, {'text': 'textdetectionmodels,wealsoverifyitseffectivenessinthe', 'confidence': 0.9897050857543945, 'text_region': [[102.0, 554.0], [571.0, 554.0], [571.0, 571.0], [102.0, 571.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [100, 410, 564, 452], 'res': [{'text': 'random', 'confidence': 0.9977168440818787, 'text_region': [[101.0, 415.0], [168.0, 414.0], [168.0, 427.0], [101.0, 428.0]]}, {'text': 'differentreal-worldvari', 'confidence': 0.9747920632362366, 'text_region': [[369.0, 413.0], [563.0, 413.0], [563.0, 430.0], [369.0, 430.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [109, 1061, 430, 1078], 'res': [{'text': '1（77e.1341andlota-/ert', 'confidence': 0.5482667088508606, 'text_region': [[173.0, 1066.0], [408.0, 1066.0], [408.0, 1073.0], [173.0, 1073.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [616, 764, 998, 823], 'res': [{'text': '5.2.1Settings', 'confidence': 0.9884315729141235, 'text_region': [[619.0, 803.0], [746.0, 807.0], [745.0, 822.0], [619.0, 822.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [99, 485, 528, 508], 'res': [{'text': ':extRecogni', 'confidence': 0.8914282321929932, 'text_region': [[347.0, 491.0], [485.0, 491.0], [485.0, 501.0], [347.0, 501.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [618, 149, 846, 167], 'res': [{'text': '', 'confidence': 0.0, 'text_region': [[627.0, 155.0], [653.0, 155.0], [653.0, 160.0], [627.0, 160.0]]}, {'text': 'Exnermentkesit', 'confidence': 0.8092010617256165, 'text_region': [[677.0, 154.0], [834.0, 154.0], [834.0, 162.0], [677.0, 162.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [101, 659, 223, 675], 'res': [], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [102, 660, 358, 675], 'res': [{'text': 'Settungs', 'confidence': 0.9060064554214478, 'text_region': [[163.0, 661.0], [227.0, 663.0], [225.0, 673.0], [161.0, 671.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure', 'bbox': [109, 136, 552, 315], 'res': [{'text': 'Ablating Viewfinder', 'confidence': 0.9805457592010498, 'text_region': [[191.0, 143.0], [273.0, 143.0], [273.0, 156.0], [191.0, 156.0]]}, {'text': 'Ablating Environment Randomization', 'confidence': 0.9912787079811096, 'text_region': [[366.0, 143.0], [520.0, 143.0], [520.0, 156.0], [366.0, 156.0]]}, {'text': '$', 'confidence': 0.3249269723892212, 'text_region': [[134.0, 156.0], [142.0, 148.0], [150.0, 155.0], [142.0, 163.0]]}, {'text': 'Random Walk +Manual Anchor (Ful)', 'confidence': 0.9700533151626587, 'text_region': [[180.0, 157.0], [313.0, 157.0], [313.0, 170.0], [180.0, 170.0]]}, {'text': 'Random Viewpoint +Manual Anchor', 'confidence': 0.9343494772911072, 'text_region': [[182.0, 166.0], [311.0, 166.0], [311.0, 178.0], [182.0, 178.0]]}, {'text': '70', 'confidence': 0.9979478120803833, 'text_region': [[347.0, 159.0], [361.0, 159.0], [361.0, 170.0], [347.0, 170.0]]}, {'text': 'W/OEnvRand', 'confidence': 0.8594198226928711, 'text_region': [[459.0, 167.0], [523.0, 166.0], [523.0, 176.0], [459.0, 177.0]]}, {'text': 'With Env Rand', 'confidence': 0.9626045823097229, 'text_region': [[461.0, 158.0], [524.0, 158.0], [524.0, 168.0], [461.0, 168.0]]}, {'text': '70', 'confidence': 0.9993896484375, 'text_region': [[137.0, 175.0], [149.0, 175.0], [149.0, 184.0], [137.0, 184.0]]}, {'text': 'Random Viewpoint Only', 'confidence': 0.9742218255996704, 'text_region': [[179.0, 173.0], [273.0, 173.0], [273.0, 185.0], [179.0, 185.0]]}, {'text': '65', 'confidence': 0.9841792583465576, 'text_region': [[347.0, 184.0], [361.0, 184.0], [361.0, 196.0], [347.0, 196.0]]}, {'text': '60', 'confidence': 0.8903038501739502, 'text_region': [[123.0, 198.0], [148.0, 194.0], [151.0, 208.0], [125.0, 212.0]]}, {'text': 'L', 'confidence': 0.3032510280609131, 'text_region': [[338.0, 199.0], [347.0, 199.0], [347.0, 210.0], [338.0, 210.0]]}, {'text': '&', 'confidence': 0.2821371555328369, 'text_region': [[129.0, 212.0], [138.0, 212.0], [138.0, 222.0], [129.0, 222.0]]}, {'text': '2', 'confidence': 0.3083866238594055, 'text_region': [[246.0, 219.0], [251.0, 219.0], [251.0, 224.0], [246.0, 224.0]]}, {'text': '55', 'confidence': 0.996710479259491, 'text_region': [[339.0, 231.0], [360.0, 231.0], [360.0, 244.0], [339.0, 244.0]]}, {'text': '40', 'confidence': 0.9723036885261536, 'text_region': [[139.0, 246.0], [148.0, 246.0], [148.0, 254.0], [139.0, 254.0]]}, {'text': '50', 'confidence': 0.9994211196899414, 'text_region': [[348.0, 257.0], [359.0, 257.0], [359.0, 267.0], [348.0, 267.0]]}, {'text': '5', 'confidence': 0.11109684407711029, 'text_region': [[413.0, 253.0], [419.0, 253.0], [419.0, 258.0], [413.0, 258.0]]}, {'text': '2', 'confidence': 0.6966790556907654, 'text_region': [[177.0, 290.0], [183.0, 287.0], [186.0, 292.0], [181.0, 295.0]]}, {'text': '4', 'confidence': 0.9474388957023621, 'text_region': [[214.0, 289.0], [220.0, 289.0], [220.0, 294.0], [214.0, 294.0]]}, {'text': '8', 'confidence': 0.5119163393974304, 'text_region': [[278.0, 289.0], [284.0, 289.0], [284.0, 294.0], [278.0, 294.0]]}, {'text': '10', 'confidence': 0.9985992908477783, 'text_region': [[312.0, 287.0], [320.0, 287.0], [320.0, 295.0], [312.0, 295.0]]}, {'text': '45', 'confidence': 0.9987220168113708, 'text_region': [[349.0, 281.0], [359.0, 281.0], [359.0, 290.0], [349.0, 290.0]]}, {'text': 'number of training images / K', 'confidence': 0.9943647980690002, 'text_region': [[175.0, 294.0], [290.0, 294.0], [290.0, 307.0], [175.0, 307.0]]}, {'text': '6', 'confidence': 0.782867968082428, 'text_region': [[242.0, 292.0], [249.0, 286.0], [256.0, 292.0], [249.0, 299.0]]}, {'text': 'L', 'confidence': 0.8475948572158813, 'text_region': [[357.0, 290.0], [362.0, 290.0], [362.0, 294.0], [357.0, 294.0]]}, {'text': '5', 'confidence': 0.9840636253356934, 'text_region': [[385.0, 289.0], [390.0, 289.0], [390.0, 294.0], [385.0, 294.0]]}, {'text': 'number of scenes', 'confidence': 0.9718326330184937, 'text_region': [[407.0, 292.0], [479.0, 295.0], [479.0, 308.0], [406.0, 306.0]]}, {'text': '10', 'confidence': 0.9991132020950317, 'text_region': [[412.0, 287.0], [424.0, 287.0], [424.0, 295.0], [412.0, 295.0]]}, {'text': '15', 'confidence': 0.9996649026870728, 'text_region': [[438.0, 287.0], [450.0, 287.0], [450.0, 295.0], [438.0, 295.0]]}, {'text': '20', 'confidence': 0.9985833168029785, 'text_region': [[464.0, 287.0], [477.0, 287.0], [477.0, 295.0], [464.0, 295.0]]}, {'text': '25', 'confidence': 0.9993650317192078, 'text_region': [[493.0, 285.0], [507.0, 285.0], [507.0, 296.0], [493.0, 296.0]]}, {'text': '90', 'confidence': 0.6363427042961121, 'text_region': [[523.0, 289.0], [530.0, 289.0], [530.0, 295.0], [523.0, 295.0]]}, {'text': '5', 'confidence': 0.13223884999752045, 'text_region': [[222.0, 309.0], [227.0, 305.0], [233.0, 310.0], [228.0, 314.0]]}, {'text': '(b)', 'confidence': 0.3936223089694977, 'text_region': [[433.0, 308.0], [446.0, 308.0], [446.0, 314.0], [433.0, 314.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [98, 316, 571, 359], 'res': [{'text': 'Figure5:', 'confidence': 0.9753282070159912, 'text_region': [[100.0, 319.0], [174.0, 320.0], [174.0, 335.0], [100.0, 333.0]]}, {'text': 'Results', 'confidence': 0.9956756830215454, 'text_region': [[183.0, 320.0], [241.0, 320.0], [241.0, 333.0], [183.0, 333.0]]}, {'text': 'OI', 'confidence': 0.693696141242981, 'text_region': [[248.0, 323.0], [264.0, 323.0], [264.0, 332.0], [248.0, 332.0]]}, {'text': '', 'confidence': 0.0, 'text_region': [[262.0, 323.0], [272.0, 323.0], [272.0, 332.0], [262.0, 332.0]]}, {'text': 'ablation', 'confidence': 0.8795992136001587, 'text_region': [[271.0, 323.0], [332.0, 323.0], [332.0, 332.0], [271.0, 332.0]]}, {'text': 'ablating', 'confidence': 0.9891222715377808, 'text_region': [[415.0, 320.0], [485.0, 321.0], [485.0, 335.0], [415.0, 333.0]]}, {'text': 'viewfinder', 'confidence': 0.8923537135124207, 'text_region': [[480.0, 321.0], [569.0, 319.0], [569.0, 332.0], [480.0, 335.0]]}, {'text': 'module', 'confidence': 0.9583420753479004, 'text_region': [[490.0, 346.0], [550.0, 346.0], [550.0, 355.0], [490.0, 355.0]]}], 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [113, 1389, 417, 1425], 'res': [{'text': 'https://github.com/Jyouhou/', 'confidence': 0.9915274381637573, 'text_region': [[127.0, 1389.0], [385.0, 1390.0], [385.0, 1406.0], [127.0, 1405.0]]}, {'text': 'DARZ0T', 'confidence': 0.7245912551879883, 'text_region': [[117.0, 1414.0], [172.0, 1414.0], [172.0, 1422.0], [117.0, 1422.0]]}, {'text': 'chemr', 'confidence': 0.8577151298522949, 'text_region': [[374.0, 1414.0], [413.0, 1414.0], [413.0, 1422.0], [374.0, 1422.0]]}], 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [632, 1408, 904, 1427], 'res': [{'text': 'https://dumps.wikimed1a.oro', 'confidence': 0.9009872674942017, 'text_region': [[647.0, 1413.0], [898.0, 1414.0], [898.0, 1422.0], [647.0, 1422.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:42:05] ppocr DEBUG: dt_boxes num : 14, elapsed : 0.16443085670471191\n",
      "[2024/05/30 16:42:07] ppocr DEBUG: rec_res num  : 14, elapsed : 1.776482105255127\n",
      "[2024/05/30 16:42:07] ppocr DEBUG: dt_boxes num : 8, elapsed : 0.12334513664245605\n",
      "[2024/05/30 16:42:08] ppocr DEBUG: rec_res num  : 8, elapsed : 0.8822612762451172\n",
      "[2024/05/30 16:42:08] ppocr DEBUG: dt_boxes num : 14, elapsed : 0.07858848571777344\n",
      "[2024/05/30 16:42:10] ppocr DEBUG: rec_res num  : 14, elapsed : 1.6807997226715088\n",
      "[2024/05/30 16:42:10] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.0808415412902832\n",
      "[2024/05/30 16:42:10] ppocr DEBUG: rec_res num  : 1, elapsed : 0.13961243629455566\n",
      "[2024/05/30 16:42:10] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.13461756706237793\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: rec_res num  : 6, elapsed : 0.4050936698913574\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.05531811714172363\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: rec_res num  : 1, elapsed : 0.1513218879699707\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.054960012435913086\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: rec_res num  : 0, elapsed : 2.1457672119140625e-06\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.0653078556060791\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: rec_res num  : 1, elapsed : 0.15250825881958008\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.049433231353759766\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: rec_res num  : 0, elapsed : 1.9073486328125e-06\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.05563998222351074\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: rec_res num  : 1, elapsed : 0.10813450813293457\n",
      "[2024/05/30 16:42:11] ppocr DEBUG: dt_boxes num : 30, elapsed : 0.19850707054138184\n",
      "[2024/05/30 16:42:15] ppocr DEBUG: rec_res num  : 30, elapsed : 3.4131076335906982\n",
      "[2024/05/30 16:42:15] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.08099198341369629\n",
      "[2024/05/30 16:42:15] ppocr DEBUG: rec_res num  : 2, elapsed : 0.22749018669128418\n",
      "{'type': 'text', 'bbox': [98, 1096, 573, 1426], 'res': [{'text': 'Thereareseveralaspectsthatareworthdivingdeeper', 'confidence': 0.9969345331192017, 'text_region': [[126.0, 1099.0], [571.0, 1099.0], [571.0, 1117.0], [126.0, 1117.0]]}, {'text': 'into:(1) Overall,the engine is based on rules and human-', 'confidence': 0.9593220949172974, 'text_region': [[100.0, 1120.0], [571.0, 1121.0], [571.0, 1141.0], [100.0, 1140.0]]}, {'text': 'selectedparameters.Theautomationoftheselectionand', 'confidence': 0.9988446235656738, 'text_region': [[102.0, 1146.0], [571.0, 1146.0], [571.0, 1163.0], [102.0, 1163.0]]}, {'text': 'searchfortheseparameterscansavehumaneffortsandhelp', 'confidence': 0.9990125298500061, 'text_region': [[102.0, 1170.0], [570.0, 1170.0], [570.0, 1188.0], [102.0, 1188.0]]}, {'text': 'adapttodifferentscenarios.(2)Whilerenderingsmalltext', 'confidence': 0.9934311509132385, 'text_region': [[102.0, 1194.0], [571.0, 1194.0], [571.0, 1212.0], [102.0, 1212.0]]}, {'text': 'canhelptrainingdetectors,thelowimagequalityof the', 'confidence': 0.9887761473655701, 'text_region': [[100.0, 1217.0], [571.0, 1216.0], [571.0, 1236.0], [100.0, 1237.0]]}, {'text': 'smalltextmakesrecognizersharder totrainandharmsthe', 'confidence': 0.9893149733543396, 'text_region': [[101.0, 1242.0], [570.0, 1242.0], [570.0, 1260.0], [101.0, 1260.0]]}, {'text': 'performance.Designing a method tomarktheillegibleones', 'confidence': 0.9793795347213745, 'text_region': [[101.0, 1265.0], [571.0, 1265.0], [571.0, 1286.0], [101.0, 1286.0]]}, {'text': 'asdifficult andexcluding themfromloss calculationmay', 'confidence': 0.9746667146682739, 'text_region': [[100.0, 1286.0], [571.0, 1288.0], [571.0, 1309.0], [100.0, 1307.0]]}, {'text': 'helpmitigate this problem.(3)For multilingual scene text,', 'confidence': 0.9538096189498901, 'text_region': [[101.0, 1312.0], [572.0, 1312.0], [572.0, 1332.0], [101.0, 1332.0]]}, {'text': 'scriptsexceptLatinhavemuchfeweravailablefontsthatwe', 'confidence': 0.9979195594787598, 'text_region': [[102.0, 1336.0], [570.0, 1335.0], [570.0, 1354.0], [102.0, 1355.0]]}, {'text': 'have easy access to.Toimproveperformance on more lan-', 'confidence': 0.9664244055747986, 'text_region': [[100.0, 1360.0], [571.0, 1360.0], [571.0, 1381.0], [100.0, 1381.0]]}, {'text': 'guages,researchers may considerlearning-based methods', 'confidence': 0.9688723683357239, 'text_region': [[100.0, 1385.0], [572.0, 1383.0], [572.0, 1403.0], [100.0, 1405.0]]}, {'text': 'totransferLatinfontstootherscripts', 'confidence': 0.9961358308792114, 'text_region': [[100.0, 1407.0], [398.0, 1408.0], [398.0, 1425.0], [100.0, 1425.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [616, 421, 1091, 605], 'res': [{'text': 'Inthispaper,weintroducea scene text image synthesis', 'confidence': 0.9631720185279846, 'text_region': [[642.0, 421.0], [1089.0, 423.0], [1089.0, 442.0], [642.0, 440.0]]}, {'text': 'enginethatrendersimageswith3Dgraphicsengines,where', 'confidence': 0.9927992820739746, 'text_region': [[619.0, 446.0], [1089.0, 446.0], [1089.0, 465.0], [619.0, 465.0]]}, {'text': 'textinstances andscenes are rendered as a whole.Inexper-', 'confidence': 0.9628844857215881, 'text_region': [[618.0, 467.0], [1087.0, 468.0], [1087.0, 488.0], [618.0, 487.0]]}, {'text': 'iments,weverifytheeffectiveness oftheproposedengine', 'confidence': 0.9802196621894836, 'text_region': [[618.0, 491.0], [1088.0, 492.0], [1088.0, 512.0], [618.0, 511.0]]}, {'text': 'inbothscene textdetection andrecognitionmodels.We', 'confidence': 0.9808133244514465, 'text_region': [[617.0, 515.0], [1089.0, 516.0], [1089.0, 535.0], [617.0, 534.0]]}, {'text': 'alsostudykey components of theproposed engine.We be-', 'confidence': 0.9543906450271606, 'text_region': [[617.0, 539.0], [1087.0, 540.0], [1087.0, 560.0], [617.0, 559.0]]}, {'text': 'lieve our workwillbea solid steppingstone towards bette1', 'confidence': 0.9459090828895569, 'text_region': [[617.0, 563.0], [1087.0, 564.0], [1087.0, 584.0], [617.0, 583.0]]}, {'text': 'synthesisalgorithms', 'confidence': 0.9978460073471069, 'text_region': [[618.0, 588.0], [781.0, 589.0], [781.0, 604.0], [618.0, 604.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 667, 573, 994], 'res': [{'text': 'ExperimentresultsareshowninTab.4.Whenweonlyuse', 'confidence': 0.9977005124092102, 'text_region': [[101.0, 669.0], [571.0, 671.0], [571.0, 688.0], [101.0, 686.0]]}, {'text': 'syntheticdataandcontrolthenumberofimagesto1.2M', 'confidence': 0.9982055425643921, 'text_region': [[100.0, 695.0], [569.0, 693.0], [569.0, 710.0], [100.0, 712.0]]}, {'text': 'oursresult in a considerableimprovement of 1.6%in over', 'confidence': 0.9599758386611938, 'text_region': [[100.0, 716.0], [569.0, 716.0], [569.0, 736.0], [100.0, 736.0]]}, {'text': 'allaccuracy,and significantimprovements onsome scripts', 'confidence': 0.977773904800415, 'text_region': [[100.0, 740.0], [569.0, 741.0], [569.0, 761.0], [100.0, 760.0]]}, {'text': 'e.g.Latin (+7.6%) and Mixed(+21.6%).Using the whole', 'confidence': 0.9769619107246399, 'text_region': [[99.0, 764.0], [571.0, 761.0], [571.0, 782.0], [99.0, 786.0]]}, {'text': 'trainingsetof4.1Mimagesfurtherimprovesoverallaccu-', 'confidence': 0.993405818939209, 'text_region': [[102.0, 790.0], [570.0, 790.0], [570.0, 807.0], [102.0, 807.0]]}, {'text': 'racy to39.5%.Whenwe trainmodels on combinations of', 'confidence': 0.9601983428001404, 'text_region': [[100.0, 812.0], [572.0, 810.0], [572.0, 831.0], [100.0, 834.0]]}, {'text': 'synthetic data and our training split of MLT19,as shown', 'confidence': 0.9490158557891846, 'text_region': [[99.0, 836.0], [572.0, 834.0], [572.0, 855.0], [99.0, 857.0]]}, {'text': 'inthebottomofTab.4,wecanstillobserveaconsiderable', 'confidence': 0.995178759098053, 'text_region': [[101.0, 861.0], [570.0, 861.0], [570.0, 879.0], [101.0, 879.0]]}, {'text': 'marginofourmethodoverSynthTextby3.2%inoverall ac-', 'confidence': 0.9833081960678101, 'text_region': [[100.0, 884.0], [570.0, 883.0], [570.0, 903.0], [100.0, 904.0]]}, {'text': 'curacy.Theexperimentresultsdemonstratethatourmethod', 'confidence': 0.9984161257743835, 'text_region': [[102.0, 909.0], [571.0, 909.0], [571.0, 927.0], [102.0, 927.0]]}, {'text': 'is alsosuperiorinmultilingual scenetextrecognition,and', 'confidence': 0.9690279960632324, 'text_region': [[100.0, 932.0], [572.0, 932.0], [572.0, 952.0], [100.0, 952.0]]}, {'text': 'we believe this resultwill become a stepping stone tofur', 'confidence': 0.9463595151901245, 'text_region': [[101.0, 956.0], [568.0, 956.0], [568.0, 977.0], [101.0, 977.0]]}, {'text': 'therresearch', 'confidence': 0.997674286365509, 'text_region': [[102.0, 981.0], [204.0, 981.0], [204.0, 993.0], [102.0, 993.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [618, 660, 1088, 700], 'res': [{'text': 'ThisresearchwassupportedbyNationalKeyR&DPro', 'confidence': 0.9983044266700745, 'text_region': [[644.0, 661.0], [1084.0, 660.0], [1084.0, 677.0], [644.0, 679.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 292, 1088, 335], 'res': [{'text': 'accuracy)', 'confidence': 0.9515259861946106, 'text_region': [[619.0, 297.0], [694.0, 297.0], [694.0, 307.0], [619.0, 307.0]]}, {'text': 'aggregates', 'confidence': 0.9968370199203491, 'text_region': [[756.0, 296.0], [851.0, 295.0], [851.0, 308.0], [756.0, 310.0]]}, {'text': 'English,French,German,anc', 'confidence': 0.9320168495178223, 'text_region': [[846.0, 293.0], [1087.0, 293.0], [1087.0, 311.0], [846.0, 311.0]]}, {'text': 'Italian,asthey', 'confidence': 0.98361736536026, 'text_region': [[100.0, 316.0], [215.0, 319.0], [214.0, 334.0], [100.0, 331.0]]}, {'text': 'afe', 'confidence': 0.91034334897995, 'text_region': [[222.0, 322.0], [248.0, 322.0], [248.0, 331.0], [222.0, 331.0]]}, {'text': 'uatasel', 'confidence': 0.8220991492271423, 'text_region': [[508.0, 322.0], [559.0, 322.0], [559.0, 331.0], [508.0, 331.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [99, 1048, 418, 1066], 'res': [{'text': '', 'confidence': 0.0, 'text_region': [[242.0, 1056.0], [326.0, 1056.0], [326.0, 1060.0], [242.0, 1060.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [617, 727, 728, 744], 'res': [], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [99, 615, 328, 633], 'res': [{'text': 'Sxnermentkest', 'confidence': 0.7982187271118164, 'text_region': [[162.0, 620.0], [316.0, 620.0], [316.0, 628.0], [162.0, 628.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [617, 380, 755, 398], 'res': [], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [619, 631, 804, 652], 'res': [{'text': 'Acknowledgemen', 'confidence': 0.9701581597328186, 'text_region': [[626.0, 636.0], [794.0, 636.0], [794.0, 647.0], [626.0, 647.0]]}], 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [97, 375, 587, 523], 'res': '', 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [129, 138, 1053, 282], 'res': '', 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [626, 767, 1089, 1421], 'res': [{'text': '[]PabloArbelaez,MichaelMaire,CharlessFowlkes,andJi', 'confidence': 0.9721828699111938, 'text_region': [[629.0, 770.0], [1086.0, 768.0], [1086.0, 782.0], [629.0, 784.0]]}, {'text': 'tendra Malik.Contour detection and hierarchical image seg-', 'confidence': 0.9716992378234863, 'text_region': [[655.0, 787.0], [1088.0, 790.0], [1088.0, 810.0], [655.0, 808.0]]}, {'text': 'mentation.IEEEtransactions onpatternanalysisandma', 'confidence': 0.9901202321052551, 'text_region': [[657.0, 811.0], [1088.0, 811.0], [1088.0, 831.0], [657.0, 831.0]]}, {'text': 'chine intelligence,33(5):898-916,2011.', 'confidence': 0.9931216835975647, 'text_region': [[657.0, 832.0], [952.0, 832.0], [952.0, 853.0], [657.0, 853.0]]}, {'text': '[2]YoungminBaek,BadoLee,DongyoonHan,SangdooYun', 'confidence': 0.9953420162200928, 'text_region': [[628.0, 856.0], [1087.0, 856.0], [1087.0, 873.0], [628.0, 873.0]]}, {'text': 'andHwalsukLee.Characterregion awarenessfor textdetec', 'confidence': 0.987934947013855, 'text_region': [[659.0, 878.0], [1085.0, 878.0], [1085.0, 896.0], [659.0, 896.0]]}, {'text': 'tion.InProceedingsoftheIEEEConferenceonComputer', 'confidence': 0.9873964190483093, 'text_region': [[658.0, 900.0], [1087.0, 900.0], [1087.0, 917.0], [658.0, 917.0]]}, {'text': 'Vision andPattern Recognition(CVPR),pages 9365-9374', 'confidence': 0.9805710911750793, 'text_region': [[657.0, 919.0], [1087.0, 920.0], [1087.0, 941.0], [657.0, 940.0]]}, {'text': '2019.', 'confidence': 0.9865638017654419, 'text_region': [[657.0, 944.0], [697.0, 944.0], [697.0, 959.0], [657.0, 959.0]]}, {'text': '[3]Zhanzhan Cheng,Xuyang Liu,Fan Bai,Yi Niu,Shiliang Pu', 'confidence': 0.9633762240409851, 'text_region': [[628.0, 967.0], [1086.0, 967.0], [1086.0, 985.0], [628.0, 985.0]]}, {'text': 'andShuigengZhou.Arbitrarily-orientedtextrecognition', 'confidence': 0.9989327192306519, 'text_region': [[658.0, 989.0], [1087.0, 989.0], [1087.0, 1006.0], [658.0, 1006.0]]}, {'text': 'CVPR2018,2017.', 'confidence': 0.9893182516098022, 'text_region': [[659.0, 1010.0], [788.0, 1010.0], [788.0, 1028.0], [659.0, 1028.0]]}, {'text': \"[4]CheeKheng Ch'ng and Chee Seng Chan.Total-text:A com\", 'confidence': 0.9735320806503296, 'text_region': [[627.0, 1033.0], [1087.0, 1032.0], [1087.0, 1052.0], [627.0, 1053.0]]}, {'text': 'prehensive datasetforscene textdetectionandrecognition', 'confidence': 0.9815278053283691, 'text_region': [[658.0, 1056.0], [1087.0, 1056.0], [1087.0, 1074.0], [658.0, 1074.0]]}, {'text': 'In Proc.ICDAR,volume 1,pages 935-942,2017.', 'confidence': 0.9692395329475403, 'text_region': [[657.0, 1076.0], [1017.0, 1076.0], [1017.0, 1096.0], [657.0, 1096.0]]}, {'text': '[5]IanGoodfellow,JeanPouget-Abadie,MehdiMirza,Bing', 'confidence': 0.9889501333236694, 'text_region': [[628.0, 1099.0], [1087.0, 1100.0], [1087.0, 1118.0], [628.0, 1116.0]]}, {'text': 'Xu,DavidWarde-Farley,SherjilOzair,AaronCourville,an', 'confidence': 0.9700707197189331, 'text_region': [[659.0, 1124.0], [1086.0, 1124.0], [1086.0, 1138.0], [659.0, 1138.0]]}, {'text': 'YoshuaBengio.Generative adversarialnets.InProc.NIPS', 'confidence': 0.9851199984550476, 'text_region': [[659.0, 1144.0], [1087.0, 1144.0], [1087.0, 1161.0], [659.0, 1161.0]]}, {'text': 'pages 2672-2680, 2014.', 'confidence': 0.9890480041503906, 'text_region': [[656.0, 1165.0], [833.0, 1161.0], [834.0, 1183.0], [656.0, 1186.0]]}, {'text': '[6]AnkushGupta,AndreaVedaldi,andAndrewZisserman', 'confidence': 0.996702253818512, 'text_region': [[628.0, 1189.0], [1087.0, 1189.0], [1087.0, 1206.0], [628.0, 1206.0]]}, {'text': 'Synthetic data for text localisation in natural images. InProc.', 'confidence': 0.9625043272972107, 'text_region': [[656.0, 1208.0], [1087.0, 1209.0], [1087.0, 1230.0], [656.0, 1229.0]]}, {'text': 'CVPR,pages 23152324,2016.', 'confidence': 0.9574609398841858, 'text_region': [[659.0, 1233.0], [885.0, 1233.0], [885.0, 1250.0], [659.0, 1250.0]]}, {'text': '[7]Tong He,Zhi Tian,Weilin Huang,Chunhua Shen,Yu Qiao', 'confidence': 0.9619812369346619, 'text_region': [[628.0, 1256.0], [1086.0, 1256.0], [1086.0, 1274.0], [628.0, 1274.0]]}, {'text': 'andChangmingSun.Anend-to-endtextspotterwithexplicit', 'confidence': 0.9972381591796875, 'text_region': [[658.0, 1278.0], [1087.0, 1278.0], [1087.0, 1295.0], [658.0, 1295.0]]}, {'text': 'alignment and attention.In Proc. CVPR,pages 5020-5029', 'confidence': 0.9838453531265259, 'text_region': [[657.0, 1297.0], [1088.0, 1297.0], [1088.0, 1318.0], [657.0, 1318.0]]}, {'text': '2018.', 'confidence': 0.9805755615234375, 'text_region': [[657.0, 1321.0], [697.0, 1321.0], [697.0, 1336.0], [657.0, 1336.0]]}, {'text': '[8]StefanHinterstoisser, OlivierPauly,Hauke Heibel,Martina', 'confidence': 0.971477746963501, 'text_region': [[628.0, 1342.0], [1086.0, 1342.0], [1086.0, 1360.0], [628.0, 1360.0]]}, {'text': 'Marek,andMartinBokeloh.An annotation saved is an an-', 'confidence': 0.9610022902488708, 'text_region': [[658.0, 1366.0], [1087.0, 1366.0], [1087.0, 1383.0], [658.0, 1383.0]]}, {'text': 'notation earned:Using fully synthetic training for object in-', 'confidence': 0.9779661893844604, 'text_region': [[656.0, 1385.0], [1088.0, 1386.0], [1088.0, 1407.0], [656.0, 1406.0]]}, {'text': 'stancedetection.（oRRabs/1902.099672019', 'confidence': 0.9451590180397034, 'text_region': [[659.0, 1411.0], [993.0, 1411.0], [993.0, 1420.0], [659.0, 1420.0]]}], 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [101, 533, 572, 555], 'res': [{'text': 'able5:ResultsonEnglishda', 'confidence': 0.8786733746528625, 'text_region': [[110.0, 536.0], [342.0, 536.0], [342.0, 545.0], [110.0, 545.0]]}, {'text': 'asets(wordlevelaccuracy', 'confidence': 0.9481464624404907, 'text_region': [[348.0, 536.0], [556.0, 537.0], [556.0, 547.0], [348.0, 546.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:42:16] ppocr DEBUG: dt_boxes num : 57, elapsed : 0.22341036796569824\n",
      "[2024/05/30 16:42:22] ppocr DEBUG: rec_res num  : 57, elapsed : 6.352528810501099\n",
      "[2024/05/30 16:42:22] ppocr DEBUG: dt_boxes num : 56, elapsed : 0.18478679656982422\n",
      "[2024/05/30 16:42:29] ppocr DEBUG: rec_res num  : 56, elapsed : 6.408672094345093\n",
      "{'type': 'reference', 'bbox': [101, 152, 574, 1423], 'res': [{'text': '[9]SeppHochreiter andJirgenSchmidhuber.Longshort-term', 'confidence': 0.9811314344406128, 'text_region': [[109.0, 152.0], [573.0, 152.0], [573.0, 169.0], [109.0, 169.0]]}, {'text': 'memory.Neural computation,9(8):1735-1780,1997', 'confidence': 0.9820894598960876, 'text_region': [[137.0, 173.0], [524.0, 172.0], [524.0, 190.0], [137.0, 192.0]]}, {'text': '10]MaxJaderberg,KarenSimonyan,Andrea Vedaldi,and An-', 'confidence': 0.9680846333503723, 'text_region': [[104.0, 197.0], [571.0, 197.0], [571.0, 214.0], [104.0, 214.0]]}, {'text': 'drewZisserman.Syntheticdata andartificialneuralnet-', 'confidence': 0.9842759966850281, 'text_region': [[140.0, 220.0], [571.0, 220.0], [571.0, 237.0], [140.0, 237.0]]}, {'text': 'worksfor natural scene text recognition.arXivpreprint', 'confidence': 0.966009259223938, 'text_region': [[140.0, 242.0], [573.0, 242.0], [573.0, 261.0], [140.0, 261.0]]}, {'text': 'arXiv:1406.2227,2014.', 'confidence': 0.9902598857879639, 'text_region': [[139.0, 263.0], [311.0, 263.0], [311.0, 280.0], [139.0, 280.0]]}, {'text': '[11]Yingying Jiang,Xiangyu Zhu,Xiaobing Wang,Shuli Yang', 'confidence': 0.966996431350708, 'text_region': [[101.0, 283.0], [571.0, 286.0], [571.0, 308.0], [101.0, 306.0]]}, {'text': 'Wei Li,Hua Wang,Pei Fu,and Zhenbo Luo.R2cnn: rota-', 'confidence': 0.9479568600654602, 'text_region': [[139.0, 307.0], [571.0, 308.0], [571.0, 327.0], [139.0, 325.0]]}, {'text': 'tionalregion cnn for orientation robust scene text detection.', 'confidence': 0.9578193426132202, 'text_region': [[137.0, 329.0], [573.0, 332.0], [573.0, 351.0], [137.0, 348.0]]}, {'text': 'arXivpreprint arXiv:1706.09579,2017.', 'confidence': 0.9805096387863159, 'text_region': [[139.0, 352.0], [425.0, 352.0], [425.0, 370.0], [139.0, 370.0]]}, {'text': '[12]Amlan Kar,Aayush Prakash,Ming-Yu Liu,Eric Cameracci,', 'confidence': 0.9638001322746277, 'text_region': [[102.0, 377.0], [571.0, 377.0], [571.0, 396.0], [102.0, 396.0]]}, {'text': 'Justin Yuan,Matt Rusiniak,David Acuna,AntonioTorralba,', 'confidence': 0.9705630540847778, 'text_region': [[137.0, 397.0], [573.0, 400.0], [573.0, 418.0], [137.0, 415.0]]}, {'text': 'and Sanja Fidler. Meta-sim: Learning to generate synthetic', 'confidence': 0.979304850101471, 'text_region': [[136.0, 418.0], [573.0, 419.0], [573.0, 442.0], [136.0, 441.0]]}, {'text': 'datasets.arXivpreprint arXiv:1904.11621,2019.', 'confidence': 0.9794142246246338, 'text_region': [[140.0, 443.0], [493.0, 443.0], [493.0, 462.0], [140.0, 462.0]]}, {'text': '[13]Dimosthenis Karatzas,Lluis Gomez-Bigorda,Anguelos', 'confidence': 0.9853360056877136, 'text_region': [[102.0, 466.0], [573.0, 467.0], [573.0, 486.0], [102.0, 484.0]]}, {'text': 'Nicolaou,Suman Ghosh,AndrewBagdanov,MasakazuIwa-', 'confidence': 0.9825592041015625, 'text_region': [[140.0, 490.0], [570.0, 490.0], [570.0, 507.0], [140.0, 507.0]]}, {'text': 'mura,Jiri Matas,Lukas Neumann,Vijay Ramaseshan Chan-', 'confidence': 0.9657307267189026, 'text_region': [[139.0, 512.0], [571.0, 512.0], [571.0, 529.0], [139.0, 529.0]]}, {'text': 'drasekhar, Shijian Lu,et al.Icdar 2015 competition on robust', 'confidence': 0.9629218578338623, 'text_region': [[139.0, 532.0], [573.0, 533.0], [573.0, 552.0], [139.0, 550.0]]}, {'text': 'reading.In 201513thInternational Conference onDocu-', 'confidence': 0.9681409001350403, 'text_region': [[136.0, 553.0], [571.0, 552.0], [571.0, 574.0], [136.0, 576.0]]}, {'text': 'mentAnalysisandRecognition(ICDAR),pages1156-1160', 'confidence': 0.9933697581291199, 'text_region': [[139.0, 577.0], [570.0, 577.0], [570.0, 594.0], [139.0, 594.0]]}, {'text': 'IEEE,2015.', 'confidence': 0.9698119163513184, 'text_region': [[138.0, 597.0], [228.0, 600.0], [227.0, 618.0], [137.0, 615.0]]}, {'text': '14]Dimosthenis Karatzas,Faisal Shafait,Seichi Uchida,', 'confidence': 0.9641339778900146, 'text_region': [[104.0, 623.0], [571.0, 623.0], [571.0, 641.0], [104.0, 641.0]]}, {'text': 'Masakazu Iwamura,Lluis Gomez i Bigorda,Sergi Robles', 'confidence': 0.9650015234947205, 'text_region': [[139.0, 643.0], [573.0, 643.0], [573.0, 662.0], [139.0, 662.0]]}, {'text': 'Mestre,Joan Mas,David Fernandez Mota,Jon Almazan Al-', 'confidence': 0.954386830329895, 'text_region': [[139.0, 667.0], [573.0, 667.0], [573.0, 684.0], [139.0, 684.0]]}, {'text': 'mazan, and Lluis Pere de las Heras. Icdar 2013 robust read-', 'confidence': 0.9658572673797607, 'text_region': [[137.0, 690.0], [571.0, 688.0], [571.0, 707.0], [137.0, 708.0]]}, {'text': 'ing competition.In 201312th International Conference on', 'confidence': 0.9747567176818848, 'text_region': [[136.0, 709.0], [573.0, 708.0], [573.0, 731.0], [136.0, 732.0]]}, {'text': 'DocumentAnalysisandRecognition(ICDAR),pages1484-', 'confidence': 0.9939620494842529, 'text_region': [[140.0, 733.0], [569.0, 733.0], [569.0, 752.0], [140.0, 752.0]]}, {'text': '1493.IEEE,2013.', 'confidence': 0.9826434850692749, 'text_region': [[139.0, 753.0], [272.0, 754.0], [272.0, 773.0], [139.0, 772.0]]}, {'text': '15]Hui Li,PengWang,ChunhuaShen,and Guyu Zhang.Show', 'confidence': 0.973538875579834, 'text_region': [[104.0, 780.0], [570.0, 780.0], [570.0, 798.0], [104.0, 798.0]]}, {'text': 'attend andread:Asimple and strongbaselineforirregular', 'confidence': 0.9767303466796875, 'text_region': [[140.0, 801.0], [573.0, 801.0], [573.0, 819.0], [140.0, 819.0]]}, {'text': 'text recognition.AAAI,2019.', 'confidence': 0.9656868577003479, 'text_region': [[139.0, 823.0], [351.0, 822.0], [351.0, 840.0], [139.0, 842.0]]}, {'text': '16]Minghui Liao,Boyu Song,Shangbang Long,Minghang He', 'confidence': 0.9770787954330444, 'text_region': [[104.0, 847.0], [569.0, 847.0], [569.0, 866.0], [104.0, 866.0]]}, {'text': 'CongYao,andXiangBai.Synthtext3d:synthesizingscene', 'confidence': 0.9959471821784973, 'text_region': [[140.0, 870.0], [573.0, 870.0], [573.0, 888.0], [140.0, 888.0]]}, {'text': 'textimagesfrom3dvirtualworlds.ScienceChinaInforma', 'confidence': 0.9984208941459656, 'text_region': [[140.0, 891.0], [570.0, 891.0], [570.0, 909.0], [140.0, 909.0]]}, {'text': 'tionSciences,63(2):120105,2020.', 'confidence': 0.9785073399543762, 'text_region': [[139.0, 913.0], [389.0, 913.0], [389.0, 930.0], [139.0, 930.0]]}, {'text': '[17]Chen-Hsuan Lin,ErsinYumer, Oliver Wang,Eli Shechtman,', 'confidence': 0.9551539421081543, 'text_region': [[102.0, 936.0], [571.0, 937.0], [571.0, 956.0], [102.0, 954.0]]}, {'text': 'andSimonLucey.St-gan:Spatial transformer generative', 'confidence': 0.986879825592041, 'text_region': [[139.0, 960.0], [573.0, 960.0], [573.0, 978.0], [139.0, 978.0]]}, {'text': 'adversarial networks for image compositing. In Proceed-', 'confidence': 0.98224276304245, 'text_region': [[136.0, 978.0], [573.0, 979.0], [573.0, 1002.0], [136.0, 1001.0]]}, {'text': 'ingsoftheIEEEConferenceonComputerVisionandPattern', 'confidence': 0.9976426959037781, 'text_region': [[137.0, 1003.0], [573.0, 1002.0], [573.0, 1021.0], [137.0, 1022.0]]}, {'text': 'Recognition,pages 9455-9464,2018.', 'confidence': 0.9887305498123169, 'text_region': [[137.0, 1022.0], [409.0, 1022.0], [409.0, 1044.0], [137.0, 1044.0]]}, {'text': '[18]XueboLiu,DingLiang,ShiYan,Dagui Chen,YuQiao,and', 'confidence': 0.9666665196418762, 'text_region': [[102.0, 1050.0], [573.0, 1050.0], [573.0, 1067.0], [102.0, 1067.0]]}, {'text': 'JunjieYan.Fots:Fast oriented text spottingwith a unified', 'confidence': 0.9714020490646362, 'text_region': [[139.0, 1071.0], [573.0, 1071.0], [573.0, 1089.0], [139.0, 1089.0]]}, {'text': 'network.Proc.CVPR,2018.', 'confidence': 0.9952625036239624, 'text_region': [[139.0, 1093.0], [346.0, 1093.0], [346.0, 1111.0], [139.0, 1111.0]]}, {'text': '[19]YuliangLiu andLianwenJin.Deepmatchingprior network:', 'confidence': 0.9855727553367615, 'text_region': [[102.0, 1116.0], [573.0, 1117.0], [573.0, 1136.0], [102.0, 1134.0]]}, {'text': 'Toward tightermulti-oriented text detection.InProc.CVPR', 'confidence': 0.9780476093292236, 'text_region': [[140.0, 1137.0], [571.0, 1137.0], [571.0, 1156.0], [140.0, 1156.0]]}, {'text': '2017.', 'confidence': 0.9993480443954468, 'text_region': [[139.0, 1160.0], [182.0, 1160.0], [182.0, 1178.0], [139.0, 1178.0]]}, {'text': '[20]ShangbangLong,Yushuo Guan,Bingxuan Wang,Kaigui', 'confidence': 0.9698296189308167, 'text_region': [[102.0, 1183.0], [573.0, 1186.0], [573.0, 1205.0], [102.0, 1202.0]]}, {'text': 'Bian,and Cong Yao.Alchemy:Techniques for rectifica-', 'confidence': 0.9693809747695923, 'text_region': [[140.0, 1207.0], [570.0, 1207.0], [570.0, 1226.0], [140.0, 1226.0]]}, {'text': 'tionbasedirregular scenetextrecognition.arXivpreprint', 'confidence': 0.9822043776512146, 'text_region': [[137.0, 1228.0], [573.0, 1230.0], [573.0, 1248.0], [137.0, 1247.0]]}, {'text': 'arXiv:1908.11834,2019', 'confidence': 0.9899607300758362, 'text_region': [[137.0, 1251.0], [319.0, 1250.0], [319.0, 1268.0], [137.0, 1269.0]]}, {'text': '21]ShangbangLong,XinHe,and CongYao.Scene text detec-', 'confidence': 0.961537778377533, 'text_region': [[104.0, 1276.0], [571.0, 1276.0], [571.0, 1293.0], [104.0, 1293.0]]}, {'text': 'tion and recognition:The deeplearning era.arXiv preprint', 'confidence': 0.9728050827980042, 'text_region': [[139.0, 1297.0], [573.0, 1297.0], [573.0, 1316.0], [139.0, 1316.0]]}, {'text': 'arXiv:1811.04256,2018.', 'confidence': 0.9941339492797852, 'text_region': [[139.0, 1320.0], [320.0, 1320.0], [320.0, 1337.0], [139.0, 1337.0]]}, {'text': '[22]Shangbang Long,Jiaqiang Ruan,Wenjie Zhang,Xin He,', 'confidence': 0.9726395010948181, 'text_region': [[101.0, 1340.0], [571.0, 1341.0], [571.0, 1363.0], [101.0, 1362.0]]}, {'text': 'WenhaoWu,and CongYao.Textsnake:A flexible represen-', 'confidence': 0.9751193523406982, 'text_region': [[140.0, 1365.0], [573.0, 1365.0], [573.0, 1383.0], [140.0, 1383.0]]}, {'text': 'tationfor detecting text of arbitrary shapes.In Proc.ECCV', 'confidence': 0.9812080264091492, 'text_region': [[139.0, 1387.0], [571.0, 1387.0], [571.0, 1406.0], [139.0, 1406.0]]}, {'text': '2018', 'confidence': 0.9992740154266357, 'text_region': [[140.0, 1410.0], [176.0, 1410.0], [176.0, 1422.0], [140.0, 1422.0]]}], 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [620, 151, 1091, 1421], 'res': [{'text': 'Ruiyu Li, and Xiaoyong Shen. 2d attentional irregular scene', 'confidence': 0.9630952477455139, 'text_region': [[656.0, 173.0], [1090.0, 173.0], [1090.0, 192.0], [656.0, 192.0]]}, {'text': 'textrecognizer.arXivpreprint arXiv:1906.05708,2019.', 'confidence': 0.9908527135848999, 'text_region': [[656.0, 195.0], [1062.0, 193.0], [1062.0, 212.0], [656.0, 213.0]]}, {'text': '[24]John McCormac,Ankur Handa,Stefan Leutenegger, and', 'confidence': 0.9792401194572449, 'text_region': [[620.0, 214.0], [1090.0, 217.0], [1090.0, 240.0], [620.0, 237.0]]}, {'text': 'Andrew J.Davison.Scenenet RGB-D:5m photorealistic', 'confidence': 0.9724904894828796, 'text_region': [[655.0, 240.0], [1090.0, 241.0], [1090.0, 259.0], [655.0, 258.0]]}, {'text': 'images of synthetic indoor trajectories with ground truth.', 'confidence': 0.963133692741394, 'text_region': [[656.0, 263.0], [1090.0, 263.0], [1090.0, 282.0], [656.0, 282.0]]}, {'text': 'CoRR,abs/1612.05079,2016.', 'confidence': 0.997469961643219, 'text_region': [[657.0, 285.0], [873.0, 285.0], [873.0, 302.0], [657.0, 302.0]]}, {'text': '25]Anand Mishra,KarteekAlahari,and CVJawahar.Scene text', 'confidence': 0.9774439930915833, 'text_region': [[623.0, 310.0], [1090.0, 310.0], [1090.0, 327.0], [623.0, 327.0]]}, {'text': 'recognitionusinghigher orderlanguagepriors.InBMVC', 'confidence': 0.9918492436408997, 'text_region': [[656.0, 331.0], [1087.0, 331.0], [1087.0, 348.0], [656.0, 348.0]]}, {'text': 'BritishMachineVisionConference.BMVA,2012', 'confidence': 0.9909967184066772, 'text_region': [[657.0, 352.0], [1016.0, 352.0], [1016.0, 369.0], [657.0, 369.0]]}, {'text': '26]Nibal Nayef,Yash Patel,Michal Busta,Pinaki Nath Chowd-', 'confidence': 0.9573544263839722, 'text_region': [[623.0, 377.0], [1088.0, 377.0], [1088.0, 394.0], [623.0, 394.0]]}, {'text': 'hury, Dimosthenis Karatzas,Wafa Khlif, Jiri Matas,Uma-', 'confidence': 0.9681464433670044, 'text_region': [[655.0, 400.0], [1090.0, 400.0], [1090.0, 417.0], [655.0, 417.0]]}, {'text': 'pada Pal,Jean-Christophe Burie, Cheng-lin Liu, et al.Ic-', 'confidence': 0.9531122446060181, 'text_region': [[656.0, 421.0], [1090.0, 421.0], [1090.0, 439.0], [656.0, 439.0]]}, {'text': 'dar2019 robust reading challenge on multi-lingualscene', 'confidence': 0.9622017741203308, 'text_region': [[655.0, 441.0], [1090.0, 443.0], [1090.0, 462.0], [655.0, 459.0]]}, {'text': 'textdetection andrecognition-rrc-mlt-2019.arXivpreprint', 'confidence': 0.9845207333564758, 'text_region': [[655.0, 463.0], [1090.0, 465.0], [1090.0, 483.0], [655.0, 482.0]]}, {'text': 'arXiv:1907.00945,2019.', 'confidence': 0.9885482788085938, 'text_region': [[656.0, 486.0], [837.0, 486.0], [837.0, 503.0], [656.0, 503.0]]}, {'text': '27]Nibal Nayef, Fei Yin,Imen Bizid,Hyunsoo Choi,Yuan', 'confidence': 0.9655833840370178, 'text_region': [[623.0, 508.0], [1090.0, 508.0], [1090.0, 527.0], [623.0, 527.0]]}, {'text': 'Feng,Dimosthenis Karatzas, Zhenbo Luo,Umapada Pal', 'confidence': 0.9752967953681946, 'text_region': [[656.0, 532.0], [1088.0, 532.0], [1088.0, 551.0], [656.0, 551.0]]}, {'text': 'Christophe Rigaud,Joseph Chazalon,et al.Icdar2017 ro-', 'confidence': 0.9810309410095215, 'text_region': [[655.0, 553.0], [1090.0, 555.0], [1090.0, 573.0], [655.0, 572.0]]}, {'text': 'bust reading challenge onmulti-lingual scene text detection', 'confidence': 0.9545938968658447, 'text_region': [[653.0, 574.0], [1090.0, 576.0], [1090.0, 594.0], [653.0, 593.0]]}, {'text': 'and script identification-rrc-mlt.In Proc.ICDAR,volume 1,', 'confidence': 0.9694520235061646, 'text_region': [[656.0, 598.0], [1090.0, 598.0], [1090.0, 615.0], [656.0, 615.0]]}, {'text': 'pages 14541459.IEEE, 2017.', 'confidence': 0.9917733073234558, 'text_region': [[653.0, 618.0], [882.0, 615.0], [882.0, 638.0], [654.0, 641.0]]}, {'text': '28]JeremiePapon andMarkusSchoeler.Semanticposeusing', 'confidence': 0.9925674200057983, 'text_region': [[621.0, 643.0], [1090.0, 644.0], [1090.0, 663.0], [621.0, 662.0]]}, {'text': 'deepnetworkstrainedonsyntheticrgb-d.InProc.ICCV,', 'confidence': 0.9823117256164551, 'text_region': [[656.0, 667.0], [1090.0, 667.0], [1090.0, 684.0], [656.0, 684.0]]}, {'text': 'pages 774-782, 2015.', 'confidence': 0.9722222089767456, 'text_region': [[653.0, 687.0], [815.0, 683.0], [816.0, 705.0], [654.0, 709.0]]}, {'text': '29]XingchaoPeng,Baochen Sun,KarimAli,andKateSaenko.', 'confidence': 0.9759180545806885, 'text_region': [[623.0, 712.0], [1088.0, 712.0], [1088.0, 730.0], [623.0, 730.0]]}, {'text': 'Learning deep object detectors from 3d models.In Proc.', 'confidence': 0.9741984009742737, 'text_region': [[656.0, 734.0], [1090.0, 734.0], [1090.0, 753.0], [656.0, 753.0]]}, {'text': 'ICCV, pages 1278-1286, 2015.', 'confidence': 0.9720138311386108, 'text_region': [[656.0, 754.0], [884.0, 754.0], [884.0, 777.0], [656.0, 777.0]]}, {'text': '30]SiyangQin,AlessandroBissacco,MichalisRaptis,Yasuhisa', 'confidence': 0.991929292678833, 'text_region': [[623.0, 781.0], [1090.0, 781.0], [1090.0, 799.0], [623.0, 799.0]]}, {'text': 'Fujii, and YingXiao.Towards unconstrained end-to-end text', 'confidence': 0.9783021211624146, 'text_region': [[655.0, 801.0], [1090.0, 802.0], [1090.0, 820.0], [655.0, 819.0]]}, {'text': 'spotting.InProceedingsoftheIEEEInternationalConfer-', 'confidence': 0.9927212595939636, 'text_region': [[657.0, 824.0], [1090.0, 824.0], [1090.0, 843.0], [657.0, 843.0]]}, {'text': 'ence on ComputerVision,pages 4704-4714,2019.', 'confidence': 0.9754312634468079, 'text_region': [[655.0, 844.0], [1023.0, 843.0], [1023.0, 865.0], [655.0, 867.0]]}, {'text': '31]Weichao Qiu and AlanYuille.Unrealcv:Connecting com-', 'confidence': 0.962482750415802, 'text_region': [[621.0, 869.0], [1090.0, 871.0], [1090.0, 889.0], [621.0, 888.0]]}, {'text': 'puter vision to unreal engine.In Proc.ECCV,pages 909-', 'confidence': 0.9754459261894226, 'text_region': [[656.0, 893.0], [1087.0, 893.0], [1087.0, 912.0], [656.0, 912.0]]}, {'text': '916,2016.', 'confidence': 0.9485714435577393, 'text_region': [[657.0, 916.0], [732.0, 916.0], [732.0, 930.0], [657.0, 930.0]]}, {'text': '32]Trung Quy Phan,Palaiahnakote Shivakumara,Shangxuan', 'confidence': 0.9790337085723877, 'text_region': [[623.0, 938.0], [1090.0, 938.0], [1090.0, 957.0], [623.0, 957.0]]}, {'text': 'Tian,and Chew Lim Tan.Recognizing text with perspective', 'confidence': 0.9760666489601135, 'text_region': [[653.0, 957.0], [1090.0, 958.0], [1090.0, 980.0], [653.0, 979.0]]}, {'text': 'distortion in natural scenes.In Proc.ICCV,pages 569-576', 'confidence': 0.9646543860435486, 'text_region': [[656.0, 982.0], [1088.0, 982.0], [1088.0, 1000.0], [656.0, 1000.0]]}, {'text': '2013.', 'confidence': 0.9982603192329407, 'text_region': [[656.0, 1003.0], [699.0, 1003.0], [699.0, 1021.0], [656.0, 1021.0]]}, {'text': '33]Stephan R Richter,VibhavVineet,StefanRoth,andVladlen', 'confidence': 0.973037600517273, 'text_region': [[623.0, 1028.0], [1090.0, 1028.0], [1090.0, 1047.0], [623.0, 1047.0]]}, {'text': 'Koltun.H', 'confidence': 0.9568427801132202, 'text_region': [[655.0, 1048.0], [737.0, 1051.0], [736.0, 1069.0], [655.0, 1066.0]]}, {'text': 'Playing for data:Groundtruthfrom computer', 'confidence': 0.9715816378593445, 'text_region': [[728.0, 1051.0], [1090.0, 1051.0], [1090.0, 1069.0], [728.0, 1069.0]]}, {'text': 'games.In European conference on computer vision,pages', 'confidence': 0.9794145822525024, 'text_region': [[653.0, 1069.0], [1090.0, 1070.0], [1090.0, 1093.0], [653.0, 1092.0]]}, {'text': '102-118. Springer, 2016.', 'confidence': 0.9938557744026184, 'text_region': [[656.0, 1092.0], [841.0, 1092.0], [841.0, 1114.0], [656.0, 1114.0]]}, {'text': '34]AnharRisnumawan,PalaiahankoteShivakumara,CheeSeng', 'confidence': 0.9939202666282654, 'text_region': [[621.0, 1118.0], [1090.0, 1118.0], [1090.0, 1135.0], [621.0, 1135.0]]}, {'text': 'Chan, and Chew Lim Tan.A robust arbitrary text detection', 'confidence': 0.9627068638801575, 'text_region': [[657.0, 1139.0], [1090.0, 1139.0], [1090.0, 1158.0], [657.0, 1158.0]]}, {'text': 'systemfornatural sceneimages.ExpertSystemswithAppli-', 'confidence': 0.9841604232788086, 'text_region': [[656.0, 1162.0], [1088.0, 1162.0], [1088.0, 1180.0], [656.0, 1180.0]]}, {'text': 'cations,41(18):8027-8048,2014', 'confidence': 0.987999677658081, 'text_region': [[655.0, 1183.0], [900.0, 1182.0], [900.0, 1200.0], [655.0, 1201.0]]}, {'text': '35]German Ros,Laura Sellart,Joanna Materzynska,David', 'confidence': 0.9727226495742798, 'text_region': [[623.0, 1208.0], [1090.0, 1208.0], [1090.0, 1225.0], [623.0, 1225.0]]}, {'text': 'Vazquez, and Antonio M Lopez.The synthia dataset:A large', 'confidence': 0.9867801666259766, 'text_region': [[655.0, 1227.0], [1090.0, 1228.0], [1090.0, 1250.0], [655.0, 1249.0]]}, {'text': 'collection ofsyntheticimages for semantic segmentation of', 'confidence': 0.967585027217865, 'text_region': [[656.0, 1252.0], [1090.0, 1252.0], [1090.0, 1270.0], [656.0, 1270.0]]}, {'text': 'urban scenes.In Proc.CVPR,pages 3234-3243,2016.', 'confidence': 0.9587910175323486, 'text_region': [[655.0, 1273.0], [1052.0, 1271.0], [1052.0, 1290.0], [655.0, 1291.0]]}, {'text': '36]ScottDRoth.Ray castingfor modeling solids.Computer', 'confidence': 0.9713353514671326, 'text_region': [[623.0, 1297.0], [1090.0, 1297.0], [1090.0, 1315.0], [623.0, 1315.0]]}, {'text': 'Graphics &ImageProcessing,18(2):109-144,1982', 'confidence': 0.9829484820365906, 'text_region': [[657.0, 1319.0], [1037.0, 1319.0], [1037.0, 1338.0], [657.0, 1338.0]]}, {'text': '37]FatemehSadatSaleh,MohammadSadeghAliakbarian.', 'confidence': 0.9845715165138245, 'text_region': [[621.0, 1343.0], [1088.0, 1343.0], [1088.0, 1360.0], [621.0, 1360.0]]}, {'text': 'Mathieu Salzmann,Lars Petersson, and Jose M Alvarez.Ef-', 'confidence': 0.9810777306556702, 'text_region': [[656.0, 1365.0], [1090.0, 1365.0], [1090.0, 1383.0], [656.0, 1383.0]]}, {'text': 'fective use of synthetic data for urban scene semantic seg-', 'confidence': 0.980147659778595, 'text_region': [[656.0, 1383.0], [1088.0, 1385.0], [1088.0, 1408.0], [656.0, 1405.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:42:29] ppocr DEBUG: dt_boxes num : 56, elapsed : 0.2576429843902588\n",
      "[2024/05/30 16:42:35] ppocr DEBUG: rec_res num  : 56, elapsed : 5.597272634506226\n",
      "[2024/05/30 16:42:35] ppocr DEBUG: dt_boxes num : 10, elapsed : 0.14626717567443848\n",
      "[2024/05/30 16:42:36] ppocr DEBUG: rec_res num  : 10, elapsed : 1.2706313133239746\n",
      "{'type': 'reference', 'bbox': [101, 150, 574, 1422], 'res': [{'text': '38]BaoguangShi,XiangBai,andSerge Belongie.Detecting', 'confidence': 0.9798747897148132, 'text_region': [[104.0, 153.0], [573.0, 153.0], [573.0, 170.0], [104.0, 170.0]]}, {'text': 'oriented text in natural images bylinkingsegments.In The', 'confidence': 0.9629227519035339, 'text_region': [[140.0, 174.0], [573.0, 174.0], [573.0, 192.0], [140.0, 192.0]]}, {'text': 'IEEEConferenceonComputerVisionandPatternRecogni-', 'confidence': 0.9949248433113098, 'text_region': [[140.0, 195.0], [571.0, 195.0], [571.0, 214.0], [140.0, 214.0]]}, {'text': 'tion(CVPR),2017.', 'confidence': 0.9835193753242493, 'text_region': [[140.0, 218.0], [278.0, 218.0], [278.0, 235.0], [140.0, 235.0]]}, {'text': '39]BaoguangShi,MingkunYang,XingGangWang,Pengyuan', 'confidence': 0.9777104258537292, 'text_region': [[104.0, 240.0], [570.0, 240.0], [570.0, 259.0], [104.0, 259.0]]}, {'text': 'Lyu,XiangBai,and CongYao.Aster:An attentional scene', 'confidence': 0.9830441474914551, 'text_region': [[140.0, 264.0], [573.0, 264.0], [573.0, 282.0], [140.0, 282.0]]}, {'text': 'text recognizer with flexiblerectification.IEEE transactions', 'confidence': 0.9718311429023743, 'text_region': [[137.0, 284.0], [573.0, 282.0], [573.0, 305.0], [137.0, 306.0]]}, {'text': 'onpatternanalysisandmachineintelligence,31(11):855-', 'confidence': 0.9870776534080505, 'text_region': [[140.0, 308.0], [567.0, 308.0], [567.0, 326.0], [140.0, 326.0]]}, {'text': '868.2018', 'confidence': 0.9807387590408325, 'text_region': [[140.0, 329.0], [213.0, 329.0], [213.0, 343.0], [140.0, 343.0]]}, {'text': '40]Zhuotao Tian,Michelle Shu,Pengyuan Lyu,Ruiyu Li, Chao', 'confidence': 0.9748018383979797, 'text_region': [[104.0, 354.0], [573.0, 354.0], [573.0, 373.0], [104.0, 373.0]]}, {'text': 'Zhou,XiaoyongShen,and Jiaya Jia.Learning shape-aware', 'confidence': 0.9770826101303101, 'text_region': [[140.0, 375.0], [573.0, 375.0], [573.0, 394.0], [140.0, 394.0]]}, {'text': 'embeddingforscenetext detection.InProceedingsofthe', 'confidence': 0.9889991879463196, 'text_region': [[141.0, 396.0], [570.0, 396.0], [570.0, 415.0], [141.0, 415.0]]}, {'text': 'IEEEConferenceonComputerVisionandPatternRecogni-', 'confidence': 0.9920322895050049, 'text_region': [[139.0, 418.0], [571.0, 420.0], [571.0, 439.0], [139.0, 436.0]]}, {'text': 'tion, pages 4234 4243, 2019.', 'confidence': 0.9620397686958313, 'text_region': [[139.0, 440.0], [352.0, 440.0], [352.0, 463.0], [139.0, 463.0]]}, {'text': '41]Josh Tobin,Rachel Fong,Alex Ray,Jonas Schneider,Woj-', 'confidence': 0.9759309887886047, 'text_region': [[104.0, 465.0], [570.0, 465.0], [570.0, 484.0], [104.0, 484.0]]}, {'text': 'ciechZaremba,andPieterAbbeel.Domainrandomization', 'confidence': 0.9979496598243713, 'text_region': [[140.0, 488.0], [573.0, 488.0], [573.0, 505.0], [140.0, 505.0]]}, {'text': 'for transferring deep neural networksfrom simulation to the', 'confidence': 0.9579284191131592, 'text_region': [[140.0, 510.0], [571.0, 510.0], [571.0, 529.0], [140.0, 529.0]]}, {'text': 'realworld.In2017IEEE/RSJInternationalConferenceon', 'confidence': 0.989037036895752, 'text_region': [[137.0, 530.0], [573.0, 532.0], [573.0, 550.0], [137.0, 549.0]]}, {'text': 'Intelligent Robots and Systems (IROS),pages 23-30.IEEE,', 'confidence': 0.9570388793945312, 'text_region': [[137.0, 550.0], [571.0, 551.0], [571.0, 574.0], [137.0, 573.0]]}, {'text': '2017.', 'confidence': 0.999675452709198, 'text_region': [[139.0, 574.0], [182.0, 574.0], [182.0, 593.0], [139.0, 593.0]]}, {'text': '[42]Jonathan Tremblay, Thang To,and Stan Birchfield. Falling', 'confidence': 0.9769537448883057, 'text_region': [[101.0, 597.0], [573.0, 598.0], [573.0, 620.0], [101.0, 619.0]]}, {'text': 'things:A synthetic datasetfor 3d object detection and pose', 'confidence': 0.9593087434768677, 'text_region': [[139.0, 622.0], [573.0, 622.0], [573.0, 640.0], [139.0, 640.0]]}, {'text': 'estimation.InProc.CVPR Workshops,pages 2038-2041', 'confidence': 0.9862372279167175, 'text_region': [[140.0, 644.0], [570.0, 644.0], [570.0, 663.0], [140.0, 663.0]]}, {'text': '2018.', 'confidence': 0.930289089679718, 'text_region': [[140.0, 665.0], [179.0, 665.0], [179.0, 680.0], [140.0, 680.0]]}, {'text': '43]Gul Varol,Javier Romero,Xavier Martin,Naureen Mah-', 'confidence': 0.9709471464157104, 'text_region': [[104.0, 689.0], [570.0, 689.0], [570.0, 708.0], [104.0, 708.0]]}, {'text': 'mood,Michael JBlack,Ivan Laptev,and Cordelia Schmid', 'confidence': 0.9627597332000732, 'text_region': [[139.0, 712.0], [570.0, 712.0], [570.0, 730.0], [139.0, 730.0]]}, {'text': 'Learning from synthetic humans. In Proc.CVPR,pages 109-', 'confidence': 0.9812949895858765, 'text_region': [[137.0, 730.0], [571.0, 732.0], [571.0, 754.0], [137.0, 753.0]]}, {'text': '117,2017.', 'confidence': 0.986598014831543, 'text_region': [[140.0, 757.0], [215.0, 757.0], [215.0, 771.0], [140.0, 771.0]]}, {'text': '44] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko-', 'confidence': 0.9648085832595825, 'text_region': [[104.0, 779.0], [570.0, 779.0], [570.0, 798.0], [104.0, 798.0]]}, {'text': 'reit,Llion Jones,Aidan N Gomez,Lukasz Kaiser, and Illia', 'confidence': 0.9616539478302002, 'text_region': [[139.0, 801.0], [571.0, 801.0], [571.0, 819.0], [139.0, 819.0]]}, {'text': 'Polosukhin. Attention is all you need. In Proc. NIPS, pages', 'confidence': 0.9829350113868713, 'text_region': [[137.0, 820.0], [571.0, 822.0], [571.0, 844.0], [137.0, 843.0]]}, {'text': '59986008,2017.', 'confidence': 0.9965211153030396, 'text_region': [[140.0, 846.0], [269.0, 846.0], [269.0, 863.0], [140.0, 863.0]]}, {'text': '45]Kai Wang,Boris Babenko,and Serge Belongie.End-to-end', 'confidence': 0.9769867062568665, 'text_region': [[104.0, 869.0], [571.0, 869.0], [571.0, 888.0], [104.0, 888.0]]}, {'text': 'scenetextrecognition.In2ol1IEEEInternationalConfer', 'confidence': 0.9727677702903748, 'text_region': [[139.0, 892.0], [570.0, 892.0], [570.0, 911.0], [139.0, 911.0]]}, {'text': 'ence on ComputerVision (ICCV),pages1457-1464.IEEE', 'confidence': 0.9701538681983948, 'text_region': [[140.0, 913.0], [569.0, 913.0], [569.0, 932.0], [140.0, 932.0]]}, {'text': '2011.', 'confidence': 0.9994584321975708, 'text_region': [[139.0, 934.0], [182.0, 934.0], [182.0, 953.0], [139.0, 953.0]]}, {'text': '46]TaoWang,David JWu,AdamCoates,andAndrewY Ng', 'confidence': 0.972873330116272, 'text_region': [[104.0, 960.0], [570.0, 960.0], [570.0, 978.0], [104.0, 978.0]]}, {'text': 'End-to-endtextrecognitionwithconvolutionalneuralnet-', 'confidence': 0.9990155696868896, 'text_region': [[139.0, 982.0], [573.0, 982.0], [573.0, 999.0], [139.0, 999.0]]}, {'text': 'works.In201221stInternationalConferenceonPattern', 'confidence': 0.9832344055175781, 'text_region': [[139.0, 1002.0], [573.0, 1005.0], [573.0, 1022.0], [139.0, 1019.0]]}, {'text': 'Recognition (ICPR),pages 3304-3308.IEEE,2012', 'confidence': 0.9739656448364258, 'text_region': [[136.0, 1022.0], [514.0, 1023.0], [513.0, 1046.0], [136.0, 1044.0]]}, {'text': '47]Xiaobing Wang,Yingying Jiang,ZhenboLuo,Cheng-Lin', 'confidence': 0.9680148363113403, 'text_region': [[104.0, 1050.0], [573.0, 1050.0], [573.0, 1068.0], [104.0, 1068.0]]}, {'text': 'Liu, Hyunsoo Choi, and Sungjin Kim.Arbitrary shape scene', 'confidence': 0.9677753448486328, 'text_region': [[137.0, 1071.0], [573.0, 1072.0], [573.0, 1091.0], [137.0, 1089.0]]}, {'text': 'text detection with adaptive text regionrepresentation.In', 'confidence': 0.9584536552429199, 'text_region': [[140.0, 1092.0], [571.0, 1092.0], [571.0, 1111.0], [140.0, 1111.0]]}, {'text': 'ProceedingsoftheIEEEConferenceonComputerVision', 'confidence': 0.9965277314186096, 'text_region': [[139.0, 1116.0], [573.0, 1116.0], [573.0, 1134.0], [139.0, 1134.0]]}, {'text': 'andPattern Recognition,pages 6449-6458,2019.', 'confidence': 0.976096510887146, 'text_region': [[137.0, 1136.0], [499.0, 1134.0], [499.0, 1157.0], [137.0, 1158.0]]}, {'text': '48]Xinlong Wang,Zhipeng Man,Mingyu You,and Chunhua', 'confidence': 0.968415379524231, 'text_region': [[104.0, 1162.0], [573.0, 1162.0], [573.0, 1181.0], [104.0, 1181.0]]}, {'text': 'Shen.Adversarialgeneration of trainingexamples:Appli-', 'confidence': 0.9817148447036743, 'text_region': [[140.0, 1184.0], [570.0, 1184.0], [570.0, 1202.0], [140.0, 1202.0]]}, {'text': 'cations tomovingvehiclelicenseplate recognition.arXiv', 'confidence': 0.9848331809043884, 'text_region': [[140.0, 1206.0], [573.0, 1206.0], [573.0, 1225.0], [140.0, 1225.0]]}, {'text': 'preprint arXiv:1707.03124,2017', 'confidence': 0.9775673151016235, 'text_region': [[136.0, 1226.0], [380.0, 1223.0], [381.0, 1246.0], [136.0, 1249.0]]}, {'text': '[49]Qixiang Ye and David Doermann.Text detection and recog', 'confidence': 0.9775403738021851, 'text_region': [[101.0, 1248.0], [571.0, 1250.0], [571.0, 1272.0], [101.0, 1271.0]]}, {'text': 'nitioninimagery:Asurvey.IEEEtransactions onpattern', 'confidence': 0.9876695275306702, 'text_region': [[140.0, 1274.0], [573.0, 1274.0], [573.0, 1292.0], [140.0, 1292.0]]}, {'text': 'analysisandmachineintelligence,37(7):1480-1500,2015.', 'confidence': 0.984143853187561, 'text_region': [[140.0, 1296.0], [566.0, 1296.0], [566.0, 1313.0], [140.0, 1313.0]]}, {'text': '50]Fangneng Zhan,Shijian Lu,and Chuhui Xue.Verisimilar', 'confidence': 0.9778396487236023, 'text_region': [[104.0, 1319.0], [573.0, 1319.0], [573.0, 1337.0], [104.0, 1337.0]]}, {'text': 'image synthesis for accurate detection and recognition of', 'confidence': 0.9833113551139832, 'text_region': [[137.0, 1340.0], [573.0, 1338.0], [573.0, 1361.0], [137.0, 1362.0]]}, {'text': 'texts in scenes.InProc.ECCV,2018', 'confidence': 0.9714483022689819, 'text_region': [[140.0, 1364.0], [410.0, 1364.0], [410.0, 1381.0], [140.0, 1381.0]]}, {'text': '51]FangnengZhan,Hongyuan Zhu,andShijianLu.Spatial fu-', 'confidence': 0.9690790176391602, 'text_region': [[104.0, 1388.0], [570.0, 1388.0], [570.0, 1405.0], [104.0, 1405.0]]}], 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [619, 151, 1090, 366], 'res': [{'text': 'ConferenceonComputerVisionandPatternRecognition', 'confidence': 0.9819054007530212, 'text_region': [[658.0, 152.0], [1087.0, 153.0], [1087.0, 170.0], [658.0, 169.0]]}, {'text': 'pages3653-3662,2019.', 'confidence': 0.9895757436752319, 'text_region': [[655.0, 174.0], [834.0, 172.0], [834.0, 191.0], [655.0, 193.0]]}, {'text': '[52]Chengquan Zhang,BorongLiang,Zuming Huang,Mengy]', 'confidence': 0.9608920812606812, 'text_region': [[620.0, 196.0], [1088.0, 198.0], [1088.0, 217.0], [620.0, 215.0]]}, {'text': 'En,Junyu Han,Errui Ding,and Xinghao Ding.Look more', 'confidence': 0.9862540364265442, 'text_region': [[656.0, 219.0], [1088.0, 219.0], [1088.0, 238.0], [656.0, 238.0]]}, {'text': 'than once:An accurate detector for text of arbitrary shapes.', 'confidence': 0.944625198841095, 'text_region': [[656.0, 239.0], [1088.0, 241.0], [1088.0, 260.0], [656.0, 258.0]]}, {'text': 'ProceedingsoftheIEEEConferenceonComputerVision', 'confidence': 0.9893120527267456, 'text_region': [[659.0, 264.0], [1088.0, 264.0], [1088.0, 281.0], [659.0, 281.0]]}, {'text': 'andPatternRecognition(CVPR),2019', 'confidence': 0.9829097390174866, 'text_region': [[659.0, 286.0], [941.0, 286.0], [941.0, 300.0], [659.0, 300.0]]}, {'text': '53]Xinyu Zhou,CongYao,HeWen,YuzhiWang,Shuchang', 'confidence': 0.9803789258003235, 'text_region': [[622.0, 309.0], [1087.0, 309.0], [1087.0, 326.0], [622.0, 326.0]]}, {'text': 'Zhou,WeiranHe,andJiajunLiang.EAST:Anefficient and', 'confidence': 0.9848479628562927, 'text_region': [[658.0, 331.0], [1088.0, 331.0], [1088.0, 348.0], [658.0, 348.0]]}, {'text': 'InPr0c.CVPR.2017', 'confidence': 0.9582473039627075, 'text_region': [[857.0, 354.0], [1018.0, 354.0], [1018.0, 365.0], [857.0, 365.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:42:36] ppocr DEBUG: dt_boxes num : 22, elapsed : 0.1702895164489746\n",
      "[2024/05/30 16:42:39] ppocr DEBUG: rec_res num  : 22, elapsed : 2.422217607498169\n",
      "[2024/05/30 16:42:39] ppocr DEBUG: dt_boxes num : 11, elapsed : 0.12809109687805176\n",
      "[2024/05/30 16:42:40] ppocr DEBUG: rec_res num  : 11, elapsed : 1.1869292259216309\n",
      "[2024/05/30 16:42:40] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.09654569625854492\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: rec_res num  : 4, elapsed : 0.49094223976135254\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: dt_boxes num : 0, elapsed : 0.08257722854614258\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: rec_res num  : 0, elapsed : 1.9073486328125e-06\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.015064239501953125\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: rec_res num  : 3, elapsed : 0.12156867980957031\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.08789587020874023\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: rec_res num  : 3, elapsed : 0.260303258895874\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.0682063102722168\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: rec_res num  : 1, elapsed : 0.12167859077453613\n",
      "[2024/05/30 16:42:41] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.050595760345458984\n",
      "[2024/05/30 16:42:42] ppocr DEBUG: rec_res num  : 1, elapsed : 0.08038043975830078\n",
      "[2024/05/30 16:42:42] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.057488203048706055\n",
      "[2024/05/30 16:42:42] ppocr DEBUG: rec_res num  : 1, elapsed : 0.1119694709777832\n",
      "[2024/05/30 16:42:42] ppocr DEBUG: dt_boxes num : 19, elapsed : 0.16111540794372559\n",
      "[2024/05/30 16:42:43] ppocr DEBUG: rec_res num  : 19, elapsed : 0.7878358364105225\n",
      "[2024/05/30 16:42:43] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.07612085342407227\n",
      "[2024/05/30 16:42:43] ppocr DEBUG: rec_res num  : 2, elapsed : 0.24753260612487793\n",
      "[2024/05/30 16:42:43] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.07805967330932617\n",
      "[2024/05/30 16:42:43] ppocr DEBUG: rec_res num  : 3, elapsed : 0.31056952476501465\n",
      "{'type': 'text', 'bbox': [98, 398, 573, 912], 'res': [{'text': 'Duringtheexperiments ofscenetextrecognitionforEn-', 'confidence': 0.9895027279853821, 'text_region': [[125.0, 398.0], [570.0, 398.0], [570.0, 418.0], [125.0, 418.0]]}, {'text': 'glish scripts,we notice that among the most widelyused', 'confidence': 0.9452914595603943, 'text_region': [[102.0, 421.0], [572.0, 421.0], [572.0, 441.0], [102.0, 441.0]]}, {'text': 'benchmarkdatasets,severalhaveincompleteannotations', 'confidence': 0.990002453327179, 'text_region': [[102.0, 446.0], [568.0, 446.0], [568.0, 463.0], [102.0, 463.0]]}, {'text': 'They areIIIT5K,SVT,SVTP,and CUTE-80.The annota-', 'confidence': 0.9480559825897217, 'text_region': [[100.0, 467.0], [571.0, 468.0], [571.0, 488.0], [100.0, 487.0]]}, {'text': 'tions of these datasets are case-insensitive,and ignore punc', 'confidence': 0.9548248648643494, 'text_region': [[99.0, 491.0], [569.0, 493.0], [569.0, 513.0], [99.0, 511.0]]}, {'text': 'tuationmarks.', 'confidence': 0.9780445694923401, 'text_region': [[103.0, 519.0], [215.0, 519.0], [215.0, 534.0], [103.0, 534.0]]}, {'text': 'Thecommonpracticeforrecentscenetextrecognition', 'confidence': 0.9992943406105042, 'text_region': [[123.0, 540.0], [571.0, 541.0], [571.0, 561.0], [123.0, 560.0]]}, {'text': 'researchistoconvertbothpredictionandground-truthtext', 'confidence': 0.9979109168052673, 'text_region': [[101.0, 566.0], [571.0, 565.0], [571.0, 582.0], [101.0, 583.0]]}, {'text': 'stringstolower-caseandthencomparethem.Thismeans', 'confidence': 0.9988812208175659, 'text_region': [[101.0, 590.0], [571.0, 590.0], [571.0, 607.0], [101.0, 607.0]]}, {'text': 'that the current evaluationisflawed.Itignoresletter case', 'confidence': 0.9715712666511536, 'text_region': [[99.0, 611.0], [572.0, 613.0], [572.0, 633.0], [99.0, 631.0]]}, {'text': 'andpunctuationmarkswhicharecrucialtotheunderstand', 'confidence': 0.9984733462333679, 'text_region': [[102.0, 637.0], [569.0, 637.0], [569.0, 654.0], [102.0, 654.0]]}, {'text': 'ingofthetextcontents.Besides,evaluatingonamuch', 'confidence': 0.9907326698303223, 'text_region': [[102.0, 661.0], [571.0, 661.0], [571.0, 678.0], [102.0, 678.0]]}, {'text': 'smallervocabularysetresultsin over-optimism of theper-', 'confidence': 0.974994421005249, 'text_region': [[100.0, 682.0], [571.0, 684.0], [571.0, 704.0], [100.0, 702.0]]}, {'text': 'formanceoftherecognitionmodels.', 'confidence': 0.9847807884216309, 'text_region': [[102.0, 709.0], [387.0, 709.0], [387.0, 726.0], [102.0, 726.0]]}, {'text': 'Toaid further research,we use the Amazon mechan-', 'confidence': 0.9517845511436462, 'text_region': [[123.0, 730.0], [570.0, 731.0], [570.0, 751.0], [123.0, 750.0]]}, {'text': 'icalTurk(AMT）tore-annotate theaforementioned4', 'confidence': 0.9756576418876648, 'text_region': [[101.0, 755.0], [572.0, 755.0], [572.0, 775.0], [101.0, 775.0]]}, {'text': 'latasets,whichamountto6837wordimagesintotal', 'confidence': 0.9830257296562195, 'text_region': [[104.0, 782.0], [568.0, 782.0], [568.0, 797.0], [104.0, 797.0]]}, {'text': 'Eachwordimageisannotatedby3workers,andwe', 'confidence': 0.9880527257919312, 'text_region': [[101.0, 804.0], [571.0, 805.0], [571.0, 822.0], [101.0, 821.0]]}, {'text': 'manuallycheckandcorrectimageswherethe3an-', 'confidence': 0.9905795454978943, 'text_region': [[102.0, 829.0], [570.0, 829.0], [570.0, 846.0], [102.0, 846.0]]}, {'text': 'notationsdiffer.', 'confidence': 0.9976100325584412, 'text_region': [[102.0, 854.0], [241.0, 854.0], [241.0, 868.0], [102.0, 868.0]]}, {'text': 'Theannotateddatasetsarereleasec', 'confidence': 0.9825746417045593, 'text_region': [[261.0, 854.0], [569.0, 854.0], [569.0, 868.0], [261.0, 868.0]]}, {'text': 'viaGitHubathttps://github.com/Jyouhou/', 'confidence': 0.9948514699935913, 'text_region': [[100.0, 876.0], [567.0, 877.0], [567.0, 894.0], [100.0, 893.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [99, 1075, 574, 1331], 'res': [{'text': 'As we areencouragingcase-sensitive(alsowith punctua-', 'confidence': 0.974373459815979, 'text_region': [[124.0, 1075.0], [571.0, 1076.0], [571.0, 1096.0], [124.0, 1095.0]]}, {'text': 'tionmarks)evaluationfor scenetextrecognition,wewould', 'confidence': 0.9878533482551575, 'text_region': [[101.0, 1099.0], [572.0, 1098.0], [572.0, 1118.0], [101.0, 1119.0]]}, {'text': 'liketoprovidebenchmarkperformancesonthosewidely', 'confidence': 0.9990656971931458, 'text_region': [[101.0, 1123.0], [571.0, 1123.0], [571.0, 1143.0], [101.0, 1143.0]]}, {'text': 'useddatasets.Weevaluatetwoimplementationsof the', 'confidence': 0.9882621169090271, 'text_region': [[100.0, 1147.0], [572.0, 1146.0], [572.0, 1166.0], [100.0, 1167.0]]}, {'text': \"ASTER models,byLong et al.'andBaeket alrespec-\", 'confidence': 0.935720682144165, 'text_region': [[101.0, 1170.0], [570.0, 1170.0], [570.0, 1190.0], [101.0, 1190.0]]}, {'text': 'tively.Results are summarized in Tab.7.', 'confidence': 0.9671229720115662, 'text_region': [[100.0, 1196.0], [427.0, 1193.0], [428.0, 1213.0], [100.0, 1216.0]]}, {'text': 'Thetwobenchmarkimplementationsperformcompara-', 'confidence': 0.9972662329673767, 'text_region': [[124.0, 1218.0], [572.0, 1219.0], [572.0, 1239.0], [124.0, 1238.0]]}, {'text': \"bly,withBaek'sbetter on straighttext andLong'sbetter at\", 'confidence': 0.9591116905212402, 'text_region': [[101.0, 1242.0], [573.0, 1243.0], [573.0, 1263.0], [101.0, 1262.0]]}, {'text': 'curvedtext.Comparedwithevaluationwithlowercase+', 'confidence': 0.998347818851471, 'text_region': [[102.0, 1268.0], [572.0, 1268.0], [572.0, 1285.0], [102.0, 1285.0]]}, {'text': 'digits,theperformancedropsconsiderablyforbothmodels', 'confidence': 0.9930998086929321, 'text_region': [[101.0, 1292.0], [571.0, 1290.0], [571.0, 1309.0], [101.0, 1311.0]]}, {'text': 'whenweevaluatewithallsymbols.Theseresultsindicate', 'confidence': 0.996159017086029, 'text_region': [[100.0, 1315.0], [571.0, 1314.0], [571.0, 1330.0], [100.0, 1330.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [98, 187, 573, 297], 'res': [{'text': 'Inthiswork,weuseatotalnumberof30scenemodels', 'confidence': 0.9812684059143066, 'text_region': [[126.0, 189.0], [570.0, 189.0], [570.0, 205.0], [126.0, 205.0]]}, {'text': 'whichareallobtainedfromtheInternet.However,mostof', 'confidence': 0.9867541193962097, 'text_region': [[102.0, 212.0], [570.0, 212.0], [570.0, 228.0], [102.0, 228.0]]}, {'text': 'thesemodels arenotfree.Therefore,we arenot allowed to', 'confidence': 0.9768580794334412, 'text_region': [[100.0, 234.0], [571.0, 235.0], [571.0, 255.0], [100.0, 253.0]]}, {'text': 'sharethemodelsthemselves.Instead,welistthemodelswe', 'confidence': 0.9863555431365967, 'text_region': [[102.0, 260.0], [570.0, 260.0], [570.0, 276.0], [102.0, 276.0]]}], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [616, 502, 1087, 542], 'res': [], 'img_idx': 0}\n",
      "{'type': 'text', 'bbox': [100, 976, 571, 1017], 'res': [{'text': 'stratethenew', 'confidence': 0.9971721172332764, 'text_region': [[100.0, 1000.0], [214.0, 1002.0], [214.0, 1016.0], [100.0, 1014.0]]}, {'text': 'annotations', 'confidence': 0.9960553646087646, 'text_region': [[214.0, 1003.0], [308.0, 1002.0], [308.0, 1014.0], [214.0, 1016.0]]}, {'text': 'inFig.', 'confidence': 0.8431763052940369, 'text_region': [[310.0, 1002.0], [363.0, 1002.0], [363.0, 1014.0], [310.0, 1014.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [99, 327, 571, 375], 'res': [{'text': 'B.NewAnnotationsforScene', 'confidence': 0.9967624545097351, 'text_region': [[102.0, 329.0], [422.0, 334.0], [421.0, 350.0], [102.0, 345.0]]}, {'text': 'TextRecogni', 'confidence': 0.9937676787376404, 'text_region': [[418.0, 333.0], [562.0, 331.0], [562.0, 348.0], [419.0, 350.0]]}, {'text': 'tionDatasets', 'confidence': 0.9974325299263, 'text_region': [[100.0, 355.0], [233.0, 355.0], [233.0, 374.0], [100.0, 374.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [100, 1037, 380, 1054], 'res': [{'text': '2n31k28', 'confidence': 0.22682391107082367, 'text_region': [[175.0, 1043.0], [280.0, 1043.0], [280.0, 1049.0], [175.0, 1049.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [100, 939, 214, 958], 'res': [{'text': 'B.1Sample', 'confidence': 0.9933350682258606, 'text_region': [[105.0, 939.0], [204.0, 941.0], [204.0, 955.0], [104.0, 952.0]]}], 'img_idx': 0}\n",
      "{'type': 'title', 'bbox': [99, 147, 268, 165], 'res': [{'text': 'SceneMode', 'confidence': 0.9895869493484497, 'text_region': [[130.0, 150.0], [256.0, 150.0], [256.0, 162.0], [130.0, 162.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure', 'bbox': [611, 143, 1091, 419], 'res': [{'text': 'Dataset', 'confidence': 0.9972609877586365, 'text_region': [[621.0, 151.0], [672.0, 151.0], [672.0, 166.0], [621.0, 166.0]]}, {'text': 'SampleImage', 'confidence': 0.9952896237373352, 'text_region': [[701.0, 148.0], [794.0, 151.0], [794.0, 168.0], [701.0, 165.0]]}, {'text': 'Original Annotation', 'confidence': 0.9785372018814087, 'text_region': [[825.0, 150.0], [954.0, 150.0], [954.0, 166.0], [825.0, 166.0]]}, {'text': 'NewAnnotation', 'confidence': 0.9985300898551941, 'text_region': [[984.0, 151.0], [1086.0, 151.0], [1086.0, 164.0], [984.0, 164.0]]}, {'text': 'Team', 'confidence': 0.9889776110649109, 'text_region': [[716.0, 178.0], [786.0, 195.0], [780.0, 216.0], [710.0, 199.0]]}, {'text': 'CUTE80', 'confidence': 0.9984726905822754, 'text_region': [[620.0, 190.0], [678.0, 190.0], [678.0, 206.0], [620.0, 206.0]]}, {'text': 'TEAM', 'confidence': 0.9993855357170105, 'text_region': [[860.0, 191.0], [903.0, 191.0], [903.0, 205.0], [860.0, 205.0]]}, {'text': 'Team', 'confidence': 0.9956225156784058, 'text_region': [[1018.0, 190.0], [1054.0, 192.0], [1053.0, 207.0], [1017.0, 205.0]]}, {'text': '15%.', 'confidence': 0.9930968284606934, 'text_region': [[709.0, 240.0], [788.0, 236.0], [790.0, 273.0], [711.0, 277.0]]}, {'text': 'IIIT5K', 'confidence': 0.9603788256645203, 'text_region': [[621.0, 253.0], [664.0, 253.0], [664.0, 268.0], [621.0, 268.0]]}, {'text': '15', 'confidence': 0.9994914531707764, 'text_region': [[872.0, 252.0], [891.0, 252.0], [891.0, 269.0], [872.0, 269.0]]}, {'text': '15%.', 'confidence': 0.8868655562400818, 'text_region': [[1019.0, 252.0], [1050.0, 252.0], [1050.0, 268.0], [1019.0, 268.0]]}, {'text': 'SVT', 'confidence': 0.9987900257110596, 'text_region': [[620.0, 315.0], [653.0, 315.0], [653.0, 332.0], [620.0, 332.0]]}, {'text': 'Donald', 'confidence': 0.9894009232521057, 'text_region': [[709.0, 310.0], [788.0, 314.0], [787.0, 338.0], [708.0, 334.0]]}, {'text': 'DONALD', 'confidence': 0.9997202754020691, 'text_region': [[848.0, 315.0], [914.0, 315.0], [914.0, 331.0], [848.0, 331.0]]}, {'text': \"Donald'\", 'confidence': 0.9564723372459412, 'text_region': [[1010.0, 315.0], [1060.0, 315.0], [1060.0, 332.0], [1010.0, 332.0]]}, {'text': 'SVTP', 'confidence': 0.9980090260505676, 'text_region': [[621.0, 378.0], [660.0, 378.0], [660.0, 392.0], [621.0, 392.0]]}, {'text': 'MARLBORO', 'confidence': 0.9991759657859802, 'text_region': [[839.0, 379.0], [924.0, 379.0], [924.0, 392.0], [839.0, 392.0]]}, {'text': 'Marlboro', 'confidence': 0.9945895075798035, 'text_region': [[1005.0, 375.0], [1065.0, 377.0], [1065.0, 394.0], [1005.0, 392.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [683, 435, 1023, 453], 'res': [{'text': '?', 'confidence': 0.05598534643650055, 'text_region': [[702.0, 442.0], [733.0, 442.0], [733.0, 446.0], [702.0, 446.0]]}, {'text': '', 'confidence': 0.0, 'text_region': [[830.0, 442.0], [918.0, 442.0], [918.0, 446.0], [830.0, 446.0]]}], 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [101, 1352, 416, 1426], 'res': [{'text': 'https://qithub.com/Jyouhou/', 'confidence': 0.9886592626571655, 'text_region': [[128.0, 1352.0], [384.0, 1352.0], [384.0, 1367.0], [128.0, 1367.0]]}, {'text': 'ICDAR2019-ArT-Recognition-Alchemy', 'confidence': 0.9910761713981628, 'text_region': [[102.0, 1372.0], [415.0, 1372.0], [415.0, 1388.0], [102.0, 1388.0]]}, {'text': 'benchmark', 'confidence': 0.9982344508171082, 'text_region': [[313.0, 1412.0], [398.0, 1412.0], [398.0, 1424.0], [313.0, 1424.0]]}], 'img_idx': 0}\n",
      "[2024/05/30 16:42:44] ppocr DEBUG: dt_boxes num : 62, elapsed : 0.37928032875061035\n",
      "[2024/05/30 16:42:52] ppocr DEBUG: rec_res num  : 62, elapsed : 7.5502238273620605\n",
      "[2024/05/30 16:42:52] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.07971549034118652\n",
      "[2024/05/30 16:42:52] ppocr DEBUG: rec_res num  : 1, elapsed : 0.07474279403686523\n",
      "[2024/05/30 16:42:52] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.12155342102050781\n",
      "[2024/05/30 16:42:52] ppocr DEBUG: rec_res num  : 3, elapsed : 0.2629108428955078\n",
      "{'type': 'figure', 'bbox': [93, 250, 1113, 863], 'res': [{'text': 'Scene Name', 'confidence': 0.9507843852043152, 'text_region': [[133.0, 255.0], [216.0, 258.0], [216.0, 276.0], [132.0, 273.0]]}, {'text': 'Link', 'confidence': 0.9959591627120972, 'text_region': [[656.0, 259.0], [688.0, 259.0], [688.0, 273.0], [656.0, 273.0]]}, {'text': 'Urban City', 'confidence': 0.9899527430534363, 'text_region': [[138.0, 277.0], [211.0, 277.0], [211.0, 295.0], [138.0, 295.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/urban-city', 'confidence': 0.9955440759658813, 'text_region': [[368.0, 279.0], [975.0, 279.0], [975.0, 294.0], [368.0, 294.0]]}, {'text': 'MedievalVillage', 'confidence': 0.9925932288169861, 'text_region': [[119.0, 294.0], [230.0, 296.0], [230.0, 314.0], [118.0, 312.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/medieval-village', 'confidence': 0.9964585900306702, 'text_region': [[339.0, 298.0], [1001.0, 298.0], [1001.0, 313.0], [339.0, 313.0]]}, {'text': 'Loft', 'confidence': 0.9985622763633728, 'text_region': [[159.0, 316.0], [191.0, 316.0], [191.0, 332.0], [159.0, 332.0]]}, {'text': 'https://ue4arch.com/shop/complete-projects/archviz/loft/', 'confidence': 0.9973171949386597, 'text_region': [[411.0, 318.0], [930.0, 318.0], [930.0, 333.0], [411.0, 333.0]]}, {'text': 'Desert Town', 'confidence': 0.9758220911026001, 'text_region': [[133.0, 336.0], [216.0, 336.0], [216.0, 351.0], [133.0, 351.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/desert-town', 'confidence': 0.9963859915733337, 'text_region': [[363.0, 337.0], [979.0, 337.0], [979.0, 352.0], [363.0, 352.0]]}, {'text': 'Archinterior1', 'confidence': 0.9646068215370178, 'text_region': [[130.0, 355.0], [219.0, 355.0], [219.0, 370.0], [130.0, 370.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/archinteriors-vol-2-scene-01', 'confidence': 0.9910523891448975, 'text_region': [[283.0, 355.0], [1059.0, 355.0], [1059.0, 370.0], [283.0, 370.0]]}, {'text': 'DesertGasStation', 'confidence': 0.9984546899795532, 'text_region': [[115.0, 373.0], [234.0, 373.0], [234.0, 388.0], [115.0, 388.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/desert-gas-station', 'confidence': 0.9950870871543884, 'text_region': [[328.0, 372.0], [1014.0, 373.0], [1014.0, 392.0], [328.0, 390.0]]}, {'text': 'Modular School', 'confidence': 0.9783226847648621, 'text_region': [[124.0, 394.0], [226.0, 394.0], [226.0, 409.0], [124.0, 409.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/modular-school-pack', 'confidence': 0.9935160279273987, 'text_region': [[326.0, 394.0], [1018.0, 394.0], [1018.0, 409.0], [326.0, 409.0]]}, {'text': 'Factory District', 'confidence': 0.9895869493484497, 'text_region': [[124.0, 412.0], [227.0, 412.0], [227.0, 430.0], [124.0, 430.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/factory-district', 'confidence': 0.9970910549163818, 'text_region': [[339.0, 414.0], [1003.0, 414.0], [1003.0, 429.0], [339.0, 429.0]]}, {'text': 'AbandonedFactory', 'confidence': 0.9983097314834595, 'text_region': [[111.0, 430.0], [238.0, 431.0], [237.0, 449.0], [111.0, 448.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/modular-abandoned-factory', 'confidence': 0.9936281442642212, 'text_region': [[295.0, 431.0], [1046.0, 432.0], [1046.0, 450.0], [295.0, 449.0]]}, {'text': 'Buddhist', 'confidence': 0.998530387878418, 'text_region': [[145.0, 450.0], [206.0, 450.0], [206.0, 468.0], [145.0, 468.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/buddhist-monastery-environment', 'confidence': 0.9982785582542419, 'text_region': [[274.0, 451.0], [1068.0, 451.0], [1068.0, 469.0], [274.0, 469.0]]}, {'text': 'Castle Fortress', 'confidence': 0.9673781991004944, 'text_region': [[126.0, 468.0], [224.0, 470.0], [223.0, 489.0], [126.0, 486.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/castle-fortress', 'confidence': 0.9924089908599854, 'text_region': [[344.0, 472.0], [999.0, 472.0], [999.0, 487.0], [344.0, 487.0]]}, {'text': 'Desert Ruin', 'confidence': 0.9960229396820068, 'text_region': [[134.0, 488.0], [215.0, 488.0], [215.0, 506.0], [134.0, 506.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/modular-desert-ruins', 'confidence': 0.9940836429595947, 'text_region': [[320.0, 491.0], [1022.0, 491.0], [1022.0, 505.0], [320.0, 505.0]]}, {'text': 'HALArchviz', 'confidence': 0.9991384744644165, 'text_region': [[133.0, 509.0], [217.0, 509.0], [217.0, 524.0], [133.0, 524.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/hal-archviz-toolkit-vl', 'confidence': 0.9918938279151917, 'text_region': [[311.0, 510.0], [1030.0, 510.0], [1030.0, 525.0], [311.0, 525.0]]}, {'text': 'Hospital', 'confidence': 0.9998018741607666, 'text_region': [[146.0, 528.0], [203.0, 528.0], [203.0, 546.0], [146.0, 546.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/modular-sci-fi-hospital', 'confidence': 0.9956753849983215, 'text_region': [[307.0, 530.0], [1034.0, 530.0], [1034.0, 545.0], [307.0, 545.0]]}, {'text': 'HQ House', 'confidence': 0.9566218852996826, 'text_region': [[139.0, 545.0], [211.0, 547.0], [211.0, 565.0], [138.0, 563.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/hq-residential-house', 'confidence': 0.9970377683639526, 'text_region': [[320.0, 549.0], [1023.0, 549.0], [1023.0, 564.0], [320.0, 564.0]]}, {'text': 'Industrial City', 'confidence': 0.9558733105659485, 'text_region': [[127.0, 564.0], [221.0, 566.0], [220.0, 584.0], [127.0, 582.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/industrial-city', 'confidence': 0.9933883547782898, 'text_region': [[345.0, 568.0], [997.0, 568.0], [997.0, 583.0], [345.0, 583.0]]}, {'text': 'Archinterior2', 'confidence': 0.9944508671760559, 'text_region': [[130.0, 586.0], [219.0, 586.0], [219.0, 601.0], [130.0, 601.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/archinteriors-vol-4-scene-02', 'confidence': 0.990888774394989, 'text_region': [[283.0, 586.0], [1061.0, 586.0], [1061.0, 601.0], [283.0, 601.0]]}, {'text': 'Office', 'confidence': 0.9978905320167542, 'text_region': [[155.0, 605.0], [196.0, 605.0], [196.0, 621.0], [155.0, 621.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/retro-office-environment', 'confidence': 0.9962298274040222, 'text_region': [[302.0, 608.0], [1040.0, 608.0], [1040.0, 622.0], [302.0, 622.0]]}, {'text': 'MeetingRoom', 'confidence': 0.996705949306488, 'text_region': [[126.0, 622.0], [224.0, 625.0], [223.0, 643.0], [126.0, 640.0]]}, {'text': 'https://drive.google.com/file/d/0B_mjKk7NOcnEUWZuRDVFQ09STE0/view', 'confidence': 0.9694507122039795, 'text_region': [[366.0, 625.0], [976.0, 624.0], [976.0, 642.0], [366.0, 643.0]]}, {'text': 'Old Village', 'confidence': 0.9615929126739502, 'text_region': [[137.0, 643.0], [213.0, 643.0], [213.0, 661.0], [137.0, 661.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/old-village', 'confidence': 0.9954062700271606, 'text_region': [[363.0, 645.0], [980.0, 645.0], [980.0, 660.0], [363.0, 660.0]]}, {'text': 'Modular Building', 'confidence': 0.9637057185173035, 'text_region': [[117.0, 661.0], [232.0, 663.0], [232.0, 681.0], [116.0, 679.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/modular-building-set', 'confidence': 0.996263861656189, 'text_region': [[320.0, 665.0], [1021.0, 665.0], [1021.0, 680.0], [320.0, 680.0]]}, {'text': 'ModularHome', 'confidence': 0.9953542947769165, 'text_region': [[125.0, 680.0], [225.0, 682.0], [224.0, 700.0], [125.0, 698.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/supergenius-modular-home', 'confidence': 0.9980455040931702, 'text_region': [[301.0, 684.0], [1041.0, 684.0], [1041.0, 699.0], [301.0, 699.0]]}, {'text': 'Dungeon', 'confidence': 0.9996482729911804, 'text_region': [[144.0, 701.0], [207.0, 701.0], [207.0, 719.0], [144.0, 719.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/top-down-multistory-dungeons', 'confidence': 0.9963271617889404, 'text_region': [[283.0, 703.0], [1059.0, 703.0], [1059.0, 718.0], [283.0, 718.0]]}, {'text': 'Old Town', 'confidence': 0.9552776217460632, 'text_region': [[141.0, 717.0], [208.0, 720.0], [207.0, 738.0], [141.0, 735.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/old-town', 'confidence': 0.9949367046356201, 'text_region': [[377.0, 721.0], [966.0, 721.0], [966.0, 736.0], [377.0, 736.0]]}, {'text': 'Root Cellar', 'confidence': 0.9821325540542603, 'text_region': [[136.0, 737.0], [213.0, 740.0], [213.0, 758.0], [135.0, 755.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/root-cellar', 'confidence': 0.9974931478500366, 'text_region': [[363.0, 741.0], [979.0, 741.0], [979.0, 759.0], [363.0, 759.0]]}, {'text': 'Victorian', 'confidence': 0.9955775737762451, 'text_region': [[144.0, 756.0], [208.0, 760.0], [207.0, 778.0], [143.0, 774.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/victorian-street', 'confidence': 0.9977972507476807, 'text_region': [[339.0, 761.0], [1003.0, 761.0], [1003.0, 776.0], [339.0, 776.0]]}, {'text': 'Spaceship', 'confidence': 0.9984828233718872, 'text_region': [[141.0, 778.0], [208.0, 778.0], [208.0, 796.0], [141.0, 796.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/spaceship-interior-environment-set', 'confidence': 0.9963538646697998, 'text_region': [[256.0, 780.0], [1086.0, 780.0], [1086.0, 795.0], [256.0, 795.0]]}, {'text': 'Top-Down City', 'confidence': 0.9836369752883911, 'text_region': [[126.0, 797.0], [225.0, 797.0], [225.0, 815.0], [126.0, 815.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/top-down-city', 'confidence': 0.9924904108047485, 'text_region': [[352.0, 798.0], [989.0, 799.0], [989.0, 814.0], [352.0, 813.0]]}, {'text': 'Scene Name', 'confidence': 0.9523543119430542, 'text_region': [[133.0, 817.0], [216.0, 817.0], [216.0, 835.0], [133.0, 835.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/urban-city', 'confidence': 0.9976435899734497, 'text_region': [[366.0, 817.0], [976.0, 818.0], [976.0, 836.0], [366.0, 835.0]]}, {'text': 'Utopian City', 'confidence': 0.9682161211967468, 'text_region': [[132.0, 834.0], [216.0, 837.0], [216.0, 856.0], [131.0, 853.0]]}, {'text': 'https://www.unrealengine.com/marketplace/en-Us/product/utopian-city', 'confidence': 0.9943206310272217, 'text_region': [[359.0, 839.0], [984.0, 839.0], [984.0, 853.0], [359.0, 853.0]]}], 'img_idx': 0}\n",
      "{'type': 'figure_caption', 'bbox': [376, 868, 813, 885], 'res': [{'text': '1151', 'confidence': 0.49420320987701416, 'text_region': [[745.0, 875.0], [774.0, 875.0], [774.0, 879.0], [745.0, 879.0]]}], 'img_idx': 0}\n",
      "{'type': 'table', 'bbox': [178, 1121, 1005, 1256], 'res': '', 'img_idx': 0}\n",
      "{'type': 'reference', 'bbox': [162, 1265, 1059, 1307], 'res': [{'text': 'ResultsonEnglishdatasets(wordle', 'confidence': 0.9945375919342041, 'text_region': [[171.0, 1268.0], [463.0, 1268.0], [463.0, 1285.0], [171.0, 1285.0]]}, {'text': 'accufacy)', 'confidence': 0.7737398147583008, 'text_region': [[491.0, 1272.0], [567.0, 1272.0], [567.0, 1281.0], [491.0, 1281.0]]}, {'text': 'theevaluationconsiderslowercasecharac', 'confidence': 0.9984344244003296, 'text_region': [[716.0, 1268.0], [1057.0, 1268.0], [1057.0, 1285.0], [716.0, 1285.0]]}], 'img_idx': 0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PPStructure,save_structure_res\n",
    "from paddle.utils import try_import\n",
    "from PIL import Image\n",
    "\n",
    "ocr_engine = PPStructure(table=False, ocr=True, show_log=True)\n",
    "\n",
    "save_folder = './output'\n",
    "img_path = '../data/ppocr_img/recovery/UnrealText.pdf'\n",
    "\n",
    "fitz = try_import(\"fitz\")\n",
    "imgs = []\n",
    "with fitz.open(img_path) as pdf:\n",
    "    for pg in range(0, pdf.page_count):\n",
    "        page = pdf[pg]\n",
    "        mat = fitz.Matrix(2, 2)\n",
    "        pm = page.get_pixmap(matrix=mat, alpha=False)\n",
    "\n",
    "        # if width or height > 2000 pixels, don't enlarge the image\n",
    "        if pm.width > 2000 or pm.height > 2000:\n",
    "            pm = page.get_pixmap(matrix=fitz.Matrix(1, 1), alpha=False)\n",
    "\n",
    "        img = Image.frombytes(\"RGB\", [pm.width, pm.height], pm.samples)\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        imgs.append(img)\n",
    "\n",
    "for index, img in enumerate(imgs):\n",
    "    result = ocr_engine(img)\n",
    "    save_structure_res(result, save_folder, os.path.basename(img_path).split('.')[0], index)\n",
    "    for line in result:\n",
    "        line.pop('img')\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 版面恢复:\n",
    "\n",
    "包含版面分析 + 表格识别\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/05/30 16:34:25] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/liangzhu/.paddleocr/whl/det/ch/ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/liangzhu/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir=None, cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir='/home/liangzhu/.paddleocr/whl/table/ch_ppstructure_mobile_v2.0_SLANet_infer', merge_no_span_structure=True, table_char_dict_path='/home/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/table_structure_dict_ch.txt', layout_model_dir='/home/liangzhu/.paddleocr/whl/layout/picodet_lcnet_x1_0_fgd_layout_cdla_infer', layout_dict_path='/home/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/layout_dict/layout_cdla_dict.txt', layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=True, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/05/30 16:34:28] ppocr DEBUG: dt_boxes num : 6, elapsed : 0.35968756675720215\n",
      "[2024/05/30 16:34:29] ppocr DEBUG: rec_res num  : 6, elapsed : 0.7817742824554443\n",
      "[2024/05/30 16:34:29] ppocr DEBUG: dt_boxes num : 4, elapsed : 0.267925500869751\n",
      "[2024/05/30 16:34:30] ppocr DEBUG: rec_res num  : 4, elapsed : 0.44135141372680664\n",
      "[2024/05/30 16:34:30] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.24258756637573242\n",
      "[2024/05/30 16:34:30] ppocr DEBUG: rec_res num  : 1, elapsed : 0.07065653800964355\n",
      "[2024/05/30 16:34:30] ppocr DEBUG: dt_boxes num : 23, elapsed : 0.2547035217285156\n",
      "[2024/05/30 16:34:31] ppocr DEBUG: rec_res num  : 23, elapsed : 0.6335570812225342\n",
      "[2024/05/30 16:34:31] ppocr DEBUG: dt_boxes num : 2, elapsed : 0.2297217845916748\n",
      "[2024/05/30 16:34:31] ppocr DEBUG: rec_res num  : 2, elapsed : 0.16411185264587402\n",
      "[2024/05/30 16:34:31] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.22698259353637695\n",
      "[2024/05/30 16:34:32] ppocr DEBUG: rec_res num  : 1, elapsed : 0.19538521766662598\n",
      "[2024/05/30 16:34:34] ppocr DEBUG: dt_boxes num : 80, elapse : 0.18213582038879395\n",
      "[2024/05/30 16:34:36] ppocr DEBUG: rec_res num  : 80, elapse : 2.0738141536712646\n",
      "[2024/05/30 16:34:39] ppocr DEBUG: dt_boxes num : 110, elapse : 0.22570538520812988\n",
      "[2024/05/30 16:34:41] ppocr DEBUG: rec_res num  : 110, elapse : 2.8511459827423096\n",
      "[2024/05/30 16:34:42] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.3181023597717285\n",
      "[2024/05/30 16:34:42] ppocr DEBUG: rec_res num  : 1, elapsed : 0.15220379829406738\n",
      "[2024/05/30 16:34:42] ppocr DEBUG: dt_boxes num : 3, elapsed : 0.32645225524902344\n",
      "[2024/05/30 16:34:43] ppocr DEBUG: rec_res num  : 3, elapsed : 0.6562418937683105\n",
      "[2024/05/30 16:34:44] ppocr INFO: docx save to ./output/1_ocr.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from paddleocr import PPStructure,save_structure_res\n",
    "from paddleocr.ppstructure.recovery.recovery_to_doc import sorted_layout_boxes, convert_info_docx\n",
    "\n",
    "# 中文测试图\n",
    "table_engine = PPStructure(recovery=True)\n",
    "# 英文测试图\n",
    "# table_engine = PPStructure(recovery=True, lang='en')\n",
    "\n",
    "save_folder = './output'\n",
    "img_path = '../data/ppocr_img/table/1.png'\n",
    "img = cv2.imread(img_path)\n",
    "result = table_engine(img)\n",
    "save_structure_res(result, save_folder, os.path.basename(img_path).split('.')[0])\n",
    "\n",
    "h, w, _ = img.shape\n",
    "res = sorted_layout_boxes(result, w)\n",
    "convert_info_docx(img, res, save_folder, os.path.basename(img_path).split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/06/03 10:44:13] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/liangzhu/.paddleocr/whl/det/ch/ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/liangzhu/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir=None, cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir='/Users/liangzhu/.paddleocr/whl/table/ch_ppstructure_mobile_v2.0_SLANet_infer', merge_no_span_structure=True, table_char_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/table_structure_dict_ch.txt', layout_model_dir='/Users/liangzhu/.paddleocr/whl/layout/picodet_lcnet_x1_0_fgd_layout_cdla_infer', layout_dict_path='/Users/liangzhu/anaconda3/envs/dify/lib/python3.10/site-packages/paddleocr/ppocr/utils/dict/layout_dict/layout_cdla_dict.txt', layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=False, recovery=True, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2', save_pdf=False)\n",
      "[2024/06/03 10:44:17] ppocr DEBUG: dt_boxes num : 25, elapse : 0.23089814186096191\n",
      "[2024/06/03 10:44:20] ppocr DEBUG: rec_res num  : 25, elapse : 2.485382080078125\n",
      "[2024/06/03 10:44:21] ppocr DEBUG: dt_boxes num : 29, elapse : 0.17829012870788574\n",
      "[2024/06/03 10:44:23] ppocr DEBUG: rec_res num  : 29, elapse : 2.7906439304351807\n",
      "[2024/06/03 10:44:24] ppocr DEBUG: dt_boxes num : 12, elapse : 0.17819690704345703\n",
      "[2024/06/03 10:44:26] ppocr DEBUG: rec_res num  : 12, elapse : 1.314337968826294\n",
      "[2024/06/03 10:44:27] ppocr DEBUG: dt_boxes num : 22, elapse : 0.16357779502868652\n",
      "[2024/06/03 10:44:29] ppocr DEBUG: rec_res num  : 22, elapse : 2.32179594039917\n",
      "[2024/06/03 10:44:29] ppocr INFO: docx save to ./output_pp_structure/UnrealText_ocr.docx\n",
      "[2024/06/03 10:44:31] ppocr DEBUG: dt_boxes num : 41, elapse : 0.28499317169189453\n",
      "[2024/06/03 10:44:35] ppocr DEBUG: rec_res num  : 41, elapse : 4.054196119308472\n",
      "[2024/06/03 10:44:36] ppocr DEBUG: dt_boxes num : 18, elapse : 0.26437878608703613\n",
      "[2024/06/03 10:44:40] ppocr DEBUG: rec_res num  : 18, elapse : 4.168055057525635\n",
      "[2024/06/03 10:44:40] ppocr INFO: docx save to ./output_pp_structure/UnrealText_ocr.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddleocr import PPStructure,save_structure_res\n",
    "from paddle.utils import try_import\n",
    "from PIL import Image\n",
    "from paddleocr.ppstructure.recovery.recovery_to_doc import sorted_layout_boxes, convert_info_docx\n",
    "\n",
    "ocr_engine = PPStructure(recovery=True, structure_version='PP-StructureV2', save_pdf=False, ocr=False)\n",
    "\n",
    "save_folder = './output_pp_structure'\n",
    "pdf_path = '../data/表格.pdf'\n",
    "\n",
    "fitz = try_import(\"fitz\")\n",
    "imgs = []\n",
    "with fitz.open(pdf_path) as pdf:\n",
    "    for pg in range(0, pdf.page_count):\n",
    "        page = pdf[pg]\n",
    "        mat = fitz.Matrix(2, 2)\n",
    "        pm = page.get_pixmap(matrix=mat, alpha=False)\n",
    "\n",
    "        # if width or height > 2000 pixels, don't enlarge the image\n",
    "        if pm.width > 2000 or pm.height > 2000:\n",
    "            pm = page.get_pixmap(matrix=fitz.Matrix(1, 1), alpha=False)\n",
    "\n",
    "        img = Image.frombytes(\"RGB\", [pm.width, pm.height], pm.samples)\n",
    "        img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
    "        imgs.append(img)\n",
    "\n",
    "for index, img in enumerate(imgs):\n",
    "    result = ocr_engine(img)\n",
    "    save_structure_res(result, save_folder, os.path.basename(img_path).split('.')[0], index)\n",
    "    h, w, _ = img.shape\n",
    "    res = sorted_layout_boxes(result, w)\n",
    "    convert_info_docx(img, res, save_folder, os.path.basename(img_path).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
