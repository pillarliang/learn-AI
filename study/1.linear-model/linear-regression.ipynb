{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression API simply application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3 0.7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([86.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# load data\n",
    "x = [[80, 86],\n",
    "     [82, 80],\n",
    "     [85, 78],\n",
    "     [90, 90],\n",
    "     [86, 82],\n",
    "     [82, 90],\n",
    "     [78, 80],\n",
    "     [92, 94]]\n",
    "\n",
    "y = [84.2, 80.6, 80.1, 90, 83.2, 87.6, 79.4, 93.4]\n",
    "\n",
    "# create model\n",
    "estimator = LinearRegression()\n",
    "\n",
    "# train model\n",
    "estimator.fit(x, y)\n",
    "\n",
    "# print coef\n",
    "print(estimator.coef_)\n",
    "\n",
    "# use model to predict\n",
    "estimator.predict([[100, 80]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boston house price forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict result: [28.22944896 31.5122308  21.11612841 32.6663189  20.0023467  19.07315705\n",
      " 21.09772798 19.61400153 19.61907059 32.87611987 20.97911561 27.52898011\n",
      " 15.54701758 19.78630176 36.88641203 18.81202132  9.35912225 18.49452615\n",
      " 30.66499315 24.30184448 19.08220837 34.11391208 29.81386585 17.51775647\n",
      " 34.91026707 26.54967053 34.71035391 27.4268996  19.09095832 14.92742976\n",
      " 30.86877936 15.88271775 37.17548808  7.72101675 16.24074861 17.19211608\n",
      "  7.42140081 20.0098852  40.58481466 28.93190595 25.25404307 17.74970308\n",
      " 38.76446932  6.87996052 21.80450956 25.29110265 20.427491   20.4698034\n",
      " 17.25330064 26.12442519  8.48268143 27.50871869 30.58284841 16.56039764\n",
      "  9.38919181 35.54434377 32.29801978 21.81298945 17.60263689 22.0804256\n",
      " 23.49262401 24.10617033 20.1346492  38.5268066  24.58319594 19.78072415\n",
      " 13.93429891  6.75507808 42.03759064 21.9215625  16.91352899 22.58327744\n",
      " 40.76440704 21.3998946  36.89912238 27.19273661 20.97945544 20.37925063\n",
      " 25.3536439  22.18729123 31.13342301 20.39451125 23.99224334 31.54729547\n",
      " 26.74581308 20.90199941 29.08225233 21.98331503 26.29101202 20.17329401\n",
      " 25.49225305 24.09171045 19.90739221 16.35154974 15.25184758 18.40766132\n",
      " 24.83797801 16.61703662 20.89470344 26.70854061 20.7591883  17.88403312\n",
      " 24.28656105 23.37651493 21.64202047 36.81476219 15.86570054 21.42338732\n",
      " 32.81366203 33.74086414 20.61688336 26.88191023 22.65739323 17.35731771\n",
      " 21.67699248 21.65034728 27.66728556 25.04691687 23.73976625 14.6649641\n",
      " 15.17700342  3.81620663 29.18194848 20.68544417 22.32934783 28.01568563\n",
      " 28.58237108]\n",
      "coefficients: [-0.64817766  1.14673408 -0.05949444  0.74216553 -1.95515269  2.70902585\n",
      " -0.07737374 -3.29889391  2.50267196 -1.85679269 -1.75044624  0.87341624\n",
      " -3.91336869]\n",
      "intercept in the model: 22.62137203166228\n",
      "error: 20.62751376309541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangzhu/anaconda3/envs/skl-learn-old/lib/python3.11/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "def linear_model_normal_equation():\n",
    "    \"\"\"METHOD1: NORMAL EQUATION\n",
    "    \"\"\"\n",
    "    # 1. get data\n",
    "    data = load_boston()\n",
    "\n",
    "    # 2. data preparation\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state=22)\n",
    "\n",
    "    # 3. Normalization\n",
    "    transformer = StandardScaler()\n",
    "    x_train = transformer.fit_transform(x_train)\n",
    "    x_test = transformer.transform(x_test)\n",
    "\n",
    "    # 4. create model\n",
    "    estimator = LinearRegression()\n",
    "    # train model\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # 5. evaluation\n",
    "    y_predict = estimator.predict(x_test)\n",
    "\n",
    "    print('predict result:', y_predict)\n",
    "    print('coefficients:', estimator.coef_)\n",
    "    print('intercept in the model:', estimator.intercept_)\n",
    "\n",
    "    error = mean_squared_error(y_test, y_predict)\n",
    "    print('error:', error)\n",
    "\n",
    "linear_model_normal_equation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit_transform()方法用于计算特征数据的均值和标准差，并将原始特征数据进行标准化处理。该方法包含两个步骤，先fit()计算特征数据的均值和标准差，再transform()进行标准化处理。在训练集上调用fit_transform()，是为了根据训练集的数据计算均值和标准差，然后将训练集数据进行标准化处理。\n",
    "\n",
    "而在测试集上，我们只需要使用训练集得到的均值和标准差对测试集进行相同的标准化处理，而不需要重新计算。因此，我们只需要调用transform()方法，使用之前fit_transform()在训练集上计算得到的均值和标准差，对测试集进行标准化处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict result: [28.24148337 31.60628939 21.38679428 32.65086631 20.09356296 19.03278764\n",
      " 21.33491509 19.43174612 19.61939941 32.84028009 21.32033085 27.37369297\n",
      " 15.60597634 19.88232337 36.9160298  18.81111025  9.50079384 18.55538839\n",
      " 30.68198512 24.30430341 19.0206954  34.06115355 29.56248987 17.47183193\n",
      " 34.80385339 26.59624302 34.47816845 27.37269689 19.08375715 15.42714316\n",
      " 30.82125655 14.90392722 37.41315497  8.34928826 16.31477472 17.00379992\n",
      "  7.60795117 19.86905989 40.45794344 29.02054052 25.23365367 17.75890517\n",
      " 38.94674495  6.80588288 21.67732106 25.14824719 20.66784488 20.56910675\n",
      " 17.11253759 26.18763432  9.39491428 27.28763897 30.57427586 16.62694159\n",
      "  9.50285435 35.4821122  31.81566213 22.60460191 17.58336501 21.85055174\n",
      " 23.64355677 24.03295133 20.24924818 38.25135451 25.39307792 19.6920338\n",
      " 14.02491124  6.76086093 42.20920966 21.89133297 16.89574689 22.47557293\n",
      " 40.77315033 21.6466213  36.86132536 27.19851606 21.48770503 20.70434434\n",
      " 25.31096125 23.23034823 31.37903854 20.27762925 23.95991716 31.50149663\n",
      " 27.10706397 20.86237628 29.13121889 21.87546901 26.59701068 19.20165125\n",
      " 25.39205509 24.01650697 19.86404281 17.11234561 15.37406266 18.34024935\n",
      " 24.68647147 16.68421813 20.74587168 26.72030382 20.70148648 17.88584278\n",
      " 24.22319978 23.31794065 20.7026137  36.64812139 15.9345506  22.19442713\n",
      " 32.72077873 33.71132335 20.58656345 26.30786408 22.95802918 17.64957099\n",
      " 21.50480995 21.73426372 27.51212834 25.15416558 23.70669143 14.54797478\n",
      " 15.48746376  3.80058489 29.2554054  20.62071269 22.34090425 28.03777109\n",
      " 28.49642247]\n",
      "coefficients: [-0.57589259  1.01293096 -0.32159037  0.77029155 -1.84746217  2.74727106\n",
      " -0.12472782 -3.25086703  1.912267   -1.18282613 -1.73943699  0.85543186\n",
      " -3.90701709]\n",
      "intercept in the model: [22.61661481]\n",
      "error: 20.92876859780435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liangzhu/anaconda3/envs/skl-learn-old/lib/python3.11/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def linear_model2():\n",
    "    \"\"\" METHOD2:SGDRegressor\n",
    "    \"\"\"\n",
    "    # 1. get data\n",
    "    data = load_boston()\n",
    "\n",
    "    # 2. data preparation\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, random_state=22)\n",
    "\n",
    "    # 3. normalization\n",
    "    transformer = StandardScaler()\n",
    "    x_train = transformer.fit_transform(x_train)\n",
    "    x_test = transformer.transform(x_test)\n",
    "\n",
    "    # 4. create Model\n",
    "    estimator = SGDRegressor(max_iter=1000)\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # 5. model evaluation\n",
    "    y_predcit = estimator.predict(x_test)\n",
    "    print('predict result:', y_predcit)\n",
    "    print('coefficients:', estimator.coef_)\n",
    "    print('intercept in the model:', estimator.intercept_)\n",
    "\n",
    "    error = mean_squared_error(y_test, y_predcit)\n",
    "    print('error:', error)\n",
    "\n",
    "linear_model2()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
